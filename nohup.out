logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_071320__layer10FNO.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [16, 16], 'hidden_channels': 24, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 10, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 32, 'n_tests': [200], 'test_resolutions': [32], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 32 with 200 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-9): 10 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([24, 24, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-9): 10 x Flattened1dConv(
        (conv): Conv1d(24, 24, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-9): 10 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(24, 12, kernel_size=(1,), stride=(1,))
          (1): Conv1d(12, 24, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-9): 10 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 24, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(24, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7ff584ef6880>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7ff584c690a0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7ff584c690a0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7ff584cbefa0>}

### Beginning Training...


n_params: 1673857
Training on 1000 samples
Testing on [200] samples         on resolutions [32].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 32, 32])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=7.39, avg_loss=0.4554, train_err=3.6431
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 32_h1=0.2780, 32_l2=0.1838
[1] time=6.05, avg_loss=0.2264, train_err=1.8114
Eval: 32_h1=0.2088, 32_l2=0.1499
[2] time=5.73, avg_loss=0.1847, train_err=1.4775
Eval: 32_h1=0.1733, 32_l2=0.1253
[3] time=6.13, avg_loss=0.1581, train_err=1.2650
Eval: 32_h1=0.1578, 32_l2=0.1134
[4] time=6.32, avg_loss=0.1430, train_err=1.1442
Eval: 32_h1=0.1515, 32_l2=0.1066
[5] time=5.68, avg_loss=0.1350, train_err=1.0803
Eval: 32_h1=0.1556, 32_l2=0.1073
[6] time=5.30, avg_loss=0.1297, train_err=1.0374
Eval: 32_h1=0.1466, 32_l2=0.0988
[7] time=5.47, avg_loss=0.1137, train_err=0.9094
Eval: 32_h1=0.1424, 32_l2=0.0881
[8] time=4.97, avg_loss=0.1182, train_err=0.9458
Eval: 32_h1=0.1387, 32_l2=0.0861
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_071426__L10_HC2_MLP.log
[9] time=6.07, avg_loss=0.1066, train_err=0.8525
Eval: 32_h1=0.1395, 32_l2=0.0964
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [16, 16], 'hidden_channels': 24, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 10, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 32, 'n_tests': [200], 'test_resolutions': [32], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 32 with 200 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-9): 10 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([24, 24, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-9): 10 x Flattened1dConv(
        (conv): Conv1d(24, 24, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-9): 10 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(24, 12, kernel_size=(1,), stride=(1,))
          (1): Conv1d(12, 24, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-9): 10 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-9): 10 x HyperConnection(
      (layer_norm): GroupNorm(1, 24, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(24, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 24, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(24, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7fe7e0e7d220>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7fe7e0e7d7c0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7fe7e0e7d7c0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7fe7e0e7d7f0>}

### Beginning Training...


n_params: 1676357
Training on 1000 samples
Testing on [200] samples         on resolutions [32].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 32, 32])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[10] time=6.18, avg_loss=0.1036, train_err=0.8286
Eval: 32_h1=0.1373, 32_l2=0.0793
[0] time=8.35, avg_loss=0.4350, train_err=3.4801
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 32_h1=0.2870, 32_l2=0.1852
[11] time=5.95, avg_loss=0.0981, train_err=0.7849
Eval: 32_h1=0.1461, 32_l2=0.0939
[1] time=6.95, avg_loss=0.2506, train_err=2.0045
Eval: 32_h1=0.2648, 32_l2=0.1810
[12] time=5.22, avg_loss=0.0892, train_err=0.7140
Eval: 32_h1=0.1315, 32_l2=0.0741
[13] time=5.88, avg_loss=0.0854, train_err=0.6829
[2] time=6.84, avg_loss=0.2091, train_err=1.6724
Eval: 32_h1=0.1332, 32_l2=0.0778
Eval: 32_h1=0.2004, 32_l2=0.1403
[14] time=5.77, avg_loss=0.0812, train_err=0.6500
Eval: 32_h1=0.1354, 32_l2=0.0715
[3] time=7.45, avg_loss=0.1795, train_err=1.4358
Eval: 32_h1=0.1823, 32_l2=0.1164
[15] time=5.97, avg_loss=0.0802, train_err=0.6414
Eval: 32_h1=0.1418, 32_l2=0.0825
[4] time=8.72, avg_loss=0.1548, train_err=1.2388
Eval: 32_h1=0.1654, 32_l2=0.1077
[16] time=5.60, avg_loss=0.0787, train_err=0.6295
Eval: 32_h1=0.1305, 32_l2=0.0678
[17] time=5.57, avg_loss=0.0742, train_err=0.5933
[5] time=7.24, avg_loss=0.1445, train_err=1.1561
Eval: 32_h1=0.1326, 32_l2=0.0708
Eval: 32_h1=0.1647, 32_l2=0.1007
[18] time=5.63, avg_loss=0.0710, train_err=0.5680
Eval: 32_h1=0.1297, 32_l2=0.0648
[6] time=6.95, avg_loss=0.1372, train_err=1.0979
Eval: 32_h1=0.1573, 32_l2=0.0941
[19] time=6.17, avg_loss=0.0708, train_err=0.5665
Eval: 32_h1=0.1291, 32_l2=0.0646
[7] time=7.28, avg_loss=0.1207, train_err=0.9654
Eval: 32_h1=0.1519, 32_l2=0.0862
[20] time=5.94, avg_loss=0.0670, train_err=0.5361
Eval: 32_h1=0.1298, 32_l2=0.0700
[8] time=7.56, avg_loss=0.1089, train_err=0.8708
Eval: 32_h1=0.1529, 32_l2=0.0871
[21] time=4.98, avg_loss=0.0681, train_err=0.5447
Eval: 32_h1=0.1317, 32_l2=0.0662
[22] time=5.61, avg_loss=0.0625, train_err=0.5002
Eval: 32_h1=0.1279, 32_l2=0.0630
[9] time=7.75, avg_loss=0.1072, train_err=0.8575
Eval: 32_h1=0.1484, 32_l2=0.0832
[23] time=6.23, avg_loss=0.0605, train_err=0.4837
Eval: 32_h1=0.1266, 32_l2=0.0584
[10] time=7.23, avg_loss=0.1048, train_err=0.8382
Eval: 32_h1=0.1511, 32_l2=0.0816
[24] time=5.89, avg_loss=0.0602, train_err=0.4819
Eval: 32_h1=0.1296, 32_l2=0.0637
[11] time=7.78, avg_loss=0.0927, train_err=0.7417
Eval: 32_h1=0.1436, 32_l2=0.0767
[25] time=6.21, avg_loss=0.0638, train_err=0.5102
Eval: 32_h1=0.1289, 32_l2=0.0616
[12] time=7.22, avg_loss=0.0906, train_err=0.7248
Eval: 32_h1=0.1460, 32_l2=0.0766
[26] time=5.45, avg_loss=0.0625, train_err=0.4999
Eval: 32_h1=0.1305, 32_l2=0.0712
[27] time=5.50, avg_loss=0.0610, train_err=0.4884
Eval: 32_h1=0.1283, 32_l2=0.0619
[13] time=7.35, avg_loss=0.0864, train_err=0.6914
Eval: 32_h1=0.1520, 32_l2=0.0806
[28] time=5.61, avg_loss=0.0585, train_err=0.4681
Eval: 32_h1=0.1254, 32_l2=0.0588
[14] time=7.05, avg_loss=0.0840, train_err=0.6724
Eval: 32_h1=0.1404, 32_l2=0.0725
[29] time=5.73, avg_loss=0.0564, train_err=0.4509
Eval: 32_h1=0.1287, 32_l2=0.0638
[15] time=7.28, avg_loss=0.0801, train_err=0.6411
Eval: 32_h1=0.1405, 32_l2=0.0762
[30] time=5.59, avg_loss=0.0560, train_err=0.4483
Eval: 32_h1=0.1283, 32_l2=0.0609
[31] time=6.42, avg_loss=0.0578, train_err=0.4622
[16] time=7.83, avg_loss=0.0776, train_err=0.6212
Eval: 32_h1=0.1275, 32_l2=0.0600
Eval: 32_h1=0.1427, 32_l2=0.0701
[32] time=6.51, avg_loss=0.0517, train_err=0.4140
Eval: 32_h1=0.1261, 32_l2=0.0594
[17] time=7.90, avg_loss=0.0757, train_err=0.6052
Eval: 32_h1=0.1393, 32_l2=0.0707
[33] time=6.32, avg_loss=0.0523, train_err=0.4185
Eval: 32_h1=0.1261, 32_l2=0.0580
[18] time=7.82, avg_loss=0.0757, train_err=0.6057
Eval: 32_h1=0.1375, 32_l2=0.0690
[34] time=5.88, avg_loss=0.0517, train_err=0.4134
Eval: 32_h1=0.1269, 32_l2=0.0589
[19] time=7.08, avg_loss=0.0718, train_err=0.5746
Eval: 32_h1=0.1384, 32_l2=0.0740
[35] time=5.96, avg_loss=0.0510, train_err=0.4080
Eval: 32_h1=0.1264, 32_l2=0.0589
[20] time=6.72, avg_loss=0.0714, train_err=0.5710
Eval: 32_h1=0.1407, 32_l2=0.0743
[36] time=5.80, avg_loss=0.0503, train_err=0.4023
Eval: 32_h1=0.1266, 32_l2=0.0632
[21] time=7.00, avg_loss=0.0757, train_err=0.6053
[37] time=6.38, avg_loss=0.0492, train_err=0.3937
Eval: 32_h1=0.1411, 32_l2=0.0700
Eval: 32_h1=0.1272, 32_l2=0.0583
[38] time=6.39, avg_loss=0.0489, train_err=0.3909
Eval: 32_h1=0.1270, 32_l2=0.0586
[22] time=7.96, avg_loss=0.0658, train_err=0.5267
Eval: 32_h1=0.1359, 32_l2=0.0678
[39] time=6.07, avg_loss=0.0516, train_err=0.4130
Eval: 32_h1=0.1264, 32_l2=0.0616
[23] time=7.14, avg_loss=0.0607, train_err=0.4854
Eval: 32_h1=0.1332, 32_l2=0.0640
[40] time=6.27, avg_loss=0.0516, train_err=0.4127
Eval: 32_h1=0.1261, 32_l2=0.0584
[24] time=7.93, avg_loss=0.0657, train_err=0.5257
Eval: 32_h1=0.1420, 32_l2=0.0740
[41] time=7.61, avg_loss=0.0481, train_err=0.3844
Eval: 32_h1=0.1256, 32_l2=0.0572
[25] time=9.13, avg_loss=0.0661, train_err=0.5289
Eval: 32_h1=0.1361, 32_l2=0.0673
[42] time=7.38, avg_loss=0.0487, train_err=0.3894
Eval: 32_h1=0.1249, 32_l2=0.0577
[43] time=7.78, avg_loss=0.0466, train_err=0.3732
Eval: 32_h1=0.1266, 32_l2=0.0595
[26] time=10.07, avg_loss=0.0630, train_err=0.5037
Eval: 32_h1=0.1385, 32_l2=0.0695
[44] time=7.56, avg_loss=0.0465, train_err=0.3717
Eval: 32_h1=0.1245, 32_l2=0.0563
[27] time=10.59, avg_loss=0.0619, train_err=0.4951
Eval: 32_h1=0.1368, 32_l2=0.0691
[45] time=7.11, avg_loss=0.0478, train_err=0.3827
Eval: 32_h1=0.1261, 32_l2=0.0611
[28] time=10.48, avg_loss=0.0603, train_err=0.4823
Eval: 32_h1=0.1407, 32_l2=0.0720
[46] time=7.90, avg_loss=0.0465, train_err=0.3717
Eval: 32_h1=0.1257, 32_l2=0.0582
[47] time=7.63, avg_loss=0.0461, train_err=0.3692
Eval: 32_h1=0.1257, 32_l2=0.0684
[29] time=9.20, avg_loss=0.0592, train_err=0.4738
Eval: 32_h1=0.1325, 32_l2=0.0650
[48] time=7.72, avg_loss=0.0435, train_err=0.3483
Eval: 32_h1=0.1247, 32_l2=0.0565
[30] time=10.92, avg_loss=0.0571, train_err=0.4570
Eval: 32_h1=0.1331, 32_l2=0.0645
[49] time=7.70, avg_loss=0.0437, train_err=0.3495
Eval: 32_h1=0.1267, 32_l2=0.0626
[31] time=9.24, avg_loss=0.0564, train_err=0.4514
Eval: 32_h1=0.1316, 32_l2=0.0627
[50] time=7.58, avg_loss=0.0451, train_err=0.3604
Eval: 32_h1=0.1252, 32_l2=0.0561
[32] time=9.72, avg_loss=0.0603, train_err=0.4826
[51] time=7.68, avg_loss=0.0463, train_err=0.3705
Eval: 32_h1=0.1258, 32_l2=0.0575
Eval: 32_h1=0.1330, 32_l2=0.0642
[52] time=7.11, avg_loss=0.0442, train_err=0.3533
Eval: 32_h1=0.1251, 32_l2=0.0575
[33] time=10.50, avg_loss=0.0537, train_err=0.4292
Eval: 32_h1=0.1325, 32_l2=0.0638
[53] time=7.98, avg_loss=0.0421, train_err=0.3370
Eval: 32_h1=0.1256, 32_l2=0.0594
[34] time=9.71, avg_loss=0.0525, train_err=0.4203
Eval: 32_h1=0.1297, 32_l2=0.0614
[54] time=7.36, avg_loss=0.0455, train_err=0.3639
Eval: 32_h1=0.1248, 32_l2=0.0577
[55] time=7.12, avg_loss=0.0449, train_err=0.3595
Eval: 32_h1=0.1267, 32_l2=0.0601
[35] time=10.29, avg_loss=0.0535, train_err=0.4276
Eval: 32_h1=0.1310, 32_l2=0.0617
[56] time=7.78, avg_loss=0.0437, train_err=0.3496
Eval: 32_h1=0.1248, 32_l2=0.0583
[36] time=10.53, avg_loss=0.0531, train_err=0.4248
Eval: 32_h1=0.1306, 32_l2=0.0623
[57] time=8.19, avg_loss=0.0419, train_err=0.3350
Eval: 32_h1=0.1256, 32_l2=0.0589
[37] time=10.26, avg_loss=0.0522, train_err=0.4174
Eval: 32_h1=0.1327, 32_l2=0.0642
[58] time=7.32, avg_loss=0.0417, train_err=0.3332
Eval: 32_h1=0.1254, 32_l2=0.0626
[59] time=7.22, avg_loss=0.0451, train_err=0.3607
Eval: 32_h1=0.1304, 32_l2=0.0649
[38] time=9.32, avg_loss=0.0565, train_err=0.4521
Eval: 32_h1=0.1335, 32_l2=0.0681
[60] time=7.11, avg_loss=0.0343, train_err=0.2740
Eval: 32_h1=0.1224, 32_l2=0.0543
[39] time=9.25, avg_loss=0.0530, train_err=0.4236
Eval: 32_h1=0.1318, 32_l2=0.0644
[61] time=6.85, avg_loss=0.0284, train_err=0.2272
Eval: 32_h1=0.1225, 32_l2=0.0544
[40] time=10.01, avg_loss=0.0496, train_err=0.3966
Eval: 32_h1=0.1312, 32_l2=0.0622
[62] time=7.59, avg_loss=0.0263, train_err=0.2105
Eval: 32_h1=0.1217, 32_l2=0.0541
[41] time=9.77, avg_loss=0.0506, train_err=0.4048
[63] time=8.41, avg_loss=0.0246, train_err=0.1964
Eval: 32_h1=0.1322, 32_l2=0.0634
Eval: 32_h1=0.1222, 32_l2=0.0546
[64] time=6.84, avg_loss=0.0254, train_err=0.2033
Eval: 32_h1=0.1233, 32_l2=0.0563
[42] time=10.27, avg_loss=0.0520, train_err=0.4159
Eval: 32_h1=0.1355, 32_l2=0.0693
[65] time=7.60, avg_loss=0.0253, train_err=0.2025
Eval: 32_h1=0.1228, 32_l2=0.0562
[43] time=10.91, avg_loss=0.0516, train_err=0.4126
Eval: 32_h1=0.1309, 32_l2=0.0626
[66] time=7.77, avg_loss=0.0250, train_err=0.2003
Eval: 32_h1=0.1226, 32_l2=0.0574
[67] time=7.18, avg_loss=0.0247, train_err=0.1977
Eval: 32_h1=0.1218, 32_l2=0.0538
[44] time=9.26, avg_loss=0.0524, train_err=0.4189
Eval: 32_h1=0.1326, 32_l2=0.0648
[68] time=7.97, avg_loss=0.0243, train_err=0.1944
Eval: 32_h1=0.1218, 32_l2=0.0534
[45] time=9.25, avg_loss=0.0493, train_err=0.3945
Eval: 32_h1=0.1303, 32_l2=0.0630
[69] time=8.05, avg_loss=0.0249, train_err=0.1992
Eval: 32_h1=0.1242, 32_l2=0.0581
[46] time=9.18, avg_loss=0.0490, train_err=0.3918
Eval: 32_h1=0.1307, 32_l2=0.0616
[70] time=7.42, avg_loss=0.0262, train_err=0.2094
Eval: 32_h1=0.1234, 32_l2=0.0589
[47] time=10.74, avg_loss=0.0471, train_err=0.3766
Eval: 32_h1=0.1287, 32_l2=0.0606
[71] time=7.59, avg_loss=0.0255, train_err=0.2041
Eval: 32_h1=0.1225, 32_l2=0.0543
[72] time=7.38, avg_loss=0.0262, train_err=0.2095
Eval: 32_h1=0.1220, 32_l2=0.0537
[48] time=9.54, avg_loss=0.0454, train_err=0.3631
Eval: 32_h1=0.1299, 32_l2=0.0630
[73] time=7.36, avg_loss=0.0259, train_err=0.2069
Eval: 32_h1=0.1223, 32_l2=0.0582
[49] time=10.09, avg_loss=0.0458, train_err=0.3661
Eval: 32_h1=0.1313, 32_l2=0.0634
[74] time=7.54, avg_loss=0.0270, train_err=0.2157
Eval: 32_h1=0.1241, 32_l2=0.0572
[75] time=6.95, avg_loss=0.0254, train_err=0.2033
[50] time=10.63, avg_loss=0.0489, train_err=0.3910
Eval: 32_h1=0.1214, 32_l2=0.0525
Eval: 32_h1=0.1330, 32_l2=0.0652
[76] time=7.62, avg_loss=0.0236, train_err=0.1885
Eval: 32_h1=0.1221, 32_l2=0.0534
[51] time=9.53, avg_loss=0.0480, train_err=0.3841
Eval: 32_h1=0.1280, 32_l2=0.0603
[77] time=7.77, avg_loss=0.0237, train_err=0.1893
Eval: 32_h1=0.1231, 32_l2=0.0576
[52] time=9.91, avg_loss=0.0460, train_err=0.3680
Eval: 32_h1=0.1291, 32_l2=0.0614
[78] time=6.79, avg_loss=0.0247, train_err=0.1980
Eval: 32_h1=0.1221, 32_l2=0.0537
[53] time=9.27, avg_loss=0.0450, train_err=0.3596
Eval: 32_h1=0.1318, 32_l2=0.0683
[79] time=7.59, avg_loss=0.0249, train_err=0.1994
Eval: 32_h1=0.1221, 32_l2=0.0527
[80] time=7.27, avg_loss=0.0254, train_err=0.2036
Eval: 32_h1=0.1223, 32_l2=0.0540
[54] time=10.29, avg_loss=0.0463, train_err=0.3702
Eval: 32_h1=0.1269, 32_l2=0.0584
[81] time=6.02, avg_loss=0.0250, train_err=0.1997
Eval: 32_h1=0.1232, 32_l2=0.0547
[55] time=10.63, avg_loss=0.0429, train_err=0.3435
Eval: 32_h1=0.1280, 32_l2=0.0600
[82] time=7.81, avg_loss=0.0254, train_err=0.2033
Eval: 32_h1=0.1228, 32_l2=0.0558
[83] time=6.93, avg_loss=0.0244, train_err=0.1953
Eval: 32_h1=0.1223, 32_l2=0.0534
[56] time=10.62, avg_loss=0.0445, train_err=0.3557
Eval: 32_h1=0.1284, 32_l2=0.0613
[84] time=6.91, avg_loss=0.0248, train_err=0.1982
Eval: 32_h1=0.1215, 32_l2=0.0517
[57] time=10.01, avg_loss=0.0455, train_err=0.3643
Eval: 32_h1=0.1301, 32_l2=0.0630
[85] time=6.25, avg_loss=0.0250, train_err=0.2000
Eval: 32_h1=0.1227, 32_l2=0.0554
[86] time=6.97, avg_loss=0.0253, train_err=0.2023
Eval: 32_h1=0.1229, 32_l2=0.0561
[58] time=10.16, avg_loss=0.0440, train_err=0.3523
Eval: 32_h1=0.1300, 32_l2=0.0665
[87] time=8.35, avg_loss=0.0233, train_err=0.1866
Eval: 32_h1=0.1220, 32_l2=0.0529
[59] time=10.00, avg_loss=0.0441, train_err=0.3526
Eval: 32_h1=0.1324, 32_l2=0.0671
[88] time=7.64, avg_loss=0.0237, train_err=0.1898
Eval: 32_h1=0.1229, 32_l2=0.0551
[60] time=10.19, avg_loss=0.0355, train_err=0.2838
Eval: 32_h1=0.1256, 32_l2=0.0589
[61] time=10.27, avg_loss=0.0288, train_err=0.2302
Eval: 32_h1=0.1260, 32_l2=0.0581
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_072454__L10FNO.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [16, 16], 'hidden_channels': 24, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 10, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 32, 'n_tests': [200], 'test_resolutions': [32], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 32 with 200 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-9): 10 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([24, 24, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-9): 10 x Flattened1dConv(
        (conv): Conv1d(24, 24, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-9): 10 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(24, 12, kernel_size=(1,), stride=(1,))
          (1): Conv1d(12, 24, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-9): 10 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 24, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(24, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f592a621880>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f592a5a30a0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f592a5a30a0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f592a5f9fa0>}

### Beginning Training...


n_params: 1673857
Training on 1000 samples
Testing on [200] samples         on resolutions [32].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 32, 32])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=5.69, avg_loss=0.4599, train_err=3.6795
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_072526__L10FNO.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [16, 16], 'hidden_channels': 24, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 10, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 32, 'n_tests': [200], 'test_resolutions': [32], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 32 with 200 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-9): 10 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([24, 24, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-9): 10 x Flattened1dConv(
        (conv): Conv1d(24, 24, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-9): 10 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(24, 12, kernel_size=(1,), stride=(1,))
          (1): Conv1d(12, 24, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-9): 10 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 24, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(24, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7fbd78531880>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7fbd784b40a0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7fbd784b40a0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7fbd78508fa0>}

### Beginning Training...


n_params: 1673857
Training on 1000 samples
Testing on [200] samples         on resolutions [32].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 32, 32])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=6.16, avg_loss=0.4901, train_err=3.9208
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 32_h1=0.2555, 32_l2=0.1697
[1] time=5.38, avg_loss=0.2169, train_err=1.7351
Eval: 32_h1=0.1984, 32_l2=0.1399
[2] time=4.79, avg_loss=0.1778, train_err=1.4223
Eval: 32_h1=0.1761, 32_l2=0.1296
[3] time=4.77, avg_loss=0.1608, train_err=1.2865
Eval: 32_h1=0.1734, 32_l2=0.1259
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_072554__L10_HC2_MLP.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [16, 16], 'hidden_channels': 24, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 10, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 32, 'n_tests': [200], 'test_resolutions': [32], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 32 with 200 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-9): 10 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([24, 24, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-9): 10 x Flattened1dConv(
        (conv): Conv1d(24, 24, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-9): 10 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(24, 12, kernel_size=(1,), stride=(1,))
          (1): Conv1d(12, 24, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-9): 10 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-9): 10 x HyperConnection(
      (layer_norm): GroupNorm(1, 24, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(24, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 24, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(24, 48, kernel_size=(1,), stride=(1,))
      (1): Conv1d(48, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7fe1e2215250>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7fe1e22157f0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7fe1e22157f0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7fe1e2215820>}

### Beginning Training...


n_params: 1676357
Training on 1000 samples
Testing on [200] samples         on resolutions [32].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 32, 32])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[4] time=5.52, avg_loss=0.1404, train_err=1.1232
Eval: 32_h1=0.1557, 32_l2=0.1077
[5] time=5.64, avg_loss=0.1259, train_err=1.0076
Eval: 32_h1=0.1457, 32_l2=0.0962
[0] time=8.98, avg_loss=0.3958, train_err=3.1660
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 32_h1=0.2829, 32_l2=0.1847
[6] time=6.88, avg_loss=0.1159, train_err=0.9274
Eval: 32_h1=0.1403, 32_l2=0.0861
[1] time=8.63, avg_loss=0.2475, train_err=1.9802
Eval: 32_h1=0.2237, 32_l2=0.1508
[7] time=5.55, avg_loss=0.1142, train_err=0.9135
Eval: 32_h1=0.1354, 32_l2=0.0779
[8] time=5.04, avg_loss=0.1107, train_err=0.8856
Eval: 32_h1=0.1343, 32_l2=0.0773
[2] time=8.56, avg_loss=0.2125, train_err=1.7001
Eval: 32_h1=0.2289, 32_l2=0.1587
[9] time=5.76, avg_loss=0.0973, train_err=0.7785
Eval: 32_h1=0.1371, 32_l2=0.0737
[3] time=7.13, avg_loss=0.1776, train_err=1.4209
Eval: 32_h1=0.1792, 32_l2=0.1175
[10] time=5.72, avg_loss=0.0907, train_err=0.7255
Eval: 32_h1=0.1322, 32_l2=0.0697
[4] time=8.13, avg_loss=0.1644, train_err=1.3154
Eval: 32_h1=0.1725, 32_l2=0.1111
[11] time=6.94, avg_loss=0.0917, train_err=0.7339
Eval: 32_h1=0.1324, 32_l2=0.0722
[12] time=5.29, avg_loss=0.0842, train_err=0.6737
Eval: 32_h1=0.1304, 32_l2=0.0672
[5] time=8.89, avg_loss=0.1435, train_err=1.1477
Eval: 32_h1=0.1721, 32_l2=0.1072
[13] time=5.53, avg_loss=0.0836, train_err=0.6686
Eval: 32_h1=0.1364, 32_l2=0.0754
[6] time=7.94, avg_loss=0.1384, train_err=1.1068
Eval: 32_h1=0.1634, 32_l2=0.0989
[14] time=5.66, avg_loss=0.0803, train_err=0.6425
Eval: 32_h1=0.1325, 32_l2=0.0705
[15] time=6.04, avg_loss=0.0822, train_err=0.6577
Eval: 32_h1=0.1341, 32_l2=0.0742
[7] time=7.85, avg_loss=0.1231, train_err=0.9851
Eval: 32_h1=0.1503, 32_l2=0.0883
[16] time=5.20, avg_loss=0.0745, train_err=0.5963
Eval: 32_h1=0.1284, 32_l2=0.0674
[8] time=8.51, avg_loss=0.1159, train_err=0.9273
Eval: 32_h1=0.1628, 32_l2=0.0947
[17] time=6.67, avg_loss=0.0695, train_err=0.5558
Eval: 32_h1=0.1290, 32_l2=0.0674
[9] time=8.37, avg_loss=0.1092, train_err=0.8734
Eval: 32_h1=0.1513, 32_l2=0.0862
[18] time=6.09, avg_loss=0.0691, train_err=0.5531
Eval: 32_h1=0.1300, 32_l2=0.0654
[19] time=5.65, avg_loss=0.0716, train_err=0.5731
Eval: 32_h1=0.1307, 32_l2=0.0664
[10] time=7.60, avg_loss=0.0987, train_err=0.7898
Eval: 32_h1=0.1460, 32_l2=0.0782
[20] time=6.00, avg_loss=0.0691, train_err=0.5529
Eval: 32_h1=0.1292, 32_l2=0.0655
[11] time=7.99, avg_loss=0.0974, train_err=0.7789
Eval: 32_h1=0.1457, 32_l2=0.0809
[21] time=6.01, avg_loss=0.0644, train_err=0.5153
Eval: 32_h1=0.1274, 32_l2=0.0631
[12] time=8.01, avg_loss=0.0925, train_err=0.7400
Eval: 32_h1=0.1407, 32_l2=0.0750
[22] time=5.74, avg_loss=0.0636, train_err=0.5089
Eval: 32_h1=0.1254, 32_l2=0.0608
[23] time=6.45, avg_loss=0.0623, train_err=0.4985
Eval: 32_h1=0.1279, 32_l2=0.0656
[13] time=7.47, avg_loss=0.0852, train_err=0.6818
Eval: 32_h1=0.1422, 32_l2=0.0752
[24] time=5.21, avg_loss=0.0599, train_err=0.4790
Eval: 32_h1=0.1311, 32_l2=0.0698
[14] time=7.53, avg_loss=0.0866, train_err=0.6930
Eval: 32_h1=0.1437, 32_l2=0.0752
[25] time=5.03, avg_loss=0.0590, train_err=0.4720
Eval: 32_h1=0.1239, 32_l2=0.0576
[26] time=5.86, avg_loss=0.0608, train_err=0.4867
[15] time=8.36, avg_loss=0.0804, train_err=0.6434
Eval: 32_h1=0.1337, 32_l2=0.0731
Eval: 32_h1=0.1404, 32_l2=0.0729
[27] time=5.21, avg_loss=0.0607, train_err=0.4858
Eval: 32_h1=0.1295, 32_l2=0.0654
[16] time=8.36, avg_loss=0.0765, train_err=0.6117
Eval: 32_h1=0.1406, 32_l2=0.0728
[28] time=6.06, avg_loss=0.0577, train_err=0.4615
Eval: 32_h1=0.1307, 32_l2=0.0704
[17] time=7.84, avg_loss=0.0749, train_err=0.5996
Eval: 32_h1=0.1402, 32_l2=0.0720
[29] time=5.86, avg_loss=0.0562, train_err=0.4497
Eval: 32_h1=0.1322, 32_l2=0.0696
[30] time=5.38, avg_loss=0.0553, train_err=0.4422
Eval: 32_h1=0.1261, 32_l2=0.0611
[18] time=8.65, avg_loss=0.0733, train_err=0.5863
Eval: 32_h1=0.1422, 32_l2=0.0721
[31] time=5.62, avg_loss=0.0534, train_err=0.4276
Eval: 32_h1=0.1259, 32_l2=0.0612
[19] time=8.12, avg_loss=0.0741, train_err=0.5929
Eval: 32_h1=0.1439, 32_l2=0.0742
[32] time=5.18, avg_loss=0.0515, train_err=0.4123
Eval: 32_h1=0.1238, 32_l2=0.0572
[33] time=5.97, avg_loss=0.0519, train_err=0.4151
Eval: 32_h1=0.1267, 32_l2=0.0633
[20] time=8.97, avg_loss=0.0702, train_err=0.5618
Eval: 32_h1=0.1381, 32_l2=0.0669
[34] time=5.96, avg_loss=0.0513, train_err=0.4107
Eval: 32_h1=0.1314, 32_l2=0.0759
[21] time=7.12, avg_loss=0.0732, train_err=0.5854
Eval: 32_h1=0.1342, 32_l2=0.0632
[35] time=5.65, avg_loss=0.0504, train_err=0.4035
Eval: 32_h1=0.1230, 32_l2=0.0575
[22] time=7.70, avg_loss=0.0697, train_err=0.5573
Eval: 32_h1=0.1411, 32_l2=0.0725
[36] time=6.01, avg_loss=0.0519, train_err=0.4153
Eval: 32_h1=0.1231, 32_l2=0.0583
[37] time=5.51, avg_loss=0.0498, train_err=0.3982
Eval: 32_h1=0.1260, 32_l2=0.0613
[23] time=6.94, avg_loss=0.0687, train_err=0.5493
Eval: 32_h1=0.1358, 32_l2=0.0655
[38] time=6.13, avg_loss=0.0485, train_err=0.3880
Eval: 32_h1=0.1227, 32_l2=0.0609
[24] time=6.24, avg_loss=0.0712, train_err=0.5700
Eval: 32_h1=0.1378, 32_l2=0.0692
[39] time=5.52, avg_loss=0.0517, train_err=0.4138
Eval: 32_h1=0.1247, 32_l2=0.0610
[25] time=7.46, avg_loss=0.0663, train_err=0.5304
Eval: 32_h1=0.1386, 32_l2=0.0704
[40] time=6.46, avg_loss=0.0485, train_err=0.3881
Eval: 32_h1=0.1235, 32_l2=0.0613
[26] time=8.16, avg_loss=0.0643, train_err=0.5145
Eval: 32_h1=0.1343, 32_l2=0.0648
[41] time=6.35, avg_loss=0.0482, train_err=0.3852
Eval: 32_h1=0.1237, 32_l2=0.0588
[42] time=5.35, avg_loss=0.0492, train_err=0.3933
Eval: 32_h1=0.1273, 32_l2=0.0645
[27] time=8.27, avg_loss=0.0596, train_err=0.4770
Eval: 32_h1=0.1370, 32_l2=0.0673
[43] time=6.28, avg_loss=0.0499, train_err=0.3991
Eval: 32_h1=0.1230, 32_l2=0.0579
[28] time=7.86, avg_loss=0.0602, train_err=0.4812
Eval: 32_h1=0.1341, 32_l2=0.0651
[44] time=7.11, avg_loss=0.0487, train_err=0.3896
Eval: 32_h1=0.1251, 32_l2=0.0620
[29] time=7.40, avg_loss=0.0565, train_err=0.4517
Eval: 32_h1=0.1324, 32_l2=0.0624
[45] time=6.82, avg_loss=0.0509, train_err=0.4070
Eval: 32_h1=0.1285, 32_l2=0.0701
[30] time=7.92, avg_loss=0.0576, train_err=0.4606
Eval: 32_h1=0.1326, 32_l2=0.0630
[46] time=6.02, avg_loss=0.0487, train_err=0.3893
Eval: 32_h1=0.1240, 32_l2=0.0602
[31] time=7.21, avg_loss=0.0551, train_err=0.4407
Eval: 32_h1=0.1318, 32_l2=0.0643
[47] time=5.29, avg_loss=0.0472, train_err=0.3776
Eval: 32_h1=0.1245, 32_l2=0.0618
[48] time=5.77, avg_loss=0.0464, train_err=0.3708
Eval: 32_h1=0.1237, 32_l2=0.0632
[32] time=8.62, avg_loss=0.0544, train_err=0.4355
Eval: 32_h1=0.1359, 32_l2=0.0689
[49] time=5.43, avg_loss=0.0530, train_err=0.4236
Eval: 32_h1=0.1322, 32_l2=0.0724
[33] time=8.12, avg_loss=0.0546, train_err=0.4364
[50] time=4.74, avg_loss=0.0473, train_err=0.3784
Eval: 32_h1=0.1320, 32_l2=0.0651
Eval: 32_h1=0.1265, 32_l2=0.0632
[51] time=5.05, avg_loss=0.0438, train_err=0.3502
Eval: 32_h1=0.1211, 32_l2=0.0548
[34] time=7.61, avg_loss=0.0556, train_err=0.4445
Eval: 32_h1=0.1316, 32_l2=0.0606
[52] time=4.78, avg_loss=0.0450, train_err=0.3602
Eval: 32_h1=0.1252, 32_l2=0.0610
[35] time=7.36, avg_loss=0.0513, train_err=0.4108
Eval: 32_h1=0.1313, 32_l2=0.0610
[53] time=5.69, avg_loss=0.0438, train_err=0.3502
Eval: 32_h1=0.1227, 32_l2=0.0597
[54] time=5.21, avg_loss=0.0420, train_err=0.3364
Eval: 32_h1=0.1221, 32_l2=0.0568
[36] time=7.47, avg_loss=0.0522, train_err=0.4178
Eval: 32_h1=0.1305, 32_l2=0.0615
[55] time=5.82, avg_loss=0.0419, train_err=0.3354
Eval: 32_h1=0.1212, 32_l2=0.0539
[37] time=7.33, avg_loss=0.0507, train_err=0.4054
Eval: 32_h1=0.1313, 32_l2=0.0661
[56] time=4.63, avg_loss=0.0436, train_err=0.3486
Eval: 32_h1=0.1225, 32_l2=0.0602
[57] time=5.28, avg_loss=0.0435, train_err=0.3481
[38] time=7.20, avg_loss=0.0529, train_err=0.4229
Eval: 32_h1=0.1221, 32_l2=0.0572
Eval: 32_h1=0.1330, 32_l2=0.0651
[58] time=5.82, avg_loss=0.0448, train_err=0.3582
Eval: 32_h1=0.1240, 32_l2=0.0641
[39] time=7.36, avg_loss=0.0567, train_err=0.4533
Eval: 32_h1=0.1311, 32_l2=0.0628
[59] time=5.21, avg_loss=0.0437, train_err=0.3494
Eval: 32_h1=0.1224, 32_l2=0.0566
[40] time=7.94, avg_loss=0.0528, train_err=0.4226
Eval: 32_h1=0.1336, 32_l2=0.0636
[60] time=5.77, avg_loss=0.0353, train_err=0.2822
Eval: 32_h1=0.1203, 32_l2=0.0560
[61] time=5.60, avg_loss=0.0278, train_err=0.2223
Eval: 32_h1=0.1203, 32_l2=0.0585
[41] time=7.48, avg_loss=0.0532, train_err=0.4257
Eval: 32_h1=0.1297, 32_l2=0.0611
[62] time=5.38, avg_loss=0.0256, train_err=0.2048
Eval: 32_h1=0.1189, 32_l2=0.0538
[42] time=7.10, avg_loss=0.0503, train_err=0.4025
Eval: 32_h1=0.1294, 32_l2=0.0597
[63] time=5.76, avg_loss=0.0257, train_err=0.2054
Eval: 32_h1=0.1188, 32_l2=0.0535
[43] time=7.42, avg_loss=0.0493, train_err=0.3946
Eval: 32_h1=0.1344, 32_l2=0.0646
[64] time=6.71, avg_loss=0.0250, train_err=0.2003
Eval: 32_h1=0.1188, 32_l2=0.0535
[44] time=7.21, avg_loss=0.0508, train_err=0.4062
Eval: 32_h1=0.1334, 32_l2=0.0642
[65] time=6.16, avg_loss=0.0250, train_err=0.2001
Eval: 32_h1=0.1192, 32_l2=0.0553
[66] time=5.45, avg_loss=0.0244, train_err=0.1955
Eval: 32_h1=0.1199, 32_l2=0.0567
[45] time=7.83, avg_loss=0.0479, train_err=0.3836
Eval: 32_h1=0.1298, 32_l2=0.0621
[67] time=4.51, avg_loss=0.0260, train_err=0.2081
Eval: 32_h1=0.1190, 32_l2=0.0535
[46] time=8.23, avg_loss=0.0499, train_err=0.3990
Eval: 32_h1=0.1288, 32_l2=0.0591
[68] time=6.47, avg_loss=0.0248, train_err=0.1985
Eval: 32_h1=0.1198, 32_l2=0.0542
[47] time=7.18, avg_loss=0.0469, train_err=0.3749
Eval: 32_h1=0.1291, 32_l2=0.0607
[69] time=5.76, avg_loss=0.0252, train_err=0.2012
Eval: 32_h1=0.1196, 32_l2=0.0548
[70] time=5.96, avg_loss=0.0264, train_err=0.2116
Eval: 32_h1=0.1190, 32_l2=0.0552
[48] time=7.84, avg_loss=0.0464, train_err=0.3710
Eval: 32_h1=0.1315, 32_l2=0.0655
[71] time=5.96, avg_loss=0.0264, train_err=0.2113
Eval: 32_h1=0.1198, 32_l2=0.0542
[49] time=8.57, avg_loss=0.0462, train_err=0.3697
Eval: 32_h1=0.1291, 32_l2=0.0605
[72] time=5.10, avg_loss=0.0253, train_err=0.2027
Eval: 32_h1=0.1190, 32_l2=0.0534
[73] time=5.37, avg_loss=0.0277, train_err=0.2216
Eval: 32_h1=0.1207, 32_l2=0.0583
[50] time=7.88, avg_loss=0.0459, train_err=0.3672
Eval: 32_h1=0.1271, 32_l2=0.0585
[74] time=4.44, avg_loss=0.0279, train_err=0.2230
Eval: 32_h1=0.1200, 32_l2=0.0538
[51] time=7.99, avg_loss=0.0466, train_err=0.3731
Eval: 32_h1=0.1293, 32_l2=0.0602
[75] time=4.49, avg_loss=0.0282, train_err=0.2256
Eval: 32_h1=0.1199, 32_l2=0.0548
[76] time=5.80, avg_loss=0.0250, train_err=0.1998
Eval: 32_h1=0.1190, 32_l2=0.0543
[52] time=8.19, avg_loss=0.0451, train_err=0.3605
Eval: 32_h1=0.1300, 32_l2=0.0618
[77] time=5.88, avg_loss=0.0235, train_err=0.1877
Eval: 32_h1=0.1189, 32_l2=0.0541
[53] time=7.65, avg_loss=0.0459, train_err=0.3675
Eval: 32_h1=0.1295, 32_l2=0.0619
[78] time=5.74, avg_loss=0.0232, train_err=0.1855
Eval: 32_h1=0.1196, 32_l2=0.0538
[79] time=4.73, avg_loss=0.0258, train_err=0.2064
Eval: 32_h1=0.1202, 32_l2=0.0549
[54] time=8.18, avg_loss=0.0430, train_err=0.3439
Eval: 32_h1=0.1278, 32_l2=0.0608
[80] time=5.19, avg_loss=0.0257, train_err=0.2053
Eval: 32_h1=0.1198, 32_l2=0.0557
[55] time=7.30, avg_loss=0.0453, train_err=0.3625
Eval: 32_h1=0.1285, 32_l2=0.0590
[81] time=5.90, avg_loss=0.0251, train_err=0.2010
Eval: 32_h1=0.1189, 32_l2=0.0532
[56] time=8.48, avg_loss=0.0508, train_err=0.4068
[82] time=5.90, avg_loss=0.0248, train_err=0.1985
Eval: 32_h1=0.1282, 32_l2=0.0614
Eval: 32_h1=0.1193, 32_l2=0.0557
[83] time=5.66, avg_loss=0.0238, train_err=0.1901
Eval: 32_h1=0.1193, 32_l2=0.0540
[57] time=7.91, avg_loss=0.0453, train_err=0.3621
Eval: 32_h1=0.1268, 32_l2=0.0571
[84] time=5.86, avg_loss=0.0237, train_err=0.1893
Eval: 32_h1=0.1194, 32_l2=0.0538
[58] time=8.33, avg_loss=0.0434, train_err=0.3471
Eval: 32_h1=0.1287, 32_l2=0.0624
[85] time=5.40, avg_loss=0.0241, train_err=0.1925
Eval: 32_h1=0.1187, 32_l2=0.0534
[86] time=5.81, avg_loss=0.0258, train_err=0.2067
Eval: 32_h1=0.1193, 32_l2=0.0553
[59] time=8.42, avg_loss=0.0438, train_err=0.3506
Eval: 32_h1=0.1271, 32_l2=0.0597
[87] time=5.57, avg_loss=0.0254, train_err=0.2032
Eval: 32_h1=0.1190, 32_l2=0.0535
[60] time=8.45, avg_loss=0.0337, train_err=0.2698
Eval: 32_h1=0.1241, 32_l2=0.0572
[88] time=5.53, avg_loss=0.0241, train_err=0.1929
Eval: 32_h1=0.1193, 32_l2=0.0537
[89] time=5.45, avg_loss=0.0248, train_err=0.1986
Eval: 32_h1=0.1191, 32_l2=0.0532
[61] time=9.27, avg_loss=0.0267, train_err=0.2134
Eval: 32_h1=0.1249, 32_l2=0.0576
[90] time=5.22, avg_loss=0.0250, train_err=0.2003
Eval: 32_h1=0.1186, 32_l2=0.0525
[62] time=7.77, avg_loss=0.0258, train_err=0.2064
Eval: 32_h1=0.1241, 32_l2=0.0565
[91] time=6.79, avg_loss=0.0229, train_err=0.1831
Eval: 32_h1=0.1199, 32_l2=0.0553
[92] time=5.88, avg_loss=0.0241, train_err=0.1928
Eval: 32_h1=0.1195, 32_l2=0.0538
[63] time=8.40, avg_loss=0.0252, train_err=0.2016
Eval: 32_h1=0.1245, 32_l2=0.0570
[93] time=5.62, avg_loss=0.0242, train_err=0.1933
Eval: 32_h1=0.1198, 32_l2=0.0548
[64] time=8.10, avg_loss=0.0249, train_err=0.1990
Eval: 32_h1=0.1239, 32_l2=0.0554
[94] time=5.30, avg_loss=0.0239, train_err=0.1912
Eval: 32_h1=0.1192, 32_l2=0.0532
[65] time=7.78, avg_loss=0.0251, train_err=0.2009
Eval: 32_h1=0.1239, 32_l2=0.0559
[95] time=6.57, avg_loss=0.0238, train_err=0.1906
Eval: 32_h1=0.1194, 32_l2=0.0539
[96] time=5.60, avg_loss=0.0244, train_err=0.1954
Eval: 32_h1=0.1214, 32_l2=0.0561
[66] time=8.36, avg_loss=0.0249, train_err=0.1991
Eval: 32_h1=0.1243, 32_l2=0.0561
[97] time=5.16, avg_loss=0.0236, train_err=0.1890
Eval: 32_h1=0.1197, 32_l2=0.0557
[67] time=7.68, avg_loss=0.0262, train_err=0.2098
Eval: 32_h1=0.1247, 32_l2=0.0563
[98] time=6.11, avg_loss=0.0233, train_err=0.1863
Eval: 32_h1=0.1194, 32_l2=0.0562
[99] time=5.28, avg_loss=0.0235, train_err=0.1881
Eval: 32_h1=0.1195, 32_l2=0.0543
[68] time=8.62, avg_loss=0.0258, train_err=0.2061
Eval: 32_h1=0.1244, 32_l2=0.0563
[100] time=4.93, avg_loss=0.0239, train_err=0.1908
Eval: 32_h1=0.1196, 32_l2=0.0550
[69] time=8.18, avg_loss=0.0255, train_err=0.2036
Eval: 32_h1=0.1258, 32_l2=0.0579
[101] time=5.52, avg_loss=0.0240, train_err=0.1918
Eval: 32_h1=0.1191, 32_l2=0.0548
[102] time=5.98, avg_loss=0.0225, train_err=0.1803
Eval: 32_h1=0.1190, 32_l2=0.0531
[70] time=8.07, avg_loss=0.0276, train_err=0.2212
Eval: 32_h1=0.1242, 32_l2=0.0559
[103] time=5.76, avg_loss=0.0229, train_err=0.1835
Eval: 32_h1=0.1197, 32_l2=0.0547
[71] time=8.02, avg_loss=0.0264, train_err=0.2111
Eval: 32_h1=0.1235, 32_l2=0.0556
[104] time=5.02, avg_loss=0.0241, train_err=0.1926
Eval: 32_h1=0.1206, 32_l2=0.0555
[105] time=5.26, avg_loss=0.0236, train_err=0.1888
Eval: 32_h1=0.1192, 32_l2=0.0542
[72] time=7.71, avg_loss=0.0255, train_err=0.2044
Eval: 32_h1=0.1251, 32_l2=0.0564
[106] time=5.26, avg_loss=0.0227, train_err=0.1819
Eval: 32_h1=0.1191, 32_l2=0.0526
[73] time=7.99, avg_loss=0.0252, train_err=0.2018
Eval: 32_h1=0.1241, 32_l2=0.0554
[107] time=6.45, avg_loss=0.0232, train_err=0.1854
Eval: 32_h1=0.1185, 32_l2=0.0527
[74] time=8.19, avg_loss=0.0253, train_err=0.2026
Eval: 32_h1=0.1240, 32_l2=0.0557
[108] time=5.76, avg_loss=0.0229, train_err=0.1833
Eval: 32_h1=0.1199, 32_l2=0.0547
[109] time=5.27, avg_loss=0.0232, train_err=0.1855
Eval: 32_h1=0.1189, 32_l2=0.0525
[75] time=8.59, avg_loss=0.0264, train_err=0.2114
Eval: 32_h1=0.1249, 32_l2=0.0572
[110] time=4.73, avg_loss=0.0226, train_err=0.1808
Eval: 32_h1=0.1185, 32_l2=0.0529
[111] time=5.38, avg_loss=0.0232, train_err=0.1859
Eval: 32_h1=0.1197, 32_l2=0.0564
[76] time=8.94, avg_loss=0.0264, train_err=0.2116
Eval: 32_h1=0.1243, 32_l2=0.0556
[112] time=5.80, avg_loss=0.0228, train_err=0.1825
Eval: 32_h1=0.1196, 32_l2=0.0540
[77] time=7.77, avg_loss=0.0268, train_err=0.2147
Eval: 32_h1=0.1248, 32_l2=0.0574
[113] time=5.82, avg_loss=0.0234, train_err=0.1873
Eval: 32_h1=0.1191, 32_l2=0.0538
[114] time=5.24, avg_loss=0.0233, train_err=0.1864
Eval: 32_h1=0.1192, 32_l2=0.0533
[78] time=8.45, avg_loss=0.0251, train_err=0.2008
Eval: 32_h1=0.1244, 32_l2=0.0553
[115] time=5.09, avg_loss=0.0231, train_err=0.1846
Eval: 32_h1=0.1189, 32_l2=0.0534
[79] time=7.87, avg_loss=0.0244, train_err=0.1950
Eval: 32_h1=0.1259, 32_l2=0.0583
[116] time=5.79, avg_loss=0.0230, train_err=0.1841
Eval: 32_h1=0.1194, 32_l2=0.0536
[80] time=8.11, avg_loss=0.0253, train_err=0.2021
[117] time=5.82, avg_loss=0.0219, train_err=0.1752
Eval: 32_h1=0.1250, 32_l2=0.0571
Eval: 32_h1=0.1194, 32_l2=0.0542
[118] time=5.85, avg_loss=0.0227, train_err=0.1817
Eval: 32_h1=0.1193, 32_l2=0.0538
[81] time=7.69, avg_loss=0.0240, train_err=0.1917
Eval: 32_h1=0.1258, 32_l2=0.0578
[119] time=5.30, avg_loss=0.0227, train_err=0.1814
Eval: 32_h1=0.1193, 32_l2=0.0530
[82] time=7.40, avg_loss=0.0241, train_err=0.1931
Eval: 32_h1=0.1235, 32_l2=0.0561
[120] time=5.93, avg_loss=0.0185, train_err=0.1478
Eval: 32_h1=0.1184, 32_l2=0.0531
[83] time=7.88, avg_loss=0.0251, train_err=0.2010
Eval: 32_h1=0.1244, 32_l2=0.0558
[121] time=5.98, avg_loss=0.0148, train_err=0.1180
Eval: 32_h1=0.1183, 32_l2=0.0524
[122] time=6.32, avg_loss=0.0140, train_err=0.1121
Eval: 32_h1=0.1185, 32_l2=0.0529
[84] time=8.14, avg_loss=0.0251, train_err=0.2004
Eval: 32_h1=0.1244, 32_l2=0.0583
[123] time=5.73, avg_loss=0.0134, train_err=0.1070
Eval: 32_h1=0.1182, 32_l2=0.0526
[85] time=7.32, avg_loss=0.0250, train_err=0.1998
Eval: 32_h1=0.1246, 32_l2=0.0561
[124] time=5.91, avg_loss=0.0132, train_err=0.1052
Eval: 32_h1=0.1187, 32_l2=0.0534
[86] time=7.69, avg_loss=0.0252, train_err=0.2013
Eval: 32_h1=0.1241, 32_l2=0.0560
[125] time=5.47, avg_loss=0.0132, train_err=0.1053
Eval: 32_h1=0.1185, 32_l2=0.0530
[126] time=6.53, avg_loss=0.0139, train_err=0.1116
Eval: 32_h1=0.1183, 32_l2=0.0525
[87] time=8.04, avg_loss=0.0239, train_err=0.1914
Eval: 32_h1=0.1248, 32_l2=0.0560
[127] time=7.14, avg_loss=0.0140, train_err=0.1119
Eval: 32_h1=0.1183, 32_l2=0.0523
[88] time=7.97, avg_loss=0.0241, train_err=0.1931
Eval: 32_h1=0.1237, 32_l2=0.0551
[128] time=5.19, avg_loss=0.0138, train_err=0.1104
Eval: 32_h1=0.1186, 32_l2=0.0536
[89] time=6.84, avg_loss=0.0247, train_err=0.1973
Eval: 32_h1=0.1243, 32_l2=0.0560
[129] time=5.84, avg_loss=0.0136, train_err=0.1092
Eval: 32_h1=0.1181, 32_l2=0.0520
[90] time=7.28, avg_loss=0.0248, train_err=0.1985
Eval: 32_h1=0.1244, 32_l2=0.0570
[130] time=6.17, avg_loss=0.0137, train_err=0.1095
Eval: 32_h1=0.1188, 32_l2=0.0537
[91] time=7.84, avg_loss=0.0244, train_err=0.1955
[131] time=6.64, avg_loss=0.0137, train_err=0.1098
Eval: 32_h1=0.1234, 32_l2=0.0545
Eval: 32_h1=0.1187, 32_l2=0.0537
[132] time=4.93, avg_loss=0.0142, train_err=0.1136
Eval: 32_h1=0.1187, 32_l2=0.0527
[92] time=7.55, avg_loss=0.0242, train_err=0.1933
Eval: 32_h1=0.1253, 32_l2=0.0585
[133] time=4.75, avg_loss=0.0145, train_err=0.1159
Eval: 32_h1=0.1187, 32_l2=0.0526
[93] time=8.22, avg_loss=0.0262, train_err=0.2100
[134] time=6.06, avg_loss=0.0151, train_err=0.1208
Eval: 32_h1=0.1245, 32_l2=0.0569
Eval: 32_h1=0.1186, 32_l2=0.0533
[135] time=5.81, avg_loss=0.0144, train_err=0.1154
Eval: 32_h1=0.1187, 32_l2=0.0524
[94] time=8.15, avg_loss=0.0255, train_err=0.2037
Eval: 32_h1=0.1247, 32_l2=0.0562
[136] time=4.59, avg_loss=0.0144, train_err=0.1149
Eval: 32_h1=0.1184, 32_l2=0.0526
[137] time=4.54, avg_loss=0.0137, train_err=0.1095
Eval: 32_h1=0.1186, 32_l2=0.0527
[95] time=8.27, avg_loss=0.0242, train_err=0.1933
Eval: 32_h1=0.1239, 32_l2=0.0554
[138] time=5.01, avg_loss=0.0139, train_err=0.1110
Eval: 32_h1=0.1186, 32_l2=0.0529
[96] time=7.23, avg_loss=0.0250, train_err=0.1998
Eval: 32_h1=0.1236, 32_l2=0.0551
[139] time=5.74, avg_loss=0.0142, train_err=0.1139
Eval: 32_h1=0.1189, 32_l2=0.0543
[97] time=7.20, avg_loss=0.0224, train_err=0.1792
Eval: 32_h1=0.1236, 32_l2=0.0549
[140] time=5.78, avg_loss=0.0140, train_err=0.1122
Eval: 32_h1=0.1185, 32_l2=0.0523
[141] time=6.38, avg_loss=0.0145, train_err=0.1162
Eval: 32_h1=0.1185, 32_l2=0.0532
[98] time=8.08, avg_loss=0.0248, train_err=0.1981
Eval: 32_h1=0.1242, 32_l2=0.0554
[142] time=5.55, avg_loss=0.0140, train_err=0.1123
Eval: 32_h1=0.1187, 32_l2=0.0530
[99] time=7.83, avg_loss=0.0231, train_err=0.1847
Eval: 32_h1=0.1237, 32_l2=0.0557
[143] time=7.04, avg_loss=0.0135, train_err=0.1080
Eval: 32_h1=0.1183, 32_l2=0.0526
[100] time=7.55, avg_loss=0.0238, train_err=0.1903
Eval: 32_h1=0.1238, 32_l2=0.0549
[144] time=5.40, avg_loss=0.0137, train_err=0.1094
Eval: 32_h1=0.1185, 32_l2=0.0526
[145] time=5.65, avg_loss=0.0139, train_err=0.1111
Eval: 32_h1=0.1186, 32_l2=0.0524
[101] time=8.64, avg_loss=0.0229, train_err=0.1833
Eval: 32_h1=0.1244, 32_l2=0.0560
[146] time=4.90, avg_loss=0.0143, train_err=0.1142
Eval: 32_h1=0.1185, 32_l2=0.0524
[102] time=8.04, avg_loss=0.0230, train_err=0.1837
Eval: 32_h1=0.1234, 32_l2=0.0555
[147] time=5.44, avg_loss=0.0138, train_err=0.1107
Eval: 32_h1=0.1186, 32_l2=0.0528
[148] time=6.58, avg_loss=0.0135, train_err=0.1084
[103] time=8.47, avg_loss=0.0230, train_err=0.1842
Eval: 32_h1=0.1187, 32_l2=0.0529
Eval: 32_h1=0.1246, 32_l2=0.0566
[149] time=6.44, avg_loss=0.0139, train_err=0.1109
Eval: 32_h1=0.1188, 32_l2=0.0532
[104] time=9.29, avg_loss=0.0235, train_err=0.1882
Eval: 32_h1=0.1239, 32_l2=0.0556
[150] time=7.23, avg_loss=0.0140, train_err=0.1119
Eval: 32_h1=0.1187, 32_l2=0.0527
[105] time=10.63, avg_loss=0.0243, train_err=0.1942
Eval: 32_h1=0.1237, 32_l2=0.0555
[151] time=7.80, avg_loss=0.0139, train_err=0.1114
Eval: 32_h1=0.1189, 32_l2=0.0532
[152] time=8.04, avg_loss=0.0138, train_err=0.1102
Eval: 32_h1=0.1188, 32_l2=0.0530
[106] time=10.40, avg_loss=0.0226, train_err=0.1809
Eval: 32_h1=0.1238, 32_l2=0.0558
[153] time=6.63, avg_loss=0.0133, train_err=0.1067
Eval: 32_h1=0.1186, 32_l2=0.0523
[107] time=10.47, avg_loss=0.0244, train_err=0.1950
Eval: 32_h1=0.1247, 32_l2=0.0570
[154] time=7.12, avg_loss=0.0133, train_err=0.1060
Eval: 32_h1=0.1187, 32_l2=0.0532
[108] time=9.00, avg_loss=0.0236, train_err=0.1885
Eval: 32_h1=0.1235, 32_l2=0.0557
[155] time=7.12, avg_loss=0.0131, train_err=0.1052
Eval: 32_h1=0.1189, 32_l2=0.0545
[156] time=7.64, avg_loss=0.0139, train_err=0.1114
Eval: 32_h1=0.1190, 32_l2=0.0541
[109] time=10.55, avg_loss=0.0222, train_err=0.1779
Eval: 32_h1=0.1242, 32_l2=0.0559
[157] time=7.77, avg_loss=0.0141, train_err=0.1130
Eval: 32_h1=0.1186, 32_l2=0.0524
[110] time=9.71, avg_loss=0.0233, train_err=0.1863
Eval: 32_h1=0.1241, 32_l2=0.0563
[158] time=7.73, avg_loss=0.0144, train_err=0.1150
Eval: 32_h1=0.1188, 32_l2=0.0531
[111] time=9.92, avg_loss=0.0232, train_err=0.1853
Eval: 32_h1=0.1250, 32_l2=0.0561
[159] time=7.76, avg_loss=0.0136, train_err=0.1090
Eval: 32_h1=0.1192, 32_l2=0.0546
[160] time=7.30, avg_loss=0.0131, train_err=0.1045
Eval: 32_h1=0.1187, 32_l2=0.0533
[112] time=9.75, avg_loss=0.0237, train_err=0.1897
Eval: 32_h1=0.1243, 32_l2=0.0579
[161] time=7.47, avg_loss=0.0133, train_err=0.1067
Eval: 32_h1=0.1190, 32_l2=0.0529
[113] time=10.25, avg_loss=0.0226, train_err=0.1809
Eval: 32_h1=0.1234, 32_l2=0.0545
[162] time=6.70, avg_loss=0.0133, train_err=0.1062
Eval: 32_h1=0.1189, 32_l2=0.0539
[114] time=9.85, avg_loss=0.0233, train_err=0.1863
[163] time=7.54, avg_loss=0.0134, train_err=0.1069
Eval: 32_h1=0.1233, 32_l2=0.0547
Eval: 32_h1=0.1187, 32_l2=0.0532
[164] time=7.92, avg_loss=0.0130, train_err=0.1037
Eval: 32_h1=0.1185, 32_l2=0.0522
[115] time=9.92, avg_loss=0.0232, train_err=0.1854
Eval: 32_h1=0.1231, 32_l2=0.0554
[165] time=7.65, avg_loss=0.0133, train_err=0.1062
Eval: 32_h1=0.1189, 32_l2=0.0528
[116] time=10.31, avg_loss=0.0228, train_err=0.1821
Eval: 32_h1=0.1235, 32_l2=0.0549
[166] time=7.87, avg_loss=0.0135, train_err=0.1083
Eval: 32_h1=0.1188, 32_l2=0.0536
[117] time=10.10, avg_loss=0.0229, train_err=0.1831
[167] time=7.11, avg_loss=0.0131, train_err=0.1049
Eval: 32_h1=0.1232, 32_l2=0.0545
Eval: 32_h1=0.1187, 32_l2=0.0529
[168] time=7.27, avg_loss=0.0129, train_err=0.1031
Eval: 32_h1=0.1188, 32_l2=0.0530
[118] time=9.36, avg_loss=0.0218, train_err=0.1741
Eval: 32_h1=0.1235, 32_l2=0.0560
[169] time=6.80, avg_loss=0.0128, train_err=0.1022
Eval: 32_h1=0.1185, 32_l2=0.0532
[119] time=9.81, avg_loss=0.0223, train_err=0.1785
Eval: 32_h1=0.1247, 32_l2=0.0577
[170] time=6.87, avg_loss=0.0132, train_err=0.1058
Eval: 32_h1=0.1191, 32_l2=0.0530
[171] time=7.29, avg_loss=0.0138, train_err=0.1106
[120] time=10.19, avg_loss=0.0189, train_err=0.1509
Eval: 32_h1=0.1187, 32_l2=0.0531
Eval: 32_h1=0.1228, 32_l2=0.0547
[172] time=7.50, avg_loss=0.0134, train_err=0.1073
Eval: 32_h1=0.1191, 32_l2=0.0534
[121] time=9.64, avg_loss=0.0143, train_err=0.1146
Eval: 32_h1=0.1229, 32_l2=0.0540
[173] time=6.92, avg_loss=0.0131, train_err=0.1050
Eval: 32_h1=0.1188, 32_l2=0.0529
[122] time=10.10, avg_loss=0.0132, train_err=0.1056
Eval: 32_h1=0.1230, 32_l2=0.0552
[174] time=7.15, avg_loss=0.0131, train_err=0.1050
Eval: 32_h1=0.1188, 32_l2=0.0534
[175] time=7.53, avg_loss=0.0132, train_err=0.1056
Eval: 32_h1=0.1185, 32_l2=0.0530
[123] time=10.43, avg_loss=0.0134, train_err=0.1072
Eval: 32_h1=0.1230, 32_l2=0.0550
[176] time=7.65, avg_loss=0.0130, train_err=0.1039
Eval: 32_h1=0.1189, 32_l2=0.0530
[124] time=8.88, avg_loss=0.0134, train_err=0.1072
Eval: 32_h1=0.1229, 32_l2=0.0543
[177] time=5.63, avg_loss=0.0129, train_err=0.1031
Eval: 32_h1=0.1188, 32_l2=0.0532
[125] time=7.43, avg_loss=0.0137, train_err=0.1095
Eval: 32_h1=0.1229, 32_l2=0.0545
[178] time=5.42, avg_loss=0.0130, train_err=0.1042
Eval: 32_h1=0.1188, 32_l2=0.0531
[179] time=6.28, avg_loss=0.0131, train_err=0.1047
[126] time=8.24, avg_loss=0.0137, train_err=0.1096
Eval: 32_h1=0.1188, 32_l2=0.0530
Eval: 32_h1=0.1234, 32_l2=0.0545
[180] time=5.55, avg_loss=0.0111, train_err=0.0890
Eval: 32_h1=0.1187, 32_l2=0.0532
[127] time=8.29, avg_loss=0.0136, train_err=0.1087
Eval: 32_h1=0.1227, 32_l2=0.0543
[181] time=6.34, avg_loss=0.0093, train_err=0.0747
Eval: 32_h1=0.1186, 32_l2=0.0531
[128] time=8.88, avg_loss=0.0138, train_err=0.1105
[182] time=5.45, avg_loss=0.0089, train_err=0.0709
Eval: 32_h1=0.1187, 32_l2=0.0529
Eval: 32_h1=0.1231, 32_l2=0.0552
[183] time=5.80, avg_loss=0.0088, train_err=0.0706
Eval: 32_h1=0.1186, 32_l2=0.0527
[129] time=8.10, avg_loss=0.0139, train_err=0.1108
Eval: 32_h1=0.1230, 32_l2=0.0548
[184] time=6.18, avg_loss=0.0088, train_err=0.0704
Eval: 32_h1=0.1186, 32_l2=0.0526
[130] time=8.55, avg_loss=0.0137, train_err=0.1098
Eval: 32_h1=0.1227, 32_l2=0.0543
[185] time=5.68, avg_loss=0.0088, train_err=0.0702
Eval: 32_h1=0.1186, 32_l2=0.0528
[186] time=5.49, avg_loss=0.0087, train_err=0.0694
Eval: 32_h1=0.1185, 32_l2=0.0524
[131] time=8.14, avg_loss=0.0144, train_err=0.1151
Eval: 32_h1=0.1230, 32_l2=0.0546
[187] time=5.90, avg_loss=0.0087, train_err=0.0694
Eval: 32_h1=0.1186, 32_l2=0.0523
[132] time=7.28, avg_loss=0.0142, train_err=0.1137
Eval: 32_h1=0.1230, 32_l2=0.0542
[188] time=5.96, avg_loss=0.0089, train_err=0.0710
Eval: 32_h1=0.1186, 32_l2=0.0525
[133] time=8.81, avg_loss=0.0142, train_err=0.1138
[189] time=5.90, avg_loss=0.0089, train_err=0.0714
Eval: 32_h1=0.1235, 32_l2=0.0546
Eval: 32_h1=0.1189, 32_l2=0.0534
[190] time=7.02, avg_loss=0.0091, train_err=0.0726
[134] time=7.34, avg_loss=0.0143, train_err=0.1145
Eval: 32_h1=0.1188, 32_l2=0.0527
Eval: 32_h1=0.1231, 32_l2=0.0547
[191] time=5.63, avg_loss=0.0092, train_err=0.0733
Eval: 32_h1=0.1187, 32_l2=0.0523
[135] time=6.92, avg_loss=0.0138, train_err=0.1103
Eval: 32_h1=0.1233, 32_l2=0.0554
[192] time=6.14, avg_loss=0.0094, train_err=0.0750
Eval: 32_h1=0.1186, 32_l2=0.0527
[136] time=7.37, avg_loss=0.0137, train_err=0.1100
Eval: 32_h1=0.1230, 32_l2=0.0547
[193] time=5.37, avg_loss=0.0091, train_err=0.0731
Eval: 32_h1=0.1189, 32_l2=0.0530
[137] time=7.60, avg_loss=0.0134, train_err=0.1070
Eval: 32_h1=0.1231, 32_l2=0.0544
[194] time=5.53, avg_loss=0.0093, train_err=0.0747
Eval: 32_h1=0.1188, 32_l2=0.0529
[195] time=5.20, avg_loss=0.0094, train_err=0.0748
Eval: 32_h1=0.1187, 32_l2=0.0524
[138] time=7.55, avg_loss=0.0134, train_err=0.1075
Eval: 32_h1=0.1227, 32_l2=0.0539
[196] time=4.79, avg_loss=0.0092, train_err=0.0736
Eval: 32_h1=0.1188, 32_l2=0.0528
[139] time=8.66, avg_loss=0.0139, train_err=0.1108
Eval: 32_h1=0.1229, 32_l2=0.0548
[197] time=6.13, avg_loss=0.0096, train_err=0.0768
Eval: 32_h1=0.1187, 32_l2=0.0526
[198] time=5.03, avg_loss=0.0092, train_err=0.0740
Eval: 32_h1=0.1187, 32_l2=0.0526
[140] time=8.73, avg_loss=0.0132, train_err=0.1059
Eval: 32_h1=0.1230, 32_l2=0.0546
[199] time=5.16, avg_loss=0.0091, train_err=0.0730
Eval: 32_h1=0.1189, 32_l2=0.0529
[200] time=4.97, avg_loss=0.0093, train_err=0.0742
Eval: 32_h1=0.1187, 32_l2=0.0529
[141] time=8.18, avg_loss=0.0133, train_err=0.1062
Eval: 32_h1=0.1229, 32_l2=0.0545
[201] time=6.89, avg_loss=0.0096, train_err=0.0768
Eval: 32_h1=0.1187, 32_l2=0.0525
[142] time=7.49, avg_loss=0.0138, train_err=0.1107
Eval: 32_h1=0.1230, 32_l2=0.0544
[202] time=5.84, avg_loss=0.0095, train_err=0.0758
Eval: 32_h1=0.1187, 32_l2=0.0524
[143] time=8.23, avg_loss=0.0134, train_err=0.1073
Eval: 32_h1=0.1227, 32_l2=0.0542
[203] time=5.46, avg_loss=0.0096, train_err=0.0772
Eval: 32_h1=0.1186, 32_l2=0.0520
[144] time=7.74, avg_loss=0.0137, train_err=0.1095
Eval: 32_h1=0.1227, 32_l2=0.0542
[204] time=6.74, avg_loss=0.0094, train_err=0.0752
Eval: 32_h1=0.1188, 32_l2=0.0528
[205] time=6.09, avg_loss=0.0098, train_err=0.0781
Eval: 32_h1=0.1187, 32_l2=0.0530
[145] time=8.35, avg_loss=0.0138, train_err=0.1103
Eval: 32_h1=0.1232, 32_l2=0.0545
[206] time=6.47, avg_loss=0.0091, train_err=0.0731
Eval: 32_h1=0.1186, 32_l2=0.0522
[146] time=8.29, avg_loss=0.0140, train_err=0.1117
Eval: 32_h1=0.1231, 32_l2=0.0546
[207] time=5.74, avg_loss=0.0087, train_err=0.0699
Eval: 32_h1=0.1186, 32_l2=0.0522
[208] time=6.11, avg_loss=0.0088, train_err=0.0703
Eval: 32_h1=0.1188, 32_l2=0.0526
[147] time=9.20, avg_loss=0.0145, train_err=0.1163
Eval: 32_h1=0.1233, 32_l2=0.0549
[209] time=5.81, avg_loss=0.0086, train_err=0.0691
Eval: 32_h1=0.1187, 32_l2=0.0527
[148] time=8.70, avg_loss=0.0140, train_err=0.1118
Eval: 32_h1=0.1232, 32_l2=0.0552
[210] time=6.11, avg_loss=0.0087, train_err=0.0695
Eval: 32_h1=0.1189, 32_l2=0.0526
[149] time=7.30, avg_loss=0.0136, train_err=0.1084
Eval: 32_h1=0.1227, 32_l2=0.0536
[211] time=5.86, avg_loss=0.0089, train_err=0.0709
Eval: 32_h1=0.1186, 32_l2=0.0524
[212] time=5.90, avg_loss=0.0089, train_err=0.0712
Eval: 32_h1=0.1190, 32_l2=0.0530
[150] time=8.32, avg_loss=0.0129, train_err=0.1031
Eval: 32_h1=0.1226, 32_l2=0.0538
[213] time=4.90, avg_loss=0.0094, train_err=0.0753
Eval: 32_h1=0.1187, 32_l2=0.0525
[214] time=5.06, avg_loss=0.0091, train_err=0.0726
Eval: 32_h1=0.1187, 32_l2=0.0523
[151] time=9.77, avg_loss=0.0128, train_err=0.1024
Eval: 32_h1=0.1230, 32_l2=0.0544
[215] time=6.58, avg_loss=0.0090, train_err=0.0721
Eval: 32_h1=0.1188, 32_l2=0.0528
[152] time=7.25, avg_loss=0.0131, train_err=0.1047
Eval: 32_h1=0.1229, 32_l2=0.0539
[216] time=6.27, avg_loss=0.0089, train_err=0.0711
Eval: 32_h1=0.1187, 32_l2=0.0525
[153] time=9.23, avg_loss=0.0132, train_err=0.1053
Eval: 32_h1=0.1230, 32_l2=0.0541
[217] time=5.63, avg_loss=0.0089, train_err=0.0709
Eval: 32_h1=0.1187, 32_l2=0.0528
[154] time=7.09, avg_loss=0.0131, train_err=0.1052
[218] time=6.11, avg_loss=0.0088, train_err=0.0706
Eval: 32_h1=0.1228, 32_l2=0.0545
Eval: 32_h1=0.1189, 32_l2=0.0527
[219] time=4.61, avg_loss=0.0089, train_err=0.0710
Eval: 32_h1=0.1188, 32_l2=0.0527
[155] time=9.16, avg_loss=0.0136, train_err=0.1085
Eval: 32_h1=0.1229, 32_l2=0.0542
[220] time=6.06, avg_loss=0.0087, train_err=0.0699
Eval: 32_h1=0.1187, 32_l2=0.0522
[156] time=6.33, avg_loss=0.0133, train_err=0.1061
Eval: 32_h1=0.1226, 32_l2=0.0534
[221] time=5.38, avg_loss=0.0088, train_err=0.0705
Eval: 32_h1=0.1188, 32_l2=0.0527
[222] time=5.33, avg_loss=0.0089, train_err=0.0710
Eval: 32_h1=0.1187, 32_l2=0.0529
[157] time=6.78, avg_loss=0.0138, train_err=0.1108
Eval: 32_h1=0.1229, 32_l2=0.0549
[223] time=5.90, avg_loss=0.0088, train_err=0.0706
Eval: 32_h1=0.1188, 32_l2=0.0526
[158] time=7.44, avg_loss=0.0139, train_err=0.1111
Eval: 32_h1=0.1234, 32_l2=0.0547
[224] time=5.34, avg_loss=0.0088, train_err=0.0705
Eval: 32_h1=0.1189, 32_l2=0.0527
[159] time=8.16, avg_loss=0.0144, train_err=0.1154
[225] time=5.15, avg_loss=0.0089, train_err=0.0713
Eval: 32_h1=0.1232, 32_l2=0.0549
Eval: 32_h1=0.1189, 32_l2=0.0529
[226] time=6.04, avg_loss=0.0091, train_err=0.0725
[160] time=6.44, avg_loss=0.0136, train_err=0.1085
Eval: 32_h1=0.1188, 32_l2=0.0526
Eval: 32_h1=0.1229, 32_l2=0.0542
[227] time=5.17, avg_loss=0.0090, train_err=0.0717
Eval: 32_h1=0.1188, 32_l2=0.0524
[161] time=8.35, avg_loss=0.0130, train_err=0.1038
Eval: 32_h1=0.1229, 32_l2=0.0539
[228] time=5.25, avg_loss=0.0089, train_err=0.0713
Eval: 32_h1=0.1188, 32_l2=0.0524
[229] time=4.93, avg_loss=0.0086, train_err=0.0686
Eval: 32_h1=0.1188, 32_l2=0.0523
[162] time=8.21, avg_loss=0.0129, train_err=0.1036
Eval: 32_h1=0.1227, 32_l2=0.0539
[230] time=5.29, avg_loss=0.0084, train_err=0.0676
Eval: 32_h1=0.1188, 32_l2=0.0529
[163] time=7.69, avg_loss=0.0131, train_err=0.1047
Eval: 32_h1=0.1230, 32_l2=0.0549
[231] time=6.60, avg_loss=0.0085, train_err=0.0677
Eval: 32_h1=0.1187, 32_l2=0.0525
[164] time=8.21, avg_loss=0.0129, train_err=0.1029
Eval: 32_h1=0.1230, 32_l2=0.0542
[232] time=5.57, avg_loss=0.0085, train_err=0.0676
Eval: 32_h1=0.1189, 32_l2=0.0528
[233] time=5.51, avg_loss=0.0085, train_err=0.0678
Eval: 32_h1=0.1187, 32_l2=0.0523
[165] time=6.69, avg_loss=0.0126, train_err=0.1009
Eval: 32_h1=0.1233, 32_l2=0.0548
[234] time=6.53, avg_loss=0.0086, train_err=0.0692
Eval: 32_h1=0.1189, 32_l2=0.0525
[166] time=7.63, avg_loss=0.0131, train_err=0.1046
Eval: 32_h1=0.1230, 32_l2=0.0547
[235] time=6.44, avg_loss=0.0086, train_err=0.0689
Eval: 32_h1=0.1189, 32_l2=0.0528
[167] time=8.72, avg_loss=0.0133, train_err=0.1063
Eval: 32_h1=0.1230, 32_l2=0.0540
[236] time=5.20, avg_loss=0.0085, train_err=0.0679
Eval: 32_h1=0.1188, 32_l2=0.0527
[237] time=5.51, avg_loss=0.0083, train_err=0.0666
Eval: 32_h1=0.1188, 32_l2=0.0524
[168] time=7.40, avg_loss=0.0139, train_err=0.1113
Eval: 32_h1=0.1229, 32_l2=0.0537
[238] time=6.08, avg_loss=0.0087, train_err=0.0692
Eval: 32_h1=0.1189, 32_l2=0.0527
[169] time=8.01, avg_loss=0.0137, train_err=0.1093
Eval: 32_h1=0.1231, 32_l2=0.0543
[239] time=6.44, avg_loss=0.0094, train_err=0.0752
Eval: 32_h1=0.1189, 32_l2=0.0522
[170] time=7.99, avg_loss=0.0128, train_err=0.1024
Eval: 32_h1=0.1227, 32_l2=0.0541
[240] time=5.29, avg_loss=0.0080, train_err=0.0637
Eval: 32_h1=0.1188, 32_l2=0.0524
[241] time=5.36, avg_loss=0.0072, train_err=0.0572
Eval: 32_h1=0.1188, 32_l2=0.0524
[171] time=8.36, avg_loss=0.0127, train_err=0.1016
Eval: 32_h1=0.1227, 32_l2=0.0535
[242] time=5.63, avg_loss=0.0069, train_err=0.0551
Eval: 32_h1=0.1188, 32_l2=0.0526
[172] time=7.91, avg_loss=0.0128, train_err=0.1027
Eval: 32_h1=0.1229, 32_l2=0.0539
[243] time=5.59, avg_loss=0.0068, train_err=0.0545
Eval: 32_h1=0.1188, 32_l2=0.0524
[244] time=5.30, avg_loss=0.0068, train_err=0.0541
Eval: 32_h1=0.1188, 32_l2=0.0523
[173] time=8.88, avg_loss=0.0136, train_err=0.1089
Eval: 32_h1=0.1231, 32_l2=0.0542
[245] time=6.16, avg_loss=0.0067, train_err=0.0539
Eval: 32_h1=0.1188, 32_l2=0.0525
[174] time=8.47, avg_loss=0.0132, train_err=0.1054
Eval: 32_h1=0.1230, 32_l2=0.0547
[246] time=6.15, avg_loss=0.0067, train_err=0.0537
Eval: 32_h1=0.1189, 32_l2=0.0525
[175] time=7.83, avg_loss=0.0125, train_err=0.1003
Eval: 32_h1=0.1230, 32_l2=0.0546
[247] time=6.50, avg_loss=0.0067, train_err=0.0537
Eval: 32_h1=0.1188, 32_l2=0.0525
[248] time=5.83, avg_loss=0.0068, train_err=0.0543
Eval: 32_h1=0.1188, 32_l2=0.0525
[176] time=8.14, avg_loss=0.0127, train_err=0.1020
Eval: 32_h1=0.1228, 32_l2=0.0535
[249] time=6.17, avg_loss=0.0068, train_err=0.0543
Eval: 32_h1=0.1189, 32_l2=0.0527
[177] time=7.22, avg_loss=0.0124, train_err=0.0994
Eval: 32_h1=0.1231, 32_l2=0.0544
[250] time=6.45, avg_loss=0.0069, train_err=0.0548
Eval: 32_h1=0.1189, 32_l2=0.0526
[178] time=8.43, avg_loss=0.0126, train_err=0.1011
Eval: 32_h1=0.1231, 32_l2=0.0544
[251] time=6.17, avg_loss=0.0070, train_err=0.0560
Eval: 32_h1=0.1189, 32_l2=0.0526
[252] time=5.26, avg_loss=0.0071, train_err=0.0564
Eval: 32_h1=0.1189, 32_l2=0.0527
[179] time=8.00, avg_loss=0.0125, train_err=0.0999
Eval: 32_h1=0.1230, 32_l2=0.0545
[253] time=6.30, avg_loss=0.0070, train_err=0.0558
Eval: 32_h1=0.1189, 32_l2=0.0524
[180] time=8.41, avg_loss=0.0108, train_err=0.0865
Eval: 32_h1=0.1228, 32_l2=0.0540
[254] time=6.13, avg_loss=0.0071, train_err=0.0570
Eval: 32_h1=0.1189, 32_l2=0.0525
[181] time=7.68, avg_loss=0.0088, train_err=0.0704
Eval: 32_h1=0.1227, 32_l2=0.0538
[255] time=6.60, avg_loss=0.0071, train_err=0.0566
Eval: 32_h1=0.1190, 32_l2=0.0530
[256] time=5.50, avg_loss=0.0072, train_err=0.0573
Eval: 32_h1=0.1190, 32_l2=0.0526
[182] time=9.09, avg_loss=0.0084, train_err=0.0671
Eval: 32_h1=0.1227, 32_l2=0.0538
[257] time=6.33, avg_loss=0.0070, train_err=0.0561
Eval: 32_h1=0.1189, 32_l2=0.0524
[183] time=8.50, avg_loss=0.0083, train_err=0.0661
Eval: 32_h1=0.1227, 32_l2=0.0538
[258] time=6.70, avg_loss=0.0069, train_err=0.0551
Eval: 32_h1=0.1189, 32_l2=0.0526
[184] time=8.44, avg_loss=0.0083, train_err=0.0664
[259] time=5.69, avg_loss=0.0069, train_err=0.0552
Eval: 32_h1=0.1228, 32_l2=0.0539
Eval: 32_h1=0.1189, 32_l2=0.0525
[260] time=6.20, avg_loss=0.0070, train_err=0.0559
Eval: 32_h1=0.1189, 32_l2=0.0524
[185] time=8.64, avg_loss=0.0082, train_err=0.0652
Eval: 32_h1=0.1227, 32_l2=0.0537
[261] time=5.60, avg_loss=0.0070, train_err=0.0558
Eval: 32_h1=0.1188, 32_l2=0.0522
[262] time=4.38, avg_loss=0.0070, train_err=0.0562
[186] time=8.04, avg_loss=0.0081, train_err=0.0648
Eval: 32_h1=0.1189, 32_l2=0.0525
Eval: 32_h1=0.1227, 32_l2=0.0538
[263] time=5.39, avg_loss=0.0070, train_err=0.0559
Eval: 32_h1=0.1188, 32_l2=0.0521
[187] time=7.41, avg_loss=0.0085, train_err=0.0678
Eval: 32_h1=0.1228, 32_l2=0.0539
[264] time=5.11, avg_loss=0.0069, train_err=0.0555
Eval: 32_h1=0.1190, 32_l2=0.0526
[188] time=7.84, avg_loss=0.0085, train_err=0.0677
Eval: 32_h1=0.1229, 32_l2=0.0542
[265] time=5.81, avg_loss=0.0068, train_err=0.0542
Eval: 32_h1=0.1189, 32_l2=0.0522
[266] time=6.45, avg_loss=0.0068, train_err=0.0544
Eval: 32_h1=0.1189, 32_l2=0.0525
[189] time=8.44, avg_loss=0.0084, train_err=0.0676
Eval: 32_h1=0.1228, 32_l2=0.0537
[267] time=6.53, avg_loss=0.0069, train_err=0.0553
Eval: 32_h1=0.1189, 32_l2=0.0525
[190] time=8.05, avg_loss=0.0086, train_err=0.0689
Eval: 32_h1=0.1229, 32_l2=0.0538
[268] time=6.38, avg_loss=0.0069, train_err=0.0554
Eval: 32_h1=0.1189, 32_l2=0.0526
[191] time=8.10, avg_loss=0.0086, train_err=0.0685
Eval: 32_h1=0.1227, 32_l2=0.0538
[269] time=6.72, avg_loss=0.0069, train_err=0.0549
Eval: 32_h1=0.1190, 32_l2=0.0526
[192] time=7.09, avg_loss=0.0088, train_err=0.0702
Eval: 32_h1=0.1228, 32_l2=0.0540
[270] time=6.02, avg_loss=0.0068, train_err=0.0548
Eval: 32_h1=0.1188, 32_l2=0.0522
[271] time=5.68, avg_loss=0.0068, train_err=0.0548
Eval: 32_h1=0.1191, 32_l2=0.0528
[193] time=8.62, avg_loss=0.0090, train_err=0.0719
Eval: 32_h1=0.1229, 32_l2=0.0539
[272] time=5.68, avg_loss=0.0068, train_err=0.0544
Eval: 32_h1=0.1189, 32_l2=0.0522
[194] time=7.47, avg_loss=0.0089, train_err=0.0713
Eval: 32_h1=0.1229, 32_l2=0.0537
[273] time=6.27, avg_loss=0.0068, train_err=0.0545
Eval: 32_h1=0.1188, 32_l2=0.0521
[195] time=7.83, avg_loss=0.0087, train_err=0.0692
Eval: 32_h1=0.1230, 32_l2=0.0540
[274] time=4.93, avg_loss=0.0067, train_err=0.0535
Eval: 32_h1=0.1190, 32_l2=0.0525
[275] time=5.51, avg_loss=0.0067, train_err=0.0535
Eval: 32_h1=0.1190, 32_l2=0.0524
[196] time=8.62, avg_loss=0.0087, train_err=0.0698
Eval: 32_h1=0.1230, 32_l2=0.0544
[276] time=6.30, avg_loss=0.0067, train_err=0.0539
Eval: 32_h1=0.1190, 32_l2=0.0526
[197] time=7.67, avg_loss=0.0091, train_err=0.0729
Eval: 32_h1=0.1230, 32_l2=0.0539
[277] time=5.75, avg_loss=0.0068, train_err=0.0541
Eval: 32_h1=0.1190, 32_l2=0.0524
[198] time=7.16, avg_loss=0.0089, train_err=0.0710
Eval: 32_h1=0.1227, 32_l2=0.0536
[278] time=5.82, avg_loss=0.0067, train_err=0.0539
Eval: 32_h1=0.1190, 32_l2=0.0526
[279] time=5.65, avg_loss=0.0067, train_err=0.0535
Eval: 32_h1=0.1190, 32_l2=0.0524
[199] time=8.38, avg_loss=0.0088, train_err=0.0707
Eval: 32_h1=0.1228, 32_l2=0.0537
[280] time=6.66, avg_loss=0.0068, train_err=0.0541
Eval: 32_h1=0.1189, 32_l2=0.0522
[200] time=7.91, avg_loss=0.0088, train_err=0.0708
Eval: 32_h1=0.1228, 32_l2=0.0539
[281] time=5.71, avg_loss=0.0067, train_err=0.0540
Eval: 32_h1=0.1190, 32_l2=0.0525
[201] time=8.55, avg_loss=0.0084, train_err=0.0675
[282] time=6.08, avg_loss=0.0069, train_err=0.0553
Eval: 32_h1=0.1229, 32_l2=0.0538
Eval: 32_h1=0.1190, 32_l2=0.0525
[283] time=6.22, avg_loss=0.0068, train_err=0.0546
Eval: 32_h1=0.1190, 32_l2=0.0524
[202] time=8.33, avg_loss=0.0085, train_err=0.0677
Eval: 32_h1=0.1228, 32_l2=0.0537
[284] time=5.81, avg_loss=0.0068, train_err=0.0541
Eval: 32_h1=0.1190, 32_l2=0.0524
[203] time=8.09, avg_loss=0.0085, train_err=0.0679
Eval: 32_h1=0.1230, 32_l2=0.0541
[285] time=6.13, avg_loss=0.0067, train_err=0.0533
Eval: 32_h1=0.1190, 32_l2=0.0527
[204] time=8.49, avg_loss=0.0086, train_err=0.0691
[286] time=6.59, avg_loss=0.0067, train_err=0.0536
Eval: 32_h1=0.1229, 32_l2=0.0538
Eval: 32_h1=0.1189, 32_l2=0.0525
[287] time=6.49, avg_loss=0.0068, train_err=0.0540
Eval: 32_h1=0.1190, 32_l2=0.0524
[205] time=8.91, avg_loss=0.0084, train_err=0.0668
Eval: 32_h1=0.1229, 32_l2=0.0538
[288] time=6.62, avg_loss=0.0067, train_err=0.0539
Eval: 32_h1=0.1190, 32_l2=0.0525
[206] time=8.85, avg_loss=0.0085, train_err=0.0679
Eval: 32_h1=0.1229, 32_l2=0.0540
[289] time=5.55, avg_loss=0.0068, train_err=0.0544
Eval: 32_h1=0.1190, 32_l2=0.0524
[290] time=5.78, avg_loss=0.0067, train_err=0.0537
Eval: 32_h1=0.1190, 32_l2=0.0525
[207] time=8.32, avg_loss=0.0085, train_err=0.0677
Eval: 32_h1=0.1229, 32_l2=0.0537
[291] time=5.87, avg_loss=0.0065, train_err=0.0522
Eval: 32_h1=0.1189, 32_l2=0.0524
[208] time=7.00, avg_loss=0.0087, train_err=0.0697
Eval: 32_h1=0.1228, 32_l2=0.0537
[292] time=5.84, avg_loss=0.0064, train_err=0.0515
Eval: 32_h1=0.1190, 32_l2=0.0524
[209] time=8.08, avg_loss=0.0088, train_err=0.0707
Eval: 32_h1=0.1229, 32_l2=0.0538
[293] time=6.11, avg_loss=0.0065, train_err=0.0519
Eval: 32_h1=0.1190, 32_l2=0.0523
[294] time=5.62, avg_loss=0.0066, train_err=0.0525
Eval: 32_h1=0.1190, 32_l2=0.0525
[210] time=9.05, avg_loss=0.0086, train_err=0.0687
Eval: 32_h1=0.1229, 32_l2=0.0538
[295] time=5.78, avg_loss=0.0067, train_err=0.0534
Eval: 32_h1=0.1189, 32_l2=0.0525
[211] time=9.24, avg_loss=0.0083, train_err=0.0664
Eval: 32_h1=0.1228, 32_l2=0.0537
[296] time=6.72, avg_loss=0.0066, train_err=0.0528
Eval: 32_h1=0.1190, 32_l2=0.0523
[297] time=6.45, avg_loss=0.0066, train_err=0.0526
Eval: 32_h1=0.1190, 32_l2=0.0526
[212] time=9.55, avg_loss=0.0083, train_err=0.0668
Eval: 32_h1=0.1230, 32_l2=0.0540
[298] time=6.29, avg_loss=0.0065, train_err=0.0522
Eval: 32_h1=0.1191, 32_l2=0.0523
[213] time=8.47, avg_loss=0.0084, train_err=0.0675
Eval: 32_h1=0.1230, 32_l2=0.0542
[299] time=5.71, avg_loss=0.0066, train_err=0.0529
Eval: 32_h1=0.1190, 32_l2=0.0525
[214] time=7.74, avg_loss=0.0085, train_err=0.0680
Eval: 32_h1=0.1230, 32_l2=0.0542
[215] time=9.23, avg_loss=0.0083, train_err=0.0662
Eval: 32_h1=0.1229, 32_l2=0.0540
[216] time=6.73, avg_loss=0.0083, train_err=0.0665
Eval: 32_h1=0.1229, 32_l2=0.0538
[217] time=8.52, avg_loss=0.0084, train_err=0.0671
Eval: 32_h1=0.1230, 32_l2=0.0540
[218] time=6.80, avg_loss=0.0083, train_err=0.0665
Eval: 32_h1=0.1229, 32_l2=0.0537
[219] time=7.32, avg_loss=0.0082, train_err=0.0656
Eval: 32_h1=0.1229, 32_l2=0.0538
[220] time=7.81, avg_loss=0.0083, train_err=0.0666
Eval: 32_h1=0.1229, 32_l2=0.0537
[221] time=7.51, avg_loss=0.0085, train_err=0.0677
Eval: 32_h1=0.1229, 32_l2=0.0536
[222] time=6.09, avg_loss=0.0086, train_err=0.0689
Eval: 32_h1=0.1229, 32_l2=0.0537
[223] time=6.49, avg_loss=0.0086, train_err=0.0686
Eval: 32_h1=0.1229, 32_l2=0.0540
[224] time=6.88, avg_loss=0.0083, train_err=0.0662
Eval: 32_h1=0.1229, 32_l2=0.0539
[225] time=6.98, avg_loss=0.0086, train_err=0.0685
Eval: 32_h1=0.1231, 32_l2=0.0539
[226] time=8.35, avg_loss=0.0085, train_err=0.0682
Eval: 32_h1=0.1229, 32_l2=0.0538
[227] time=7.11, avg_loss=0.0084, train_err=0.0674
Eval: 32_h1=0.1230, 32_l2=0.0539
[228] time=6.34, avg_loss=0.0083, train_err=0.0662
Eval: 32_h1=0.1230, 32_l2=0.0537
[229] time=7.68, avg_loss=0.0083, train_err=0.0667
Eval: 32_h1=0.1230, 32_l2=0.0536
[230] time=7.55, avg_loss=0.0081, train_err=0.0650
Eval: 32_h1=0.1229, 32_l2=0.0539
[231] time=7.79, avg_loss=0.0079, train_err=0.0632
Eval: 32_h1=0.1231, 32_l2=0.0538
[232] time=7.54, avg_loss=0.0079, train_err=0.0632
Eval: 32_h1=0.1230, 32_l2=0.0538
[233] time=7.64, avg_loss=0.0079, train_err=0.0631
Eval: 32_h1=0.1230, 32_l2=0.0541
[234] time=6.43, avg_loss=0.0081, train_err=0.0649
Eval: 32_h1=0.1228, 32_l2=0.0537
[235] time=6.16, avg_loss=0.0082, train_err=0.0657
Eval: 32_h1=0.1231, 32_l2=0.0544
[236] time=7.22, avg_loss=0.0082, train_err=0.0655
Eval: 32_h1=0.1230, 32_l2=0.0540
[237] time=7.60, avg_loss=0.0086, train_err=0.0687
Eval: 32_h1=0.1230, 32_l2=0.0539
[238] time=6.50, avg_loss=0.0082, train_err=0.0658
Eval: 32_h1=0.1229, 32_l2=0.0536
[239] time=8.69, avg_loss=0.0082, train_err=0.0653
Eval: 32_h1=0.1229, 32_l2=0.0536
[240] time=7.59, avg_loss=0.0073, train_err=0.0583
Eval: 32_h1=0.1230, 32_l2=0.0540
[241] time=7.78, avg_loss=0.0065, train_err=0.0517
Eval: 32_h1=0.1229, 32_l2=0.0536
[242] time=7.84, avg_loss=0.0063, train_err=0.0501
Eval: 32_h1=0.1229, 32_l2=0.0537
[243] time=7.79, avg_loss=0.0062, train_err=0.0492
Eval: 32_h1=0.1229, 32_l2=0.0536
[244] time=7.12, avg_loss=0.0062, train_err=0.0493
Eval: 32_h1=0.1229, 32_l2=0.0537
[245] time=7.55, avg_loss=0.0061, train_err=0.0490
Eval: 32_h1=0.1229, 32_l2=0.0537
[246] time=8.67, avg_loss=0.0061, train_err=0.0487
Eval: 32_h1=0.1230, 32_l2=0.0537
[247] time=6.41, avg_loss=0.0061, train_err=0.0487
Eval: 32_h1=0.1229, 32_l2=0.0536
[248] time=6.60, avg_loss=0.0061, train_err=0.0491
Eval: 32_h1=0.1229, 32_l2=0.0536
[249] time=6.78, avg_loss=0.0062, train_err=0.0495
Eval: 32_h1=0.1229, 32_l2=0.0538
[250] time=7.79, avg_loss=0.0063, train_err=0.0503
Eval: 32_h1=0.1229, 32_l2=0.0536
[251] time=7.98, avg_loss=0.0063, train_err=0.0507
Eval: 32_h1=0.1229, 32_l2=0.0537
[252] time=9.00, avg_loss=0.0064, train_err=0.0511
Eval: 32_h1=0.1230, 32_l2=0.0539
[253] time=8.42, avg_loss=0.0065, train_err=0.0518
Eval: 32_h1=0.1229, 32_l2=0.0537
[254] time=7.78, avg_loss=0.0065, train_err=0.0524
Eval: 32_h1=0.1229, 32_l2=0.0535
[255] time=7.44, avg_loss=0.0069, train_err=0.0554
Eval: 32_h1=0.1230, 32_l2=0.0537
[256] time=7.94, avg_loss=0.0067, train_err=0.0535
Eval: 32_h1=0.1230, 32_l2=0.0539
[257] time=7.58, avg_loss=0.0065, train_err=0.0521
Eval: 32_h1=0.1230, 32_l2=0.0538
[258] time=8.97, avg_loss=0.0064, train_err=0.0512
Eval: 32_h1=0.1230, 32_l2=0.0537
[259] time=7.47, avg_loss=0.0065, train_err=0.0518
Eval: 32_h1=0.1230, 32_l2=0.0538
[260] time=7.51, avg_loss=0.0065, train_err=0.0520
Eval: 32_h1=0.1230, 32_l2=0.0537
[261] time=6.82, avg_loss=0.0063, train_err=0.0508
Eval: 32_h1=0.1229, 32_l2=0.0535
[262] time=7.54, avg_loss=0.0063, train_err=0.0505
Eval: 32_h1=0.1231, 32_l2=0.0539
[263] time=6.75, avg_loss=0.0063, train_err=0.0501
Eval: 32_h1=0.1229, 32_l2=0.0536
[264] time=6.57, avg_loss=0.0062, train_err=0.0497
Eval: 32_h1=0.1230, 32_l2=0.0538
[265] time=6.91, avg_loss=0.0063, train_err=0.0502
Eval: 32_h1=0.1230, 32_l2=0.0537
[266] time=7.70, avg_loss=0.0064, train_err=0.0508
Eval: 32_h1=0.1230, 32_l2=0.0538
[267] time=6.86, avg_loss=0.0063, train_err=0.0504
Eval: 32_h1=0.1230, 32_l2=0.0535
[268] time=8.07, avg_loss=0.0064, train_err=0.0512
Eval: 32_h1=0.1230, 32_l2=0.0537
[269] time=8.31, avg_loss=0.0064, train_err=0.0512
Eval: 32_h1=0.1230, 32_l2=0.0538
[270] time=8.39, avg_loss=0.0062, train_err=0.0498
Eval: 32_h1=0.1230, 32_l2=0.0538
[271] time=7.78, avg_loss=0.0063, train_err=0.0508
Eval: 32_h1=0.1230, 32_l2=0.0537
[272] time=7.05, avg_loss=0.0063, train_err=0.0505
Eval: 32_h1=0.1231, 32_l2=0.0538
[273] time=7.43, avg_loss=0.0064, train_err=0.0510
Eval: 32_h1=0.1230, 32_l2=0.0536
[274] time=7.42, avg_loss=0.0063, train_err=0.0502
Eval: 32_h1=0.1231, 32_l2=0.0538
[275] time=8.03, avg_loss=0.0062, train_err=0.0498
Eval: 32_h1=0.1230, 32_l2=0.0536
[276] time=6.97, avg_loss=0.0063, train_err=0.0506
Eval: 32_h1=0.1230, 32_l2=0.0536
[277] time=7.91, avg_loss=0.0062, train_err=0.0492
Eval: 32_h1=0.1231, 32_l2=0.0537
[278] time=8.17, avg_loss=0.0062, train_err=0.0495
Eval: 32_h1=0.1231, 32_l2=0.0537
[279] time=8.51, avg_loss=0.0062, train_err=0.0500
Eval: 32_h1=0.1231, 32_l2=0.0539
[280] time=7.45, avg_loss=0.0062, train_err=0.0494
Eval: 32_h1=0.1230, 32_l2=0.0536
[281] time=7.67, avg_loss=0.0062, train_err=0.0492
Eval: 32_h1=0.1231, 32_l2=0.0537
[282] time=8.33, avg_loss=0.0063, train_err=0.0505
Eval: 32_h1=0.1231, 32_l2=0.0538
[283] time=8.81, avg_loss=0.0063, train_err=0.0501
Eval: 32_h1=0.1231, 32_l2=0.0536
[284] time=8.29, avg_loss=0.0063, train_err=0.0501
Eval: 32_h1=0.1231, 32_l2=0.0537
[285] time=7.67, avg_loss=0.0062, train_err=0.0495
Eval: 32_h1=0.1230, 32_l2=0.0535
[286] time=6.56, avg_loss=0.0061, train_err=0.0488
Eval: 32_h1=0.1231, 32_l2=0.0538
[287] time=8.15, avg_loss=0.0060, train_err=0.0482
Eval: 32_h1=0.1230, 32_l2=0.0537
[288] time=6.30, avg_loss=0.0060, train_err=0.0480
Eval: 32_h1=0.1231, 32_l2=0.0539
[289] time=7.18, avg_loss=0.0062, train_err=0.0499
Eval: 32_h1=0.1231, 32_l2=0.0538
[290] time=7.81, avg_loss=0.0062, train_err=0.0498
Eval: 32_h1=0.1231, 32_l2=0.0537
[291] time=8.25, avg_loss=0.0061, train_err=0.0492
Eval: 32_h1=0.1231, 32_l2=0.0537
[292] time=8.66, avg_loss=0.0061, train_err=0.0487
Eval: 32_h1=0.1231, 32_l2=0.0537
[293] time=8.04, avg_loss=0.0060, train_err=0.0481
Eval: 32_h1=0.1231, 32_l2=0.0537
[294] time=7.69, avg_loss=0.0060, train_err=0.0477
Eval: 32_h1=0.1230, 32_l2=0.0536
[295] time=6.85, avg_loss=0.0060, train_err=0.0479
Eval: 32_h1=0.1231, 32_l2=0.0536
[296] time=7.25, avg_loss=0.0060, train_err=0.0478
Eval: 32_h1=0.1231, 32_l2=0.0537
[297] time=7.58, avg_loss=0.0061, train_err=0.0488
Eval: 32_h1=0.1231, 32_l2=0.0538
[298] time=6.71, avg_loss=0.0060, train_err=0.0477
Eval: 32_h1=0.1232, 32_l2=0.0537
[299] time=7.83, avg_loss=0.0062, train_err=0.0493
Eval: 32_h1=0.1230, 32_l2=0.0537
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_131957__L8FNO421.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/Darcy_pt', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 421, 'n_tests': [224], 'test_resolutions': [421], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 421 with 224 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f15772f18e0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f15772c5760>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f15772c5760>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f15772c5730>}

### Beginning Training...


n_params: 138496577
Training on 800 samples
Testing on [224] samples         on resolutions [421].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 421, 421])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260128_132012__L8FNOT50.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_medium2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 4, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.0003, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 100, 'gamma': 0.5, 'n_epochs': 600}, 'data': {'_config_name': 'navierstokesdatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/V1e-3_N5000_T50', 'batch_size': 24, 'n_train': 10000, 'train_resolution': 128, 'n_tests': [2000], 'test_resolutions': [128], 'test_batch_sizes': [24], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'ns128_hc_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 128 with 2000 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f26fff5c4f0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f26fd9fe400>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f26fd9fe400>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f26fd9fe3d0>}

### Beginning Training...


n_params: 138505025
Training on 10000 samples
Testing on [2000] samples         on resolutions [128].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([24, 1, 128, 128])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=78.09, avg_loss=0.4010, train_err=3.2081
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 421_h1=0.1438, 421_l2=0.0847
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260128_132137__L8HC2T50.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_medium2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 4, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.0003, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 100, 'gamma': 0.5, 'n_epochs': 600}, 'data': {'_config_name': 'navierstokesdatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/V1e-3_N5000_T50', 'batch_size': 24, 'n_train': 10000, 'train_resolution': 128, 'n_tests': [2000], 'test_resolutions': [128], 'test_batch_sizes': [24], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'ns128_hc_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 128 with 2000 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 64, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f78ac9cc820>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f78ac9cc9d0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f78ac9cc9d0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f78ac9cca00>}

### Beginning Training...


n_params: 138510225
Training on 10000 samples
Testing on [2000] samples         on resolutions [128].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([24, 1, 128, 128])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=107.49, avg_loss=0.2036, train_err=4.8823
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 128_h1=0.0970, 128_l2=0.0775
[1] time=75.21, avg_loss=0.1383, train_err=1.1062
Eval: 421_h1=0.1081, 421_l2=0.0749
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_132444__L8FNO421.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [32, 32], 'hidden_channels': 32, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/Darcy_pt', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 421, 'n_tests': [224], 'test_resolutions': [421], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 421 with 224 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 32, 17]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7fe5e0f158e0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7fe5e0eea760>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7fe5e0eea760>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7fe5e0eea730>}

### Beginning Training...


n_params: 8934689
Training on 800 samples
Testing on [224] samples         on resolutions [421].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 421, 421])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=36.86, avg_loss=0.3977, train_err=3.1817
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 421_h1=0.1851, 421_l2=0.0892
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_132546__L8HC2_421.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [32, 32], 'hidden_channels': 32, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/Darcy_pt', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 421, 'n_tests': [224], 'test_resolutions': [421], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 421 with 224 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 32, 17]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f15a767b8e0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f15a764f760>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f15a764f760>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f15a764f730>}

### Beginning Training...


n_params: 8934689
Training on 800 samples
Testing on [224] samples         on resolutions [421].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 421, 421])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[1] time=51.93, avg_loss=0.1478, train_err=1.1824
Eval: 421_h1=0.1382, 421_l2=0.0834
[1] time=256.63, avg_loss=0.0810, train_err=1.9433
Eval: 128_h1=0.0693, 128_l2=0.0528
[0] time=84.72, avg_loss=0.4110, train_err=3.2884
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 421_h1=0.1644, 421_l2=0.0883
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260128_132738__L8FNOT50.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_medium2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 4, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 0, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.0003, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 100, 'gamma': 0.5, 'n_epochs': 600}, 'data': {'_config_name': 'navierstokesdatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/V1e-3_N5000_T50', 'batch_size': 24, 'n_train': 10000, 'train_resolution': 128, 'n_tests': [2000], 'test_resolutions': [128], 'test_batch_sizes': [24], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'ns128_hc_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 128 with 2000 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f4a29b5f4f0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f4a29616400>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f4a29616400>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f4a296163d0>}

### Beginning Training...


n_params: 138505025
Training on 10000 samples
Testing on [2000] samples         on resolutions [128].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([24, 1, 128, 128])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[2] time=81.73, avg_loss=0.1218, train_err=0.9742
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260128_132800__L8HC2T50.log
Eval: 421_h1=0.1276, 421_l2=0.0817
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_medium2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 4, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.0003, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 100, 'gamma': 0.5, 'n_epochs': 600}, 'data': {'_config_name': 'navierstokesdatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/V1e-3_N5000_T50', 'batch_size': 24, 'n_train': 10000, 'train_resolution': 128, 'n_tests': [2000], 'test_resolutions': [128], 'test_batch_sizes': [24], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'ns128_hc_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 128 with 2000 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 64, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f0b321267c0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f0b32126970>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f0b32126970>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f0b321269a0>}

### Beginning Training...


n_params: 138510225
Training on 10000 samples
Testing on [2000] samples         on resolutions [128].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([24, 1, 128, 128])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[1] time=81.13, avg_loss=0.1535, train_err=1.2280
Eval: 421_h1=0.1436, 421_l2=0.0837
[3] time=75.49, avg_loss=0.1157, train_err=0.9259
Eval: 421_h1=0.1222, 421_l2=0.0843
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260128_132933__L8HC2_421.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [32, 32], 'hidden_channels': 32, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/Darcy_pt', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 421, 'n_tests': [224], 'test_resolutions': [421], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 421 with 224 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 32, 17]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 32, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(32, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f5b8ed887f0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f5b8ed88d90>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f5b8ed88d90>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f5b8ed88dc0>}

### Beginning Training...


n_params: 8937329
Training on 800 samples
Testing on [224] samples         on resolutions [421].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 421, 421])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[4] time=57.54, avg_loss=0.1005, train_err=0.8041
Eval: 421_h1=0.0918, 421_l2=0.0629
[0] time=210.74, avg_loss=0.2015, train_err=4.8328
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 128_h1=0.1003, 128_l2=0.0697
[5] time=82.12, avg_loss=0.0919, train_err=0.7350
Eval: 421_h1=0.1068, 421_l2=0.0684
[6] time=82.12, avg_loss=0.0846, train_err=0.6767
Eval: 421_h1=0.0816, 421_l2=0.0582
[0] time=308.22, avg_loss=0.3154, train_err=2.5231
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
[7] time=81.87, avg_loss=0.0844, train_err=0.6756
Eval: 421_h1=0.0838, 421_l2=0.0586
Eval: 421_h1=0.1892, 421_l2=0.0977
[1] time=265.04, avg_loss=0.0819, train_err=1.9649
Eval: 128_h1=0.0690, 128_l2=0.0516
[0] time=488.58, avg_loss=0.1230, train_err=2.9490
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
[8] time=81.87, avg_loss=0.0769, train_err=0.6155
Eval: 421_h1=0.0781, 421_l2=0.0537
Eval: 128_h1=0.0794, 128_l2=0.0544
[9] time=82.10, avg_loss=0.0744, train_err=0.5950
Eval: 421_h1=0.0749, 421_l2=0.0514
[10] time=82.15, avg_loss=0.0752, train_err=0.6013
Eval: 421_h1=0.0858, 421_l2=0.0591
[1] time=304.63, avg_loss=0.1541, train_err=1.2328
[2] time=249.57, avg_loss=0.0620, train_err=1.4876
Eval: 128_h1=0.0564, 128_l2=0.0419
Eval: 421_h1=0.1426, 421_l2=0.0769
[11] time=81.60, avg_loss=0.0719, train_err=0.5751
Eval: 421_h1=0.0900, 421_l2=0.0616
[12] time=82.09, avg_loss=0.0677, train_err=0.5413
Eval: 421_h1=0.0704, 421_l2=0.0470
[13] time=82.09, avg_loss=0.0701, train_err=0.5605
Eval: 421_h1=0.0870, 421_l2=0.0522
[1] time=470.42, avg_loss=0.0698, train_err=1.6731
[3] time=254.58, avg_loss=0.0516, train_err=1.2377
Eval: 128_h1=0.0612, 128_l2=0.0494
Eval: 128_h1=0.0493, 128_l2=0.0373
[14] time=82.12, avg_loss=0.0671, train_err=0.5368
Eval: 421_h1=0.0727, 421_l2=0.0446
[2] time=304.22, avg_loss=0.1283, train_err=1.0263
Eval: 421_h1=0.1282, 421_l2=0.0669
[15] time=81.50, avg_loss=0.0669, train_err=0.5348
Eval: 421_h1=0.0929, 421_l2=0.0534
[16] time=82.12, avg_loss=0.0699, train_err=0.5592
Eval: 421_h1=0.0687, 421_l2=0.0373
[4] time=255.81, avg_loss=0.0450, train_err=1.0796
Eval: 128_h1=0.0446, 128_l2=0.0348
[17] time=82.13, avg_loss=0.0612, train_err=0.4898
Eval: 421_h1=0.0747, 421_l2=0.0438
[18] time=82.14, avg_loss=0.0613, train_err=0.4904
[3] time=304.33, avg_loss=0.1152, train_err=0.9213
Eval: 421_h1=0.0704, 421_l2=0.0355
Eval: 421_h1=0.1100, 421_l2=0.0649
[19] time=81.80, avg_loss=0.0594, train_err=0.4755
[2] time=478.51, avg_loss=0.0583, train_err=1.3972
Eval: 421_h1=0.0666, 421_l2=0.0285
Eval: 128_h1=0.0545, 128_l2=0.0476
[5] time=256.62, avg_loss=0.0402, train_err=0.9649
Eval: 128_h1=0.0409, 128_l2=0.0328
[20] time=82.16, avg_loss=0.0589, train_err=0.4710
Eval: 421_h1=0.0668, 421_l2=0.0270
[21] time=82.10, avg_loss=0.0606, train_err=0.4847
Eval: 421_h1=0.0688, 421_l2=0.0303
[4] time=304.77, avg_loss=0.1073, train_err=0.8587
[22] time=81.87, avg_loss=0.0592, train_err=0.4737
Eval: 421_h1=0.0979, 421_l2=0.0523
Eval: 421_h1=0.0700, 421_l2=0.0337
[6] time=261.37, avg_loss=0.0366, train_err=0.8786
Eval: 128_h1=0.0382, 128_l2=0.0312
[23] time=82.12, avg_loss=0.0678, train_err=0.5421
Eval: 421_h1=0.0733, 421_l2=0.0284
[24] time=82.13, avg_loss=0.0564, train_err=0.4511
Eval: 421_h1=0.0670, 421_l2=0.0223
[3] time=480.65, avg_loss=0.0515, train_err=1.2345
Eval: 128_h1=0.0476, 128_l2=0.0427
[25] time=82.14, avg_loss=0.0600, train_err=0.4797
Eval: 421_h1=0.0662, 421_l2=0.0233
[5] time=304.46, avg_loss=0.0981, train_err=0.7849
[7] time=248.99, avg_loss=0.0338, train_err=0.8108
Eval: 421_h1=0.1041, 421_l2=0.0547
Eval: 128_h1=0.0362, 128_l2=0.0299
[26] time=81.51, avg_loss=0.0569, train_err=0.4553
Eval: 421_h1=0.0709, 421_l2=0.0293
[27] time=82.15, avg_loss=0.0538, train_err=0.4302
Eval: 421_h1=0.0660, 421_l2=0.0204
[28] time=82.10, avg_loss=0.0516, train_err=0.4127
Eval: 421_h1=0.0678, 421_l2=0.0226
[8] time=256.20, avg_loss=0.0315, train_err=0.7549
Eval: 128_h1=0.0343, 128_l2=0.0286
[29] time=82.13, avg_loss=0.0548, train_err=0.4380
[6] time=304.46, avg_loss=0.0915, train_err=0.7319
Eval: 421_h1=0.0665, 421_l2=0.0211
Eval: 421_h1=0.0943, 421_l2=0.0448
[30] time=81.83, avg_loss=0.0517, train_err=0.4137
Eval: 421_h1=0.0677, 421_l2=0.0196
[4] time=481.45, avg_loss=0.0467, train_err=1.1197
Eval: 128_h1=0.0439, 128_l2=0.0405
[31] time=82.14, avg_loss=0.0507, train_err=0.4054
Eval: 421_h1=0.0692, 421_l2=0.0214
[9] time=261.93, avg_loss=0.0295, train_err=0.7074
Eval: 128_h1=0.0323, 128_l2=0.0268
[32] time=82.14, avg_loss=0.0540, train_err=0.4317
Eval: 421_h1=0.0705, 421_l2=0.0225
[7] time=304.67, avg_loss=0.0866, train_err=0.6926
[33] time=81.88, avg_loss=0.0530, train_err=0.4239
Eval: 421_h1=0.0735, 421_l2=0.0341
Eval: 421_h1=0.0876, 421_l2=0.0429
[34] time=81.87, avg_loss=0.0517, train_err=0.4138
Eval: 421_h1=0.0684, 421_l2=0.0260
[10] time=253.53, avg_loss=0.0278, train_err=0.6672
Eval: 128_h1=0.0302, 128_l2=0.0247
[35] time=82.16, avg_loss=0.0540, train_err=0.4317
Eval: 421_h1=0.0660, 421_l2=0.0171
[5] time=476.28, avg_loss=0.0430, train_err=1.0316
[36] time=82.15, avg_loss=0.0531, train_err=0.4245
Eval: 421_h1=0.0715, 421_l2=0.0258
Eval: 128_h1=0.0416, 128_l2=0.0393
[8] time=304.77, avg_loss=0.0847, train_err=0.6779
Eval: 421_h1=0.1077, 421_l2=0.0640
[37] time=81.53, avg_loss=0.0490, train_err=0.3919
Eval: 421_h1=0.0667, 421_l2=0.0176
[11] time=252.39, avg_loss=0.0265, train_err=0.6353
Eval: 128_h1=0.0292, 128_l2=0.0243
[38] time=82.12, avg_loss=0.0483, train_err=0.3865
Eval: 421_h1=0.0676, 421_l2=0.0178
[39] time=82.18, avg_loss=0.0493, train_err=0.3942
Eval: 421_h1=0.0711, 421_l2=0.0265
[40] time=82.08, avg_loss=0.0517, train_err=0.4137
Eval: 421_h1=0.0692, 421_l2=0.0220
[9] time=304.01, avg_loss=0.0866, train_err=0.6926
Eval: 421_h1=0.0905, 421_l2=0.0438
[12] time=257.35, avg_loss=0.0257, train_err=0.6152
Eval: 128_h1=0.0265, 128_l2=0.0231
[41] time=81.55, avg_loss=0.0491, train_err=0.3930
Eval: 421_h1=0.0696, 421_l2=0.0246
[6] time=478.51, avg_loss=0.0398, train_err=0.9548
Eval: 128_h1=0.0409, 128_l2=0.0394
[42] time=82.14, avg_loss=0.0485, train_err=0.3881
Eval: 421_h1=0.0745, 421_l2=0.0294
[43] time=82.06, avg_loss=0.0484, train_err=0.3869
Eval: 421_h1=0.0693, 421_l2=0.0209
[13] time=253.38, avg_loss=0.0244, train_err=0.5850
Eval: 128_h1=0.0248, 128_l2=0.0215
[10] time=304.81, avg_loss=0.0752, train_err=0.6014
[44] time=81.81, avg_loss=0.0489, train_err=0.3915
Eval: 421_h1=0.0908, 421_l2=0.0363
Eval: 421_h1=0.0863, 421_l2=0.0415
[45] time=81.82, avg_loss=0.0518, train_err=0.4141
Eval: 421_h1=0.0690, 421_l2=0.0178
[46] time=82.10, avg_loss=0.0465, train_err=0.3718
Eval: 421_h1=0.0661, 421_l2=0.0144
[14] time=265.05, avg_loss=0.0235, train_err=0.5629
Eval: 128_h1=0.0249, 128_l2=0.0201
[47] time=82.15, avg_loss=0.0444, train_err=0.3554
Eval: 421_h1=0.0654, 421_l2=0.0154
[7] time=490.91, avg_loss=0.0375, train_err=0.9005
Eval: 128_h1=0.0397, 128_l2=0.0383
[11] time=304.71, avg_loss=0.0764, train_err=0.6108
Eval: 421_h1=0.0883, 421_l2=0.0398
[48] time=81.59, avg_loss=0.0448, train_err=0.3588
Eval: 421_h1=0.0659, 421_l2=0.0164
[49] time=82.09, avg_loss=0.0469, train_err=0.3750
Eval: 421_h1=0.0681, 421_l2=0.0165
[15] time=250.52, avg_loss=0.0225, train_err=0.5402
Eval: 128_h1=0.0252, 128_l2=0.0203
[50] time=82.12, avg_loss=0.0484, train_err=0.3875
Eval: 421_h1=0.0753, 421_l2=0.0314
[51] time=82.09, avg_loss=0.0492, train_err=0.3935
Eval: 421_h1=0.0776, 421_l2=0.0303
[12] time=304.14, avg_loss=0.0718, train_err=0.5744
Eval: 421_h1=0.0794, 421_l2=0.0348
[52] time=81.49, avg_loss=0.0460, train_err=0.3680
Eval: 421_h1=0.0675, 421_l2=0.0179
[16] time=256.05, avg_loss=0.0214, train_err=0.5138
[8] time=472.38, avg_loss=0.0357, train_err=0.8551
Eval: 128_h1=0.0225, 128_l2=0.0186
Eval: 128_h1=0.0381, 128_l2=0.0367
[53] time=82.13, avg_loss=0.0431, train_err=0.3448
Eval: 421_h1=0.0653, 421_l2=0.0137
[54] time=82.10, avg_loss=0.0460, train_err=0.3678
Eval: 421_h1=0.0672, 421_l2=0.0166
[13] time=304.76, avg_loss=0.0706, train_err=0.5649
[55] time=81.81, avg_loss=0.0441, train_err=0.3525
Eval: 421_h1=0.0721, 421_l2=0.0220
Eval: 421_h1=0.0798, 421_l2=0.0336
[17] time=262.83, avg_loss=0.0205, train_err=0.4924
Eval: 128_h1=0.0219, 128_l2=0.0184
[56] time=81.85, avg_loss=0.0462, train_err=0.3694
Eval: 421_h1=0.0671, 421_l2=0.0143
[57] time=82.19, avg_loss=0.0427, train_err=0.3414
Eval: 421_h1=0.0667, 421_l2=0.0158
[58] time=82.12, avg_loss=0.0436, train_err=0.3487
Eval: 421_h1=0.0668, 421_l2=0.0161
[9] time=488.80, avg_loss=0.0341, train_err=0.8169
[14] time=304.59, avg_loss=0.0701, train_err=0.5607
Eval: 128_h1=0.0368, 128_l2=0.0354
[18] time=253.17, avg_loss=0.0199, train_err=0.4770
Eval: 128_h1=0.0215, 128_l2=0.0180
Eval: 421_h1=0.0823, 421_l2=0.0368
[59] time=81.52, avg_loss=0.0477, train_err=0.3816
Eval: 421_h1=0.0719, 421_l2=0.0251
[60] time=82.15, avg_loss=0.0390, train_err=0.3116
Eval: 421_h1=0.0645, 421_l2=0.0132
[61] time=82.12, avg_loss=0.0353, train_err=0.2826
Eval: 421_h1=0.0643, 421_l2=0.0112
[19] time=251.22, avg_loss=0.0193, train_err=0.4634
Eval: 128_h1=0.0210, 128_l2=0.0176
[62] time=82.11, avg_loss=0.0351, train_err=0.2810
Eval: 421_h1=0.0651, 421_l2=0.0149
[15] time=304.14, avg_loss=0.0681, train_err=0.5450
Eval: 421_h1=0.0766, 421_l2=0.0287
[63] time=81.52, avg_loss=0.0356, train_err=0.2844
Eval: 421_h1=0.0663, 421_l2=0.0138
[10] time=468.72, avg_loss=0.0329, train_err=0.7887
[64] time=82.08, avg_loss=0.0349, train_err=0.2789
Eval: 421_h1=0.0645, 421_l2=0.0113
Eval: 128_h1=0.0348, 128_l2=0.0332
[20] time=255.49, avg_loss=0.0189, train_err=0.4524
Eval: 128_h1=0.0211, 128_l2=0.0172
[65] time=82.10, avg_loss=0.0348, train_err=0.2787
Eval: 421_h1=0.0647, 421_l2=0.0112
[16] time=304.75, avg_loss=0.0694, train_err=0.5555
[66] time=81.87, avg_loss=0.0345, train_err=0.2758
Eval: 421_h1=0.0650, 421_l2=0.0111
Eval: 421_h1=0.0859, 421_l2=0.0383
[67] time=81.84, avg_loss=0.0340, train_err=0.2718
Eval: 421_h1=0.0647, 421_l2=0.0105
[21] time=259.71, avg_loss=0.0188, train_err=0.4519
Eval: 128_h1=0.0283, 128_l2=0.0234
[68] time=82.08, avg_loss=0.0343, train_err=0.2746
Eval: 421_h1=0.0650, 421_l2=0.0118
[69] time=82.11, avg_loss=0.0345, train_err=0.2760
Eval: 421_h1=0.0657, 421_l2=0.0113
[11] time=482.13, avg_loss=0.0314, train_err=0.7521
[17] time=304.68, avg_loss=0.0651, train_err=0.5212
Eval: 128_h1=0.0337, 128_l2=0.0318
[70] time=81.84, avg_loss=0.0343, train_err=0.2741
Eval: 421_h1=0.0775, 421_l2=0.0273
Eval: 421_h1=0.0647, 421_l2=0.0125
[22] time=249.84, avg_loss=0.0198, train_err=0.4742
Eval: 128_h1=0.0192, 128_l2=0.0158
[71] time=82.14, avg_loss=0.0345, train_err=0.2756
Eval: 421_h1=0.0656, 421_l2=0.0137
[72] time=82.14, avg_loss=0.0342, train_err=0.2732
Eval: 421_h1=0.0656, 421_l2=0.0134
[73] time=82.12, avg_loss=0.0341, train_err=0.2732
Eval: 421_h1=0.0658, 421_l2=0.0132
[18] time=304.43, avg_loss=0.0607, train_err=0.4858
[23] time=253.46, avg_loss=0.0179, train_err=0.4302
Eval: 421_h1=0.0725, 421_l2=0.0271
Eval: 128_h1=0.0190, 128_l2=0.0157
[74] time=81.57, avg_loss=0.0347, train_err=0.2774
Eval: 421_h1=0.0669, 421_l2=0.0161
[75] time=82.08, avg_loss=0.0363, train_err=0.2907
[12] time=473.43, avg_loss=0.0298, train_err=0.7148
Eval: 421_h1=0.0662, 421_l2=0.0119
Eval: 128_h1=0.0318, 128_l2=0.0291
[76] time=82.14, avg_loss=0.0342, train_err=0.2736
Eval: 421_h1=0.0655, 421_l2=0.0115
[24] time=255.25, avg_loss=0.0172, train_err=0.4121
Eval: 128_h1=0.0208, 128_l2=0.0170
[77] time=82.10, avg_loss=0.0342, train_err=0.2738
[19] time=304.44, avg_loss=0.0681, train_err=0.5451
Eval: 421_h1=0.0655, 421_l2=0.0113
Eval: 421_h1=0.0817, 421_l2=0.0356
[78] time=81.80, avg_loss=0.0342, train_err=0.2733
Eval: 421_h1=0.0660, 421_l2=0.0114
[79] time=82.11, avg_loss=0.0352, train_err=0.2817
Eval: 421_h1=0.0673, 421_l2=0.0131
[25] time=263.82, avg_loss=0.0170, train_err=0.4073
Eval: 128_h1=0.0206, 128_l2=0.0168
[80] time=82.10, avg_loss=0.0348, train_err=0.2784
Eval: 421_h1=0.0660, 421_l2=0.0149
[13] time=492.46, avg_loss=0.0286, train_err=0.6862
[20] time=304.71, avg_loss=0.0586, train_err=0.4689
[81] time=81.81, avg_loss=0.0335, train_err=0.2678
Eval: 128_h1=0.0308, 128_l2=0.0277
Eval: 421_h1=0.0739, 421_l2=0.0288
Eval: 421_h1=0.0658, 421_l2=0.0118
[82] time=82.14, avg_loss=0.0333, train_err=0.2664
Eval: 421_h1=0.0665, 421_l2=0.0132
[26] time=251.25, avg_loss=0.0169, train_err=0.4061
Eval: 128_h1=0.0193, 128_l2=0.0158
[83] time=82.14, avg_loss=0.0338, train_err=0.2702
Eval: 421_h1=0.0664, 421_l2=0.0123
[84] time=82.12, avg_loss=0.0341, train_err=0.2729
Eval: 421_h1=0.0679, 421_l2=0.0150
[21] time=304.38, avg_loss=0.0617, train_err=0.4935
Eval: 421_h1=0.0806, 421_l2=0.0322
[85] time=81.51, avg_loss=0.0344, train_err=0.2753
Eval: 421_h1=0.0679, 421_l2=0.0155
[27] time=251.29, avg_loss=0.0165, train_err=0.3967
Eval: 128_h1=0.0187, 128_l2=0.0154
[86] time=82.09, avg_loss=0.0346, train_err=0.2766
Eval: 421_h1=0.0663, 421_l2=0.0107
[14] time=464.19, avg_loss=0.0274, train_err=0.6559
Eval: 128_h1=0.0289, 128_l2=0.0263
[87] time=82.09, avg_loss=0.0343, train_err=0.2747
Eval: 421_h1=0.0670, 421_l2=0.0124
[88] time=82.12, avg_loss=0.0331, train_err=0.2646
Eval: 421_h1=0.0663, 421_l2=0.0111
[22] time=304.18, avg_loss=0.0591, train_err=0.4727
Eval: 421_h1=0.0753, 421_l2=0.0269
[28] time=256.29, avg_loss=0.0163, train_err=0.3916
Eval: 128_h1=0.0176, 128_l2=0.0145
[89] time=81.52, avg_loss=0.0327, train_err=0.2615
Eval: 421_h1=0.0660, 421_l2=0.0107
[90] time=82.10, avg_loss=0.0349, train_err=0.2793
Eval: 421_h1=0.0688, 421_l2=0.0173
[91] time=82.10, avg_loss=0.0336, train_err=0.2689
Eval: 421_h1=0.0669, 421_l2=0.0141
[29] time=261.22, avg_loss=0.0163, train_err=0.3913
Eval: 128_h1=0.0189, 128_l2=0.0160
[23] time=304.68, avg_loss=0.0603, train_err=0.4826
[15] time=490.60, avg_loss=0.0264, train_err=0.6335
[92] time=81.82, avg_loss=0.0325, train_err=0.2599
Eval: 421_h1=0.0660, 421_l2=0.0111
Eval: 421_h1=0.0734, 421_l2=0.0231
Eval: 128_h1=0.0284, 128_l2=0.0253
[93] time=81.83, avg_loss=0.0325, train_err=0.2601
Eval: 421_h1=0.0668, 421_l2=0.0112
[94] time=82.15, avg_loss=0.0323, train_err=0.2585
Eval: 421_h1=0.0667, 421_l2=0.0139
[30] time=250.57, avg_loss=0.0165, train_err=0.3954
Eval: 128_h1=0.0216, 128_l2=0.0191
[95] time=82.15, avg_loss=0.0329, train_err=0.2633
Eval: 421_h1=0.0669, 421_l2=0.0121
[24] time=304.71, avg_loss=0.0647, train_err=0.5175
Eval: 421_h1=0.0796, 421_l2=0.0347
[96] time=81.53, avg_loss=0.0329, train_err=0.2628
Eval: 421_h1=0.0659, 421_l2=0.0108
[97] time=82.10, avg_loss=0.0335, train_err=0.2681
Eval: 421_h1=0.0700, 421_l2=0.0193
[16] time=467.79, avg_loss=0.0257, train_err=0.6156
[31] time=252.13, avg_loss=0.0151, train_err=0.3612
Eval: 128_h1=0.0276, 128_l2=0.0243
Eval: 128_h1=0.0162, 128_l2=0.0135
[98] time=82.12, avg_loss=0.0329, train_err=0.2636
Eval: 421_h1=0.0665, 421_l2=0.0116
[99] time=82.13, avg_loss=0.0316, train_err=0.2531
Eval: 421_h1=0.0667, 421_l2=0.0108
[25] time=304.08, avg_loss=0.0565, train_err=0.4521
Eval: 421_h1=0.0713, 421_l2=0.0233
[100] time=81.55, avg_loss=0.0313, train_err=0.2505
Eval: 421_h1=0.0670, 421_l2=0.0139
[32] time=262.78, avg_loss=0.0148, train_err=0.3541
Eval: 128_h1=0.0160, 128_l2=0.0133
[101] time=82.08, avg_loss=0.0317, train_err=0.2538
Eval: 421_h1=0.0680, 421_l2=0.0143
[102] time=82.13, avg_loss=0.0328, train_err=0.2622
Eval: 421_h1=0.0672, 421_l2=0.0139
[26] time=304.69, avg_loss=0.0566, train_err=0.4527
[103] time=81.84, avg_loss=0.0319, train_err=0.2555
[17] time=487.45, avg_loss=0.0251, train_err=0.6029
Eval: 421_h1=0.0675, 421_l2=0.0114
Eval: 421_h1=0.0725, 421_l2=0.0207
Eval: 128_h1=0.0268, 128_l2=0.0234
[33] time=252.17, avg_loss=0.0145, train_err=0.3482
Eval: 128_h1=0.0158, 128_l2=0.0134
[104] time=81.86, avg_loss=0.0338, train_err=0.2706
Eval: 421_h1=0.0674, 421_l2=0.0125
[105] time=82.11, avg_loss=0.0332, train_err=0.2654
Eval: 421_h1=0.0668, 421_l2=0.0117
[106] time=82.11, avg_loss=0.0325, train_err=0.2597
Eval: 421_h1=0.0674, 421_l2=0.0121
[34] time=255.14, avg_loss=0.0141, train_err=0.3384
[27] time=304.61, avg_loss=0.0574, train_err=0.4593
Eval: 128_h1=0.0159, 128_l2=0.0135
Eval: 421_h1=0.0742, 421_l2=0.0228
[107] time=81.57, avg_loss=0.0307, train_err=0.2452
Eval: 421_h1=0.0672, 421_l2=0.0115
[108] time=82.13, avg_loss=0.0310, train_err=0.2483
Eval: 421_h1=0.0671, 421_l2=0.0112
[18] time=472.95, avg_loss=0.0246, train_err=0.5902
Eval: 128_h1=0.0266, 128_l2=0.0228
[109] time=82.14, avg_loss=0.0306, train_err=0.2446
Eval: 421_h1=0.0677, 421_l2=0.0132
[35] time=253.41, avg_loss=0.0140, train_err=0.3361
Eval: 128_h1=0.0156, 128_l2=0.0128
[110] time=82.16, avg_loss=0.0324, train_err=0.2592
Eval: 421_h1=0.0674, 421_l2=0.0127
[28] time=304.04, avg_loss=0.0575, train_err=0.4604
Eval: 421_h1=0.0712, 421_l2=0.0213
[111] time=81.59, avg_loss=0.0314, train_err=0.2515
Eval: 421_h1=0.0669, 421_l2=0.0114
[112] time=82.16, avg_loss=0.0312, train_err=0.2497
Eval: 421_h1=0.0669, 421_l2=0.0109
[36] time=263.39, avg_loss=0.0142, train_err=0.3412
Eval: 128_h1=0.0161, 128_l2=0.0133
[113] time=82.14, avg_loss=0.0315, train_err=0.2522
Eval: 421_h1=0.0679, 421_l2=0.0120
[29] time=304.53, avg_loss=0.0524, train_err=0.4189
[114] time=81.92, avg_loss=0.0318, train_err=0.2542
Eval: 421_h1=0.0670, 421_l2=0.0113
[19] time=484.45, avg_loss=0.0235, train_err=0.5630
Eval: 421_h1=0.0694, 421_l2=0.0191
Eval: 128_h1=0.0259, 128_l2=0.0222
[115] time=81.83, avg_loss=0.0307, train_err=0.2459
Eval: 421_h1=0.0674, 421_l2=0.0110
[37] time=246.90, avg_loss=0.0152, train_err=0.3646
Eval: 128_h1=0.0160, 128_l2=0.0132
[116] time=82.14, avg_loss=0.0302, train_err=0.2419
Eval: 421_h1=0.0689, 421_l2=0.0130
[117] time=82.13, avg_loss=0.0321, train_err=0.2565
Eval: 421_h1=0.0672, 421_l2=0.0116
[30] time=304.61, avg_loss=0.0531, train_err=0.4245
Eval: 421_h1=0.0713, 421_l2=0.0211
[118] time=81.62, avg_loss=0.0318, train_err=0.2547
Eval: 421_h1=0.0686, 421_l2=0.0170
[38] time=252.64, avg_loss=0.0147, train_err=0.3528
Eval: 128_h1=0.0150, 128_l2=0.0121
[119] time=82.15, avg_loss=0.0308, train_err=0.2463
Eval: 421_h1=0.0670, 421_l2=0.0113
[20] time=468.33, avg_loss=0.0229, train_err=0.5486
Eval: 128_h1=0.0255, 128_l2=0.0216
[120] time=82.16, avg_loss=0.0283, train_err=0.2267
Eval: 421_h1=0.0665, 421_l2=0.0097
[121] time=82.13, avg_loss=0.0269, train_err=0.2153
Eval: 421_h1=0.0668, 421_l2=0.0097
[31] time=303.97, avg_loss=0.0537, train_err=0.4298
[39] time=257.57, avg_loss=0.0142, train_err=0.3401
Eval: 128_h1=0.0149, 128_l2=0.0120
Eval: 421_h1=0.0704, 421_l2=0.0199
[122] time=81.55, avg_loss=0.0265, train_err=0.2123
Eval: 421_h1=0.0672, 421_l2=0.0103
[123] time=82.11, avg_loss=0.0265, train_err=0.2119
Eval: 421_h1=0.0672, 421_l2=0.0095
[124] time=82.15, avg_loss=0.0262, train_err=0.2100
Eval: 421_h1=0.0672, 421_l2=0.0097
[40] time=257.69, avg_loss=0.0137, train_err=0.3290
Eval: 128_h1=0.0146, 128_l2=0.0118
[125] time=82.14, avg_loss=0.0261, train_err=0.2090
[32] time=304.39, avg_loss=0.0507, train_err=0.4056
Eval: 421_h1=0.0673, 421_l2=0.0095
[21] time=482.67, avg_loss=0.0224, train_err=0.5377
Eval: 421_h1=0.0705, 421_l2=0.0187
Eval: 128_h1=0.0246, 128_l2=0.0207
[126] time=81.86, avg_loss=0.0261, train_err=0.2086
Eval: 421_h1=0.0675, 421_l2=0.0093
[127] time=82.14, avg_loss=0.0263, train_err=0.2102
Eval: 421_h1=0.0677, 421_l2=0.0095
[41] time=242.53, avg_loss=0.0132, train_err=0.3167
Eval: 128_h1=0.0146, 128_l2=0.0117
[128] time=82.12, avg_loss=0.0262, train_err=0.2094
Eval: 421_h1=0.0677, 421_l2=0.0094
[33] time=304.60, avg_loss=0.0567, train_err=0.4538
[129] time=81.83, avg_loss=0.0262, train_err=0.2096
Eval: 421_h1=0.0877, 421_l2=0.0416
Eval: 421_h1=0.0677, 421_l2=0.0095
[130] time=82.14, avg_loss=0.0261, train_err=0.2092
Eval: 421_h1=0.0677, 421_l2=0.0095
[42] time=251.78, avg_loss=0.0130, train_err=0.3114
Eval: 128_h1=0.0142, 128_l2=0.0116
[22] time=460.24, avg_loss=0.0220, train_err=0.5285
Eval: 128_h1=0.0239, 128_l2=0.0200
[131] time=82.11, avg_loss=0.0262, train_err=0.2099
Eval: 421_h1=0.0680, 421_l2=0.0114
[132] time=82.10, avg_loss=0.0264, train_err=0.2115
Eval: 421_h1=0.0674, 421_l2=0.0095
[34] time=304.30, avg_loss=0.0607, train_err=0.4855
Eval: 421_h1=0.0706, 421_l2=0.0199
[133] time=81.60, avg_loss=0.0268, train_err=0.2141
Eval: 421_h1=0.0682, 421_l2=0.0115
[43] time=254.16, avg_loss=0.0125, train_err=0.2993
Eval: 128_h1=0.0139, 128_l2=0.0115
[134] time=82.16, avg_loss=0.0273, train_err=0.2180
Eval: 421_h1=0.0685, 421_l2=0.0114
[135] time=82.11, avg_loss=0.0273, train_err=0.2186
Eval: 421_h1=0.0680, 421_l2=0.0111
[136] time=82.12, avg_loss=0.0271, train_err=0.2168
[35] time=304.35, avg_loss=0.0534, train_err=0.4275
Eval: 421_h1=0.0682, 421_l2=0.0097
[44] time=261.81, avg_loss=0.0121, train_err=0.2910
[23] time=484.49, avg_loss=0.0221, train_err=0.5294
Eval: 421_h1=0.0731, 421_l2=0.0240
Eval: 128_h1=0.0136, 128_l2=0.0112
Eval: 128_h1=0.0234, 128_l2=0.0196
[137] time=81.81, avg_loss=0.0265, train_err=0.2121
Eval: 421_h1=0.0679, 421_l2=0.0097
[138] time=82.12, avg_loss=0.0263, train_err=0.2101
Eval: 421_h1=0.0679, 421_l2=0.0095
[139] time=82.16, avg_loss=0.0260, train_err=0.2082
Eval: 421_h1=0.0680, 421_l2=0.0098
[45] time=249.85, avg_loss=0.0122, train_err=0.2921
Eval: 128_h1=0.0137, 128_l2=0.0111
[36] time=304.67, avg_loss=0.0512, train_err=0.4100
[140] time=81.80, avg_loss=0.0260, train_err=0.2082
Eval: 421_h1=0.0681, 421_l2=0.0097
Eval: 421_h1=0.0798, 421_l2=0.0309
[141] time=82.16, avg_loss=0.0261, train_err=0.2090
Eval: 421_h1=0.0679, 421_l2=0.0097
[24] time=461.83, avg_loss=0.0218, train_err=0.5224
[142] time=82.14, avg_loss=0.0264, train_err=0.2116
Eval: 128_h1=0.0231, 128_l2=0.0187
Eval: 421_h1=0.0688, 421_l2=0.0115
[46] time=249.52, avg_loss=0.0123, train_err=0.2949
Eval: 128_h1=0.0137, 128_l2=0.0110
[143] time=82.18, avg_loss=0.0261, train_err=0.2089
Eval: 421_h1=0.0682, 421_l2=0.0093
[37] time=304.44, avg_loss=0.0502, train_err=0.4019
Eval: 421_h1=0.0694, 421_l2=0.0171
[144] time=81.56, avg_loss=0.0260, train_err=0.2083
Eval: 421_h1=0.0682, 421_l2=0.0100
[145] time=82.15, avg_loss=0.0262, train_err=0.2093
Eval: 421_h1=0.0686, 421_l2=0.0097
[47] time=256.00, avg_loss=0.0124, train_err=0.2971
Eval: 128_h1=0.0141, 128_l2=0.0116
[146] time=82.17, avg_loss=0.0279, train_err=0.2231
Eval: 421_h1=0.0687, 421_l2=0.0100
[147] time=82.13, avg_loss=0.0261, train_err=0.2088
Eval: 421_h1=0.0688, 421_l2=0.0108
[38] time=304.03, avg_loss=0.0502, train_err=0.4019
[25] time=490.01, avg_loss=0.0209, train_err=0.5005
Eval: 421_h1=0.0829, 421_l2=0.0344
Eval: 128_h1=0.0253, 128_l2=0.0194
[148] time=81.53, avg_loss=0.0259, train_err=0.2073
Eval: 421_h1=0.0687, 421_l2=0.0097
[48] time=264.51, avg_loss=0.0127, train_err=0.3040
Eval: 128_h1=0.0143, 128_l2=0.0111
[149] time=82.11, avg_loss=0.0261, train_err=0.2087
Eval: 421_h1=0.0683, 421_l2=0.0098
[150] time=82.14, avg_loss=0.0255, train_err=0.2038
Eval: 421_h1=0.0685, 421_l2=0.0096
[39] time=304.69, avg_loss=0.0503, train_err=0.4024
[151] time=81.87, avg_loss=0.0254, train_err=0.2028
Eval: 421_h1=0.0689, 421_l2=0.0102
[49] time=246.22, avg_loss=0.0123, train_err=0.2942
Eval: 421_h1=0.0691, 421_l2=0.0169
Eval: 128_h1=0.0140, 128_l2=0.0112
[152] time=81.85, avg_loss=0.0255, train_err=0.2041
Eval: 421_h1=0.0686, 421_l2=0.0092
[26] time=461.54, avg_loss=0.0200, train_err=0.4799
[153] time=82.16, avg_loss=0.0256, train_err=0.2047
Eval: 421_h1=0.0684, 421_l2=0.0106
Eval: 128_h1=0.0225, 128_l2=0.0174
[154] time=82.18, avg_loss=0.0259, train_err=0.2076
[50] time=248.86, avg_loss=0.0125, train_err=0.2999
Eval: 421_h1=0.0691, 421_l2=0.0104
Eval: 128_h1=0.0174, 128_l2=0.0138
[40] time=304.64, avg_loss=0.0495, train_err=0.3960
Eval: 421_h1=0.0694, 421_l2=0.0188
[155] time=81.58, avg_loss=0.0271, train_err=0.2168
Eval: 421_h1=0.0688, 421_l2=0.0099
[156] time=82.13, avg_loss=0.0258, train_err=0.2066
Eval: 421_h1=0.0686, 421_l2=0.0104
[157] time=82.21, avg_loss=0.0256, train_err=0.2046
[51] time=259.44, avg_loss=0.0131, train_err=0.3140
Eval: 421_h1=0.0686, 421_l2=0.0096
Eval: 128_h1=0.0141, 128_l2=0.0107
[158] time=82.12, avg_loss=0.0252, train_err=0.2016
Eval: 421_h1=0.0687, 421_l2=0.0096
[41] time=303.93, avg_loss=0.0471, train_err=0.3772
Eval: 421_h1=0.0717, 421_l2=0.0217
[27] time=488.36, avg_loss=0.0197, train_err=0.4725
Eval: 128_h1=0.0221, 128_l2=0.0169
[159] time=81.57, avg_loss=0.0251, train_err=0.2010
Eval: 421_h1=0.0689, 421_l2=0.0094
[160] time=82.15, avg_loss=0.0252, train_err=0.2013
Eval: 421_h1=0.0688, 421_l2=0.0102
[52] time=257.16, avg_loss=0.0125, train_err=0.2995
Eval: 128_h1=0.0140, 128_l2=0.0106
[161] time=82.14, avg_loss=0.0254, train_err=0.2032
Eval: 421_h1=0.0689, 421_l2=0.0105
[42] time=304.64, avg_loss=0.0516, train_err=0.4131
[162] time=81.89, avg_loss=0.0254, train_err=0.2032
Eval: 421_h1=0.0687, 421_l2=0.0094
Eval: 421_h1=0.0701, 421_l2=0.0163
[53] time=245.70, avg_loss=0.0122, train_err=0.2933
[163] time=81.79, avg_loss=0.0253, train_err=0.2025
Eval: 421_h1=0.0691, 421_l2=0.0095
Eval: 128_h1=0.0137, 128_l2=0.0104
[28] time=459.10, avg_loss=0.0193, train_err=0.4625
[164] time=82.12, avg_loss=0.0256, train_err=0.2047
Eval: 421_h1=0.0691, 421_l2=0.0103
Eval: 128_h1=0.0213, 128_l2=0.0163
[165] time=82.14, avg_loss=0.0253, train_err=0.2023
Eval: 421_h1=0.0693, 421_l2=0.0094
[43] time=304.66, avg_loss=0.0490, train_err=0.3921
Eval: 421_h1=0.0696, 421_l2=0.0213
[54] time=252.78, avg_loss=0.0128, train_err=0.3068
[166] time=81.56, avg_loss=0.0250, train_err=0.1999
Eval: 421_h1=0.0694, 421_l2=0.0102
Eval: 128_h1=0.0134, 128_l2=0.0102
[167] time=82.13, avg_loss=0.0259, train_err=0.2075
Eval: 421_h1=0.0691, 421_l2=0.0100
[168] time=82.11, avg_loss=0.0254, train_err=0.2034
Eval: 421_h1=0.0694, 421_l2=0.0101
[169] time=82.13, avg_loss=0.0247, train_err=0.1980
[55] time=264.87, avg_loss=0.0117, train_err=0.2816
Eval: 421_h1=0.0692, 421_l2=0.0098
Eval: 128_h1=0.0131, 128_l2=0.0101
[44] time=304.08, avg_loss=0.0457, train_err=0.3656
Eval: 421_h1=0.0686, 421_l2=0.0170
[29] time=491.82, avg_loss=0.0188, train_err=0.4520
Eval: 128_h1=0.0210, 128_l2=0.0159
[170] time=81.55, avg_loss=0.0246, train_err=0.1968
Eval: 421_h1=0.0694, 421_l2=0.0100
[171] time=82.13, avg_loss=0.0245, train_err=0.1958
Eval: 421_h1=0.0694, 421_l2=0.0098
[56] time=251.31, avg_loss=0.0112, train_err=0.2679
[172] time=82.14, avg_loss=0.0249, train_err=0.1992
Eval: 421_h1=0.0694, 421_l2=0.0096
Eval: 128_h1=0.0130, 128_l2=0.0100
[45] time=304.56, avg_loss=0.0451, train_err=0.3605
[173] time=81.86, avg_loss=0.0247, train_err=0.1973
Eval: 421_h1=0.0692, 421_l2=0.0096
Eval: 421_h1=0.0692, 421_l2=0.0190
[174] time=81.84, avg_loss=0.0251, train_err=0.2008
Eval: 421_h1=0.0695, 421_l2=0.0097
[57] time=247.58, avg_loss=0.0108, train_err=0.2598
[175] time=82.17, avg_loss=0.0250, train_err=0.2000
[30] time=460.27, avg_loss=0.0187, train_err=0.4486
Eval: 128_h1=0.0131, 128_l2=0.0099
Eval: 421_h1=0.0699, 421_l2=0.0094
Eval: 128_h1=0.0242, 128_l2=0.0174
[176] time=82.17, avg_loss=0.0246, train_err=0.1971
Eval: 421_h1=0.0693, 421_l2=0.0093
[46] time=304.62, avg_loss=0.0474, train_err=0.3793
Eval: 421_h1=0.0752, 421_l2=0.0275
[177] time=81.53, avg_loss=0.0245, train_err=0.1957
Eval: 421_h1=0.0704, 421_l2=0.0112
[58] time=257.48, avg_loss=0.0109, train_err=0.2620
[178] time=82.14, avg_loss=0.0250, train_err=0.2003
Eval: 128_h1=0.0129, 128_l2=0.0100
Eval: 421_h1=0.0703, 421_l2=0.0104
[179] time=82.12, avg_loss=0.0253, train_err=0.2025
Eval: 421_h1=0.0698, 421_l2=0.0112
[180] time=82.14, avg_loss=0.0239, train_err=0.1908
Eval: 421_h1=0.0692, 421_l2=0.0093
[47] time=304.01, avg_loss=0.0478, train_err=0.3827
Eval: 421_h1=0.0693, 421_l2=0.0183
[31] time=491.15, avg_loss=0.0190, train_err=0.4559
[59] time=260.89, avg_loss=0.0107, train_err=0.2573
[181] time=81.58, avg_loss=0.0230, train_err=0.1842
Eval: 128_h1=0.0228, 128_l2=0.0180
Eval: 421_h1=0.0696, 421_l2=0.0094
Eval: 128_h1=0.0131, 128_l2=0.0101
[182] time=82.08, avg_loss=0.0228, train_err=0.1828
Eval: 421_h1=0.0697, 421_l2=0.0092
[183] time=82.12, avg_loss=0.0228, train_err=0.1824
Eval: 421_h1=0.0698, 421_l2=0.0092
[60] time=253.43, avg_loss=0.0107, train_err=0.2558
[184] time=82.15, avg_loss=0.0227, train_err=0.1818
[48] time=304.43, avg_loss=0.0501, train_err=0.4007
Eval: 421_h1=0.0701, 421_l2=0.0092
Eval: 128_h1=0.0129, 128_l2=0.0102
Eval: 421_h1=0.0701, 421_l2=0.0192
[185] time=81.85, avg_loss=0.0227, train_err=0.1816
Eval: 421_h1=0.0701, 421_l2=0.0092
[186] time=82.17, avg_loss=0.0227, train_err=0.1813
Eval: 421_h1=0.0701, 421_l2=0.0091
[32] time=465.51, avg_loss=0.0207, train_err=0.4973
Eval: 128_h1=0.0279, 128_l2=0.0191
[61] time=247.15, avg_loss=0.0112, train_err=0.2692
[187] time=82.15, avg_loss=0.0226, train_err=0.1811
Eval: 128_h1=0.0135, 128_l2=0.0108
Eval: 421_h1=0.0703, 421_l2=0.0092
[49] time=304.59, avg_loss=0.0439, train_err=0.3509
[188] time=81.81, avg_loss=0.0226, train_err=0.1811
Eval: 421_h1=0.0688, 421_l2=0.0170
Eval: 421_h1=0.0703, 421_l2=0.0093
[189] time=82.14, avg_loss=0.0226, train_err=0.1806
Eval: 421_h1=0.0704, 421_l2=0.0092
[62] time=263.05, avg_loss=0.0111, train_err=0.2655
[190] time=82.15, avg_loss=0.0226, train_err=0.1807
Eval: 421_h1=0.0704, 421_l2=0.0094
Eval: 128_h1=0.0123, 128_l2=0.0095
[191] time=82.13, avg_loss=0.0226, train_err=0.1811
Eval: 421_h1=0.0705, 421_l2=0.0093
[50] time=304.37, avg_loss=0.0470, train_err=0.3762
Eval: 421_h1=0.0704, 421_l2=0.0185
[33] time=489.17, avg_loss=0.0195, train_err=0.4674
[192] time=81.56, avg_loss=0.0226, train_err=0.1811
Eval: 421_h1=0.0705, 421_l2=0.0092
Eval: 128_h1=0.0253, 128_l2=0.0173
[63] time=251.18, avg_loss=0.0108, train_err=0.2579
[193] time=82.10, avg_loss=0.0227, train_err=0.1815
Eval: 128_h1=0.0121, 128_l2=0.0093
Eval: 421_h1=0.0705, 421_l2=0.0097
[194] time=82.14, avg_loss=0.0231, train_err=0.1848
Eval: 421_h1=0.0709, 421_l2=0.0099
[195] time=82.09, avg_loss=0.0232, train_err=0.1855
[51] time=304.41, avg_loss=0.0485, train_err=0.3879
Eval: 421_h1=0.0708, 421_l2=0.0093
Eval: 421_h1=0.0714, 421_l2=0.0200
[64] time=254.49, avg_loss=0.0113, train_err=0.2701
[196] time=81.80, avg_loss=0.0228, train_err=0.1822
Eval: 128_h1=0.0126, 128_l2=0.0097
Eval: 421_h1=0.0705, 421_l2=0.0094
[197] time=82.11, avg_loss=0.0227, train_err=0.1820
Eval: 421_h1=0.0707, 421_l2=0.0095
[34] time=466.32, avg_loss=0.0191, train_err=0.4575
Eval: 128_h1=0.0232, 128_l2=0.0158
[198] time=82.17, avg_loss=0.0228, train_err=0.1821
Eval: 421_h1=0.0706, 421_l2=0.0095
[52] time=304.69, avg_loss=0.0465, train_err=0.3717
[65] time=250.50, avg_loss=0.0120, train_err=0.2875
Eval: 128_h1=0.0124, 128_l2=0.0101
[199] time=81.82, avg_loss=0.0226, train_err=0.1810
Eval: 421_h1=0.0706, 421_l2=0.0093
Eval: 421_h1=0.0706, 421_l2=0.0200
[200] time=81.89, avg_loss=0.0227, train_err=0.1819
Eval: 421_h1=0.0708, 421_l2=0.0100
[201] time=82.09, avg_loss=0.0226, train_err=0.1807
Eval: 421_h1=0.0709, 421_l2=0.0093
[66] time=264.36, avg_loss=0.0111, train_err=0.2658
[202] time=82.13, avg_loss=0.0225, train_err=0.1802
Eval: 128_h1=0.0128, 128_l2=0.0104
Eval: 421_h1=0.0710, 421_l2=0.0093
[53] time=304.61, avg_loss=0.0452, train_err=0.3616
Eval: 421_h1=0.0702, 421_l2=0.0183
[203] time=81.59, avg_loss=0.0225, train_err=0.1800
[35] time=491.84, avg_loss=0.0183, train_err=0.4384
Eval: 421_h1=0.0711, 421_l2=0.0097
Eval: 128_h1=0.0222, 128_l2=0.0159
[204] time=82.17, avg_loss=0.0225, train_err=0.1801
Eval: 421_h1=0.0709, 421_l2=0.0095
[67] time=250.92, avg_loss=0.0106, train_err=0.2533
Eval: 128_h1=0.0132, 128_l2=0.0110
[205] time=82.24, avg_loss=0.0226, train_err=0.1808
Eval: 421_h1=0.0712, 421_l2=0.0096
[206] time=82.17, avg_loss=0.0227, train_err=0.1814
Eval: 421_h1=0.0712, 421_l2=0.0096
[54] time=303.82, avg_loss=0.0551, train_err=0.4405
Eval: 421_h1=0.0736, 421_l2=0.0231
[207] time=81.56, avg_loss=0.0224, train_err=0.1796
Eval: 421_h1=0.0714, 421_l2=0.0092
[68] time=254.56, avg_loss=0.0104, train_err=0.2487
Eval: 128_h1=0.0120, 128_l2=0.0093
[208] time=82.15, avg_loss=0.0223, train_err=0.1787
Eval: 421_h1=0.0711, 421_l2=0.0092
[36] time=471.30, avg_loss=0.0179, train_err=0.4299
Eval: 128_h1=0.0183, 128_l2=0.0137
[209] time=82.16, avg_loss=0.0223, train_err=0.1787
Eval: 421_h1=0.0713, 421_l2=0.0091
[55] time=304.55, avg_loss=0.0485, train_err=0.3880
[210] time=81.89, avg_loss=0.0224, train_err=0.1793
Eval: 421_h1=0.0714, 421_l2=0.0095
Eval: 421_h1=0.0687, 421_l2=0.0181
[69] time=256.26, avg_loss=0.0106, train_err=0.2549
Eval: 128_h1=0.0119, 128_l2=0.0093
[211] time=81.86, avg_loss=0.0225, train_err=0.1802
Eval: 421_h1=0.0714, 421_l2=0.0092
[212] time=82.15, avg_loss=0.0223, train_err=0.1788
Eval: 421_h1=0.0715, 421_l2=0.0093
[213] time=82.19, avg_loss=0.0223, train_err=0.1786
Eval: 421_h1=0.0713, 421_l2=0.0096
[56] time=304.60, avg_loss=0.0451, train_err=0.3612
Eval: 421_h1=0.0683, 421_l2=0.0194
[70] time=260.61, avg_loss=0.0105, train_err=0.2528
[214] time=81.64, avg_loss=0.0224, train_err=0.1794
Eval: 128_h1=0.0120, 128_l2=0.0095
Eval: 421_h1=0.0714, 421_l2=0.0092
[37] time=488.43, avg_loss=0.0169, train_err=0.4052
Eval: 128_h1=0.0182, 128_l2=0.0130
[215] time=82.19, avg_loss=0.0222, train_err=0.1775
Eval: 421_h1=0.0714, 421_l2=0.0094
[216] time=82.17, avg_loss=0.0223, train_err=0.1780
Eval: 421_h1=0.0714, 421_l2=0.0094
[71] time=246.63, avg_loss=0.0103, train_err=0.2480
Eval: 128_h1=0.0119, 128_l2=0.0092
[217] time=82.11, avg_loss=0.0223, train_err=0.1781
Eval: 421_h1=0.0714, 421_l2=0.0094
[57] time=303.84, avg_loss=0.0420, train_err=0.3358
Eval: 421_h1=0.0682, 421_l2=0.0161
[218] time=81.57, avg_loss=0.0221, train_err=0.1770
Eval: 421_h1=0.0718, 421_l2=0.0094
[219] time=82.17, avg_loss=0.0223, train_err=0.1780
Eval: 421_h1=0.0717, 421_l2=0.0093
[38] time=469.27, avg_loss=0.0170, train_err=0.4072
[72] time=256.08, avg_loss=0.0103, train_err=0.2480
Eval: 128_h1=0.0119, 128_l2=0.0096
[220] time=82.16, avg_loss=0.0221, train_err=0.1771
Eval: 128_h1=0.0181, 128_l2=0.0133
Eval: 421_h1=0.0717, 421_l2=0.0094
[58] time=304.60, avg_loss=0.0415, train_err=0.3321
[221] time=81.87, avg_loss=0.0221, train_err=0.1766
Eval: 421_h1=0.0719, 421_l2=0.0101
Eval: 421_h1=0.0716, 421_l2=0.0218
[222] time=81.86, avg_loss=0.0222, train_err=0.1773
Eval: 421_h1=0.0716, 421_l2=0.0094
[73] time=259.31, avg_loss=0.0102, train_err=0.2442
Eval: 128_h1=0.0119, 128_l2=0.0092
[223] time=82.14, avg_loss=0.0221, train_err=0.1767
Eval: 421_h1=0.0720, 421_l2=0.0095
[224] time=82.15, avg_loss=0.0220, train_err=0.1759
Eval: 421_h1=0.0720, 421_l2=0.0099
[59] time=304.57, avg_loss=0.0465, train_err=0.3718
Eval: 421_h1=0.0692, 421_l2=0.0183
[225] time=81.52, avg_loss=0.0219, train_err=0.1753
Eval: 421_h1=0.0719, 421_l2=0.0095
[39] time=482.87, avg_loss=0.0175, train_err=0.4208
Eval: 128_h1=0.0219, 128_l2=0.0151
[74] time=253.13, avg_loss=0.0099, train_err=0.2380
Eval: 128_h1=0.0115, 128_l2=0.0090
[226] time=82.18, avg_loss=0.0219, train_err=0.1754
Eval: 421_h1=0.0716, 421_l2=0.0093
[227] time=82.18, avg_loss=0.0220, train_err=0.1756
Eval: 421_h1=0.0720, 421_l2=0.0095
[228] time=82.16, avg_loss=0.0219, train_err=0.1753
Eval: 421_h1=0.0719, 421_l2=0.0092
[60] time=303.99, avg_loss=0.0379, train_err=0.3030
Eval: 421_h1=0.0657, 421_l2=0.0136
[75] time=250.29, avg_loss=0.0097, train_err=0.2336
Eval: 128_h1=0.0112, 128_l2=0.0082
[229] time=81.57, avg_loss=0.0220, train_err=0.1764
Eval: 421_h1=0.0724, 421_l2=0.0095
[230] time=82.16, avg_loss=0.0220, train_err=0.1759
Eval: 421_h1=0.0719, 421_l2=0.0097
[40] time=468.01, avg_loss=0.0168, train_err=0.4041
[231] time=82.14, avg_loss=0.0219, train_err=0.1756
Eval: 421_h1=0.0721, 421_l2=0.0093
Eval: 128_h1=0.0175, 128_l2=0.0123
[76] time=256.32, avg_loss=0.0098, train_err=0.2340
Eval: 128_h1=0.0114, 128_l2=0.0081
[61] time=304.57, avg_loss=0.0350, train_err=0.2799
[232] time=81.83, avg_loss=0.0219, train_err=0.1750
Eval: 421_h1=0.0719, 421_l2=0.0095
Eval: 421_h1=0.0662, 421_l2=0.0139
[233] time=81.84, avg_loss=0.0219, train_err=0.1751
Eval: 421_h1=0.0726, 421_l2=0.0127
[234] time=82.15, avg_loss=0.0221, train_err=0.1772
Eval: 421_h1=0.0721, 421_l2=0.0093
[77] time=259.50, avg_loss=0.0098, train_err=0.2361
Eval: 128_h1=0.0115, 128_l2=0.0083
[235] time=82.15, avg_loss=0.0218, train_err=0.1743
Eval: 421_h1=0.0720, 421_l2=0.0096
[62] time=304.66, avg_loss=0.0344, train_err=0.2755
Eval: 421_h1=0.0670, 421_l2=0.0143
[236] time=81.56, avg_loss=0.0216, train_err=0.1731
Eval: 421_h1=0.0723, 421_l2=0.0094
[41] time=480.48, avg_loss=0.0161, train_err=0.3870
Eval: 128_h1=0.0173, 128_l2=0.0125
[237] time=82.16, avg_loss=0.0216, train_err=0.1727
Eval: 421_h1=0.0721, 421_l2=0.0093
[78] time=246.71, avg_loss=0.0098, train_err=0.2358
Eval: 128_h1=0.0115, 128_l2=0.0086
[238] time=82.15, avg_loss=0.0216, train_err=0.1728
Eval: 421_h1=0.0724, 421_l2=0.0094
[239] time=82.13, avg_loss=0.0216, train_err=0.1730
Eval: 421_h1=0.0721, 421_l2=0.0093
[63] time=303.90, avg_loss=0.0340, train_err=0.2718
Eval: 421_h1=0.0665, 421_l2=0.0130
[240] time=81.65, avg_loss=0.0214, train_err=0.1712
Eval: 421_h1=0.0722, 421_l2=0.0092
[79] time=251.14, avg_loss=0.0107, train_err=0.2574
Eval: 128_h1=0.0119, 128_l2=0.0082
[241] time=82.16, avg_loss=0.0211, train_err=0.1684
Eval: 421_h1=0.0725, 421_l2=0.0092
[42] time=468.15, avg_loss=0.0160, train_err=0.3837
[242] time=82.22, avg_loss=0.0210, train_err=0.1679
Eval: 421_h1=0.0725, 421_l2=0.0092
Eval: 128_h1=0.0171, 128_l2=0.0120
[243] time=82.17, avg_loss=0.0210, train_err=0.1677
[64] time=304.23, avg_loss=0.0341, train_err=0.2726
Eval: 421_h1=0.0726, 421_l2=0.0093
Eval: 421_h1=0.0664, 421_l2=0.0127
[80] time=261.30, avg_loss=0.0104, train_err=0.2491
Eval: 128_h1=0.0113, 128_l2=0.0082
[244] time=81.80, avg_loss=0.0209, train_err=0.1675
Eval: 421_h1=0.0727, 421_l2=0.0093
[245] time=82.18, avg_loss=0.0209, train_err=0.1674
Eval: 421_h1=0.0727, 421_l2=0.0093
[246] time=82.21, avg_loss=0.0209, train_err=0.1673
Eval: 421_h1=0.0728, 421_l2=0.0093
[81] time=253.74, avg_loss=0.0096, train_err=0.2297
[65] time=304.59, avg_loss=0.0339, train_err=0.2709
Eval: 128_h1=0.0112, 128_l2=0.0079
[247] time=81.90, avg_loss=0.0209, train_err=0.1672
Eval: 421_h1=0.0666, 421_l2=0.0124
Eval: 421_h1=0.0728, 421_l2=0.0092
[43] time=480.61, avg_loss=0.0160, train_err=0.3834
Eval: 128_h1=0.0171, 128_l2=0.0123
[248] time=82.22, avg_loss=0.0209, train_err=0.1671
Eval: 421_h1=0.0729, 421_l2=0.0093
[249] time=82.14, avg_loss=0.0209, train_err=0.1669
Eval: 421_h1=0.0729, 421_l2=0.0092
[82] time=250.93, avg_loss=0.0092, train_err=0.2200
Eval: 128_h1=0.0107, 128_l2=0.0076
[250] time=82.19, avg_loss=0.0209, train_err=0.1668
Eval: 421_h1=0.0730, 421_l2=0.0092
[66] time=304.14, avg_loss=0.0337, train_err=0.2697
Eval: 421_h1=0.0666, 421_l2=0.0128
[251] time=81.58, avg_loss=0.0208, train_err=0.1668
Eval: 421_h1=0.0730, 421_l2=0.0092
[252] time=82.21, avg_loss=0.0208, train_err=0.1667
Eval: 421_h1=0.0731, 421_l2=0.0093
[83] time=250.90, avg_loss=0.0087, train_err=0.2090
Eval: 128_h1=0.0105, 128_l2=0.0075
[44] time=470.34, avg_loss=0.0160, train_err=0.3842
[253] time=82.19, avg_loss=0.0209, train_err=0.1670
Eval: 421_h1=0.0732, 421_l2=0.0098
Eval: 128_h1=0.0184, 128_l2=0.0142
[254] time=82.15, avg_loss=0.0210, train_err=0.1679
[67] time=304.38, avg_loss=0.0336, train_err=0.2687
Eval: 421_h1=0.0734, 421_l2=0.0094
Eval: 421_h1=0.0666, 421_l2=0.0122
[255] time=81.80, avg_loss=0.0210, train_err=0.1679
Eval: 421_h1=0.0735, 421_l2=0.0093
[84] time=264.38, avg_loss=0.0085, train_err=0.2039
Eval: 128_h1=0.0100, 128_l2=0.0074
[256] time=82.13, avg_loss=0.0209, train_err=0.1670
Eval: 421_h1=0.0733, 421_l2=0.0092
[257] time=82.19, avg_loss=0.0208, train_err=0.1666
Eval: 421_h1=0.0733, 421_l2=0.0093
[68] time=304.50, avg_loss=0.0341, train_err=0.2731
[258] time=81.95, avg_loss=0.0208, train_err=0.1665
Eval: 421_h1=0.0669, 421_l2=0.0128
Eval: 421_h1=0.0732, 421_l2=0.0093
[85] time=247.53, avg_loss=0.0086, train_err=0.2056
[45] time=479.89, avg_loss=0.0157, train_err=0.3758
Eval: 128_h1=0.0101, 128_l2=0.0075
Eval: 128_h1=0.0167, 128_l2=0.0119
[259] time=82.16, avg_loss=0.0208, train_err=0.1665
Eval: 421_h1=0.0732, 421_l2=0.0093
[260] time=82.18, avg_loss=0.0208, train_err=0.1664
Eval: 421_h1=0.0732, 421_l2=0.0092
[261] time=82.19, avg_loss=0.0208, train_err=0.1665
Eval: 421_h1=0.0733, 421_l2=0.0093
[86] time=251.62, avg_loss=0.0087, train_err=0.2097
[69] time=304.25, avg_loss=0.0347, train_err=0.2778
Eval: 128_h1=0.0108, 128_l2=0.0077
Eval: 421_h1=0.0668, 421_l2=0.0128
[262] time=81.51, avg_loss=0.0208, train_err=0.1663
Eval: 421_h1=0.0734, 421_l2=0.0093
[263] time=82.16, avg_loss=0.0208, train_err=0.1662
Eval: 421_h1=0.0734, 421_l2=0.0093
[264] time=82.21, avg_loss=0.0208, train_err=0.1662
[46] time=469.71, avg_loss=0.0151, train_err=0.3624
Eval: 421_h1=0.0736, 421_l2=0.0093
Eval: 128_h1=0.0170, 128_l2=0.0122
[87] time=252.86, avg_loss=0.0089, train_err=0.2123
Eval: 128_h1=0.0108, 128_l2=0.0073
[265] time=82.17, avg_loss=0.0208, train_err=0.1660
Eval: 421_h1=0.0735, 421_l2=0.0096
[70] time=304.00, avg_loss=0.0344, train_err=0.2748
Eval: 421_h1=0.0669, 421_l2=0.0126
[266] time=81.54, avg_loss=0.0208, train_err=0.1661
Eval: 421_h1=0.0735, 421_l2=0.0098
[267] time=82.13, avg_loss=0.0208, train_err=0.1663
Eval: 421_h1=0.0737, 421_l2=0.0093
[88] time=259.68, avg_loss=0.0082, train_err=0.1965
Eval: 128_h1=0.0104, 128_l2=0.0073
[268] time=82.17, avg_loss=0.0207, train_err=0.1656
Eval: 421_h1=0.0736, 421_l2=0.0092
[71] time=304.57, avg_loss=0.0348, train_err=0.2783
[269] time=81.83, avg_loss=0.0207, train_err=0.1655
Eval: 421_h1=0.0737, 421_l2=0.0092
Eval: 421_h1=0.0672, 421_l2=0.0133
[47] time=483.92, avg_loss=0.0160, train_err=0.3827
[270] time=81.84, avg_loss=0.0206, train_err=0.1651
Eval: 128_h1=0.0168, 128_l2=0.0116
Eval: 421_h1=0.0737, 421_l2=0.0093
[89] time=255.79, avg_loss=0.0080, train_err=0.1917
Eval: 128_h1=0.0104, 128_l2=0.0070
[271] time=82.18, avg_loss=0.0206, train_err=0.1648
Eval: 421_h1=0.0737, 421_l2=0.0092
[272] time=82.18, avg_loss=0.0206, train_err=0.1647
Eval: 421_h1=0.0737, 421_l2=0.0094
[72] time=304.63, avg_loss=0.0349, train_err=0.2796
Eval: 421_h1=0.0672, 421_l2=0.0129
[273] time=81.53, avg_loss=0.0206, train_err=0.1647
Eval: 421_h1=0.0738, 421_l2=0.0095
[90] time=252.93, avg_loss=0.0085, train_err=0.2029
Eval: 128_h1=0.0104, 128_l2=0.0072
[274] time=82.20, avg_loss=0.0206, train_err=0.1646
Eval: 421_h1=0.0740, 421_l2=0.0093
[275] time=82.16, avg_loss=0.0206, train_err=0.1645
Eval: 421_h1=0.0740, 421_l2=0.0093
[48] time=469.99, avg_loss=0.0151, train_err=0.3614
Eval: 128_h1=0.0163, 128_l2=0.0110
[276] time=82.23, avg_loss=0.0205, train_err=0.1643
Eval: 421_h1=0.0740, 421_l2=0.0092
[73] time=303.78, avg_loss=0.0339, train_err=0.2713
[91] time=254.06, avg_loss=0.0083, train_err=0.1998
Eval: 421_h1=0.0674, 421_l2=0.0125
Eval: 128_h1=0.0103, 128_l2=0.0070
[277] time=81.48, avg_loss=0.0206, train_err=0.1647
Eval: 421_h1=0.0739, 421_l2=0.0093
[278] time=82.17, avg_loss=0.0206, train_err=0.1650
Eval: 421_h1=0.0741, 421_l2=0.0095
[279] time=82.20, avg_loss=0.0205, train_err=0.1640
Eval: 421_h1=0.0741, 421_l2=0.0093
[92] time=261.41, avg_loss=0.0083, train_err=0.1984
Eval: 128_h1=0.0102, 128_l2=0.0070
[74] time=304.57, avg_loss=0.0342, train_err=0.2738
[280] time=81.92, avg_loss=0.0205, train_err=0.1638
Eval: 421_h1=0.0741, 421_l2=0.0093
Eval: 421_h1=0.0673, 421_l2=0.0125
[49] time=480.22, avg_loss=0.0142, train_err=0.3394
[281] time=81.84, avg_loss=0.0205, train_err=0.1637
Eval: 421_h1=0.0742, 421_l2=0.0093
Eval: 128_h1=0.0162, 128_l2=0.0109
[282] time=82.23, avg_loss=0.0204, train_err=0.1635
Eval: 421_h1=0.0742, 421_l2=0.0092
[93] time=242.90, avg_loss=0.0091, train_err=0.2176
Eval: 128_h1=0.0110, 128_l2=0.0106
[283] time=82.16, avg_loss=0.0205, train_err=0.1636
Eval: 421_h1=0.0744, 421_l2=0.0093
[75] time=304.57, avg_loss=0.0344, train_err=0.2750
Eval: 421_h1=0.0681, 421_l2=0.0143
[284] time=81.49, avg_loss=0.0205, train_err=0.1638
Eval: 421_h1=0.0741, 421_l2=0.0093
[285] time=82.20, avg_loss=0.0204, train_err=0.1636
Eval: 421_h1=0.0744, 421_l2=0.0092
[94] time=252.27, avg_loss=0.0094, train_err=0.2251
Eval: 128_h1=0.0111, 128_l2=0.0130
[286] time=82.19, avg_loss=0.0204, train_err=0.1633
Eval: 421_h1=0.0742, 421_l2=0.0092
[50] time=468.04, avg_loss=0.0140, train_err=0.3352
Eval: 128_h1=0.0161, 128_l2=0.0109
[287] time=82.16, avg_loss=0.0204, train_err=0.1633
Eval: 421_h1=0.0742, 421_l2=0.0093
[76] time=303.91, avg_loss=0.0349, train_err=0.2789
Eval: 421_h1=0.0675, 421_l2=0.0129
[288] time=81.54, avg_loss=0.0204, train_err=0.1631
Eval: 421_h1=0.0743, 421_l2=0.0094
[95] time=254.21, avg_loss=0.0088, train_err=0.2106
Eval: 128_h1=0.0103, 128_l2=0.0091
[289] time=82.18, avg_loss=0.0203, train_err=0.1627
Eval: 421_h1=0.0745, 421_l2=0.0093
[290] time=82.18, avg_loss=0.0203, train_err=0.1626
Eval: 421_h1=0.0745, 421_l2=0.0094
[77] time=304.54, avg_loss=0.0375, train_err=0.2999
[291] time=81.89, avg_loss=0.0203, train_err=0.1628
Eval: 421_h1=0.0745, 421_l2=0.0093
[96] time=257.16, avg_loss=0.0079, train_err=0.1891
Eval: 421_h1=0.0682, 421_l2=0.0144
Eval: 128_h1=0.0101, 128_l2=0.0079
[51] time=475.79, avg_loss=0.0139, train_err=0.3343
[292] time=81.78, avg_loss=0.0203, train_err=0.1626
Eval: 421_h1=0.0745, 421_l2=0.0093
Eval: 128_h1=0.0160, 128_l2=0.0110
[293] time=82.18, avg_loss=0.0203, train_err=0.1625
Eval: 421_h1=0.0745, 421_l2=0.0093
[294] time=82.14, avg_loss=0.0203, train_err=0.1623
Eval: 421_h1=0.0747, 421_l2=0.0093
[97] time=251.72, avg_loss=0.0079, train_err=0.1890
Eval: 128_h1=0.0102, 128_l2=0.0085
[78] time=304.56, avg_loss=0.0348, train_err=0.2787
Eval: 421_h1=0.0676, 421_l2=0.0144
[295] time=81.54, avg_loss=0.0203, train_err=0.1623
Eval: 421_h1=0.0745, 421_l2=0.0094
[296] time=82.20, avg_loss=0.0203, train_err=0.1620
Eval: 421_h1=0.0747, 421_l2=0.0093
[297] time=82.16, avg_loss=0.0202, train_err=0.1618
Eval: 421_h1=0.0748, 421_l2=0.0095
[98] time=253.00, avg_loss=0.0097, train_err=0.2319
Eval: 128_h1=0.0111, 128_l2=0.0147
[52] time=471.62, avg_loss=0.0140, train_err=0.3362
Eval: 128_h1=0.0162, 128_l2=0.0108
[298] time=82.17, avg_loss=0.0202, train_err=0.1617
Eval: 421_h1=0.0746, 421_l2=0.0094
[79] time=303.85, avg_loss=0.0337, train_err=0.2695
Eval: 421_h1=0.0679, 421_l2=0.0135
[299] time=81.55, avg_loss=0.0202, train_err=0.1619
Eval: 421_h1=0.0748, 421_l2=0.0093
[99] time=252.40, avg_loss=0.0097, train_err=0.2322
Eval: 128_h1=0.0112, 128_l2=0.0122
[80] time=153.78, avg_loss=0.0339, train_err=0.2712
Eval: 421_h1=0.0679, 421_l2=0.0123
[81] time=130.35, avg_loss=0.0338, train_err=0.2701
Eval: 421_h1=0.0681, 421_l2=0.0145
[53] time=486.24, avg_loss=0.0135, train_err=0.3244
[100] time=262.12, avg_loss=0.0080, train_err=0.1914
Eval: 128_h1=0.0163, 128_l2=0.0105
Eval: 128_h1=0.0093, 128_l2=0.0067
[82] time=130.36, avg_loss=0.0330, train_err=0.2639
Eval: 421_h1=0.0676, 421_l2=0.0128
[83] time=130.34, avg_loss=0.0338, train_err=0.2701
Eval: 421_h1=0.0686, 421_l2=0.0155
[101] time=243.56, avg_loss=0.0076, train_err=0.1815
Eval: 128_h1=0.0090, 128_l2=0.0066
[84] time=130.37, avg_loss=0.0339, train_err=0.2713
Eval: 421_h1=0.0680, 421_l2=0.0140
[85] time=130.33, avg_loss=0.0339, train_err=0.2710
[54] time=453.90, avg_loss=0.0149, train_err=0.3575
Eval: 421_h1=0.0683, 421_l2=0.0130
Eval: 128_h1=0.0182, 128_l2=0.0127
[102] time=247.60, avg_loss=0.0073, train_err=0.1756
Eval: 128_h1=0.0089, 128_l2=0.0068
[86] time=130.34, avg_loss=0.0344, train_err=0.2755
Eval: 421_h1=0.0681, 421_l2=0.0128
[87] time=130.38, avg_loss=0.0338, train_err=0.2702
Eval: 421_h1=0.0685, 421_l2=0.0134
[103] time=254.42, avg_loss=0.0072, train_err=0.1720
Eval: 128_h1=0.0088, 128_l2=0.0068
[88] time=130.33, avg_loss=0.0359, train_err=0.2873
Eval: 421_h1=0.0679, 421_l2=0.0124
[55] time=483.75, avg_loss=0.0160, train_err=0.3848
Eval: 128_h1=0.0234, 128_l2=0.0167
[89] time=130.34, avg_loss=0.0336, train_err=0.2685
Eval: 421_h1=0.0702, 421_l2=0.0182
[104] time=258.53, avg_loss=0.0071, train_err=0.1697
Eval: 128_h1=0.0087, 128_l2=0.0070
[90] time=130.36, avg_loss=0.0330, train_err=0.2637
Eval: 421_h1=0.0681, 421_l2=0.0140
[91] time=130.34, avg_loss=0.0324, train_err=0.2591
[105] time=241.74, avg_loss=0.0070, train_err=0.1677
Eval: 421_h1=0.0680, 421_l2=0.0131
Eval: 128_h1=0.0087, 128_l2=0.0071
[56] time=451.23, avg_loss=0.0162, train_err=0.3877
[92] time=130.36, avg_loss=0.0350, train_err=0.2799
Eval: 421_h1=0.0695, 421_l2=0.0175
Eval: 128_h1=0.0187, 128_l2=0.0121
[106] time=248.95, avg_loss=0.0069, train_err=0.1658
Eval: 128_h1=0.0087, 128_l2=0.0072
[93] time=130.39, avg_loss=0.0354, train_err=0.2835
Eval: 421_h1=0.0683, 421_l2=0.0126
[94] time=130.36, avg_loss=0.0327, train_err=0.2613
Eval: 421_h1=0.0702, 421_l2=0.0175
[107] time=263.85, avg_loss=0.0068, train_err=0.1643
Eval: 128_h1=0.0086, 128_l2=0.0072
[95] time=130.33, avg_loss=0.0329, train_err=0.2635
Eval: 421_h1=0.0685, 421_l2=0.0131
[57] time=484.97, avg_loss=0.0140, train_err=0.3347
Eval: 128_h1=0.0156, 128_l2=0.0101
[96] time=130.36, avg_loss=0.0315, train_err=0.2518
Eval: 421_h1=0.0681, 421_l2=0.0124
[108] time=247.13, avg_loss=0.0068, train_err=0.1635
Eval: 128_h1=0.0086, 128_l2=0.0070
[97] time=130.34, avg_loss=0.0319, train_err=0.2555
Eval: 421_h1=0.0685, 421_l2=0.0147
[98] time=130.34, avg_loss=0.0326, train_err=0.2612
Eval: 421_h1=0.0683, 421_l2=0.0122
[109] time=243.45, avg_loss=0.0068, train_err=0.1638
Eval: 128_h1=0.0085, 128_l2=0.0065
[58] time=449.97, avg_loss=0.0140, train_err=0.3349
[99] time=130.34, avg_loss=0.0318, train_err=0.2548
Eval: 128_h1=0.0212, 128_l2=0.0146
Eval: 421_h1=0.0690, 421_l2=0.0150
[100] time=130.36, avg_loss=0.0343, train_err=0.2745
Eval: 421_h1=0.0700, 421_l2=0.0159
[110] time=253.58, avg_loss=0.0067, train_err=0.1602
Eval: 128_h1=0.0085, 128_l2=0.0067
[101] time=130.33, avg_loss=0.0328, train_err=0.2628
Eval: 421_h1=0.0680, 421_l2=0.0129
[102] time=130.34, avg_loss=0.0321, train_err=0.2568
Eval: 421_h1=0.0684, 421_l2=0.0122
[111] time=261.64, avg_loss=0.0066, train_err=0.1577
Eval: 128_h1=0.0085, 128_l2=0.0069
[59] time=488.73, avg_loss=0.0137, train_err=0.3280
Eval: 128_h1=0.0152, 128_l2=0.0097
[103] time=130.34, avg_loss=0.0338, train_err=0.2702
Eval: 421_h1=0.0688, 421_l2=0.0148
[104] time=130.35, avg_loss=0.0325, train_err=0.2604
[112] time=244.60, avg_loss=0.0065, train_err=0.1560
Eval: 421_h1=0.0679, 421_l2=0.0122
Eval: 128_h1=0.0084, 128_l2=0.0071
[105] time=130.33, avg_loss=0.0329, train_err=0.2632
Eval: 421_h1=0.0685, 421_l2=0.0125
[60] time=449.95, avg_loss=0.0133, train_err=0.3196
[113] time=243.96, avg_loss=0.0064, train_err=0.1536
Eval: 128_h1=0.0155, 128_l2=0.0098
Eval: 128_h1=0.0084, 128_l2=0.0072
[106] time=130.35, avg_loss=0.0320, train_err=0.2556
Eval: 421_h1=0.0683, 421_l2=0.0125
[107] time=130.35, avg_loss=0.0317, train_err=0.2538
Eval: 421_h1=0.0699, 421_l2=0.0168
[114] time=258.53, avg_loss=0.0063, train_err=0.1508
Eval: 128_h1=0.0084, 128_l2=0.0072
[108] time=130.37, avg_loss=0.0315, train_err=0.2518
Eval: 421_h1=0.0686, 421_l2=0.0127
[109] time=130.33, avg_loss=0.0312, train_err=0.2497
Eval: 421_h1=0.0685, 421_l2=0.0136
[61] time=484.10, avg_loss=0.0133, train_err=0.3197
Eval: 128_h1=0.0145, 128_l2=0.0092
[115] time=253.56, avg_loss=0.0062, train_err=0.1487
Eval: 128_h1=0.0083, 128_l2=0.0071
[110] time=130.34, avg_loss=0.0309, train_err=0.2473
Eval: 421_h1=0.0687, 421_l2=0.0124
[111] time=130.39, avg_loss=0.0312, train_err=0.2494
Eval: 421_h1=0.0685, 421_l2=0.0117
[116] time=245.63, avg_loss=0.0061, train_err=0.1466
Eval: 128_h1=0.0082, 128_l2=0.0068
[112] time=130.34, avg_loss=0.0319, train_err=0.2552
Eval: 421_h1=0.0683, 421_l2=0.0118
[62] time=449.50, avg_loss=0.0125, train_err=0.3005
Eval: 128_h1=0.0147, 128_l2=0.0091
[113] time=130.32, avg_loss=0.0315, train_err=0.2519
Eval: 421_h1=0.0688, 421_l2=0.0146
[117] time=243.57, avg_loss=0.0060, train_err=0.1447
Eval: 128_h1=0.0082, 128_l2=0.0067
[114] time=130.37, avg_loss=0.0315, train_err=0.2520
Eval: 421_h1=0.0687, 421_l2=0.0142
[115] time=130.33, avg_loss=0.0312, train_err=0.2497
Eval: 421_h1=0.0680, 421_l2=0.0123
[118] time=262.92, avg_loss=0.0060, train_err=0.1430
Eval: 128_h1=0.0081, 128_l2=0.0066
[116] time=130.34, avg_loss=0.0325, train_err=0.2600
Eval: 421_h1=0.0684, 421_l2=0.0131
[63] time=482.69, avg_loss=0.0124, train_err=0.2964
Eval: 128_h1=0.0143, 128_l2=0.0089
[117] time=130.34, avg_loss=0.0316, train_err=0.2525
[119] time=246.20, avg_loss=0.0059, train_err=0.1413
Eval: 421_h1=0.0689, 421_l2=0.0122
Eval: 128_h1=0.0081, 128_l2=0.0065
[118] time=130.37, avg_loss=0.0338, train_err=0.2702
Eval: 421_h1=0.0680, 421_l2=0.0123
[120] time=247.72, avg_loss=0.0058, train_err=0.1401
[119] time=130.34, avg_loss=0.0305, train_err=0.2442
Eval: 128_h1=0.0081, 128_l2=0.0063
Eval: 421_h1=0.0684, 421_l2=0.0122
[64] time=452.19, avg_loss=0.0127, train_err=0.3037
Eval: 128_h1=0.0149, 128_l2=0.0095
[120] time=130.35, avg_loss=0.0283, train_err=0.2261
Eval: 421_h1=0.0678, 421_l2=0.0119
[121] time=248.33, avg_loss=0.0061, train_err=0.1456
Eval: 128_h1=0.0082, 128_l2=0.0063
[121] time=130.33, avg_loss=0.0267, train_err=0.2137
Eval: 421_h1=0.0681, 421_l2=0.0118
[122] time=130.35, avg_loss=0.0262, train_err=0.2095
Eval: 421_h1=0.0683, 421_l2=0.0114
[122] time=261.14, avg_loss=0.0068, train_err=0.1628
Eval: 128_h1=0.0087, 128_l2=0.0066
[123] time=130.33, avg_loss=0.0260, train_err=0.2077
Eval: 421_h1=0.0684, 421_l2=0.0114
[65] time=482.40, avg_loss=0.0128, train_err=0.3079
Eval: 128_h1=0.0144, 128_l2=0.0093
[124] time=130.36, avg_loss=0.0259, train_err=0.2070
Eval: 421_h1=0.0686, 421_l2=0.0114
[123] time=244.18, avg_loss=0.0067, train_err=0.1611
Eval: 128_h1=0.0088, 128_l2=0.0062
[125] time=130.37, avg_loss=0.0258, train_err=0.2063
Eval: 421_h1=0.0687, 421_l2=0.0113
[126] time=130.36, avg_loss=0.0258, train_err=0.2066
Eval: 421_h1=0.0689, 421_l2=0.0113
[124] time=247.93, avg_loss=0.0064, train_err=0.1527
Eval: 128_h1=0.0085, 128_l2=0.0061
[66] time=454.78, avg_loss=0.0124, train_err=0.2979
Eval: 128_h1=0.0143, 128_l2=0.0096
[127] time=130.38, avg_loss=0.0259, train_err=0.2074
Eval: 421_h1=0.0689, 421_l2=0.0113
[128] time=130.39, avg_loss=0.0260, train_err=0.2083
Eval: 421_h1=0.0689, 421_l2=0.0112
[125] time=253.95, avg_loss=0.0062, train_err=0.1495
Eval: 128_h1=0.0083, 128_l2=0.0060
[129] time=130.37, avg_loss=0.0261, train_err=0.2091
Eval: 421_h1=0.0689, 421_l2=0.0114
[67] time=480.99, avg_loss=0.0140, train_err=0.3356
[130] time=130.36, avg_loss=0.0262, train_err=0.2098
Eval: 421_h1=0.0691, 421_l2=0.0111
[126] time=254.76, avg_loss=0.0062, train_err=0.1487
Eval: 128_h1=0.0145, 128_l2=0.0089
Eval: 128_h1=0.0085, 128_l2=0.0059
[131] time=130.35, avg_loss=0.0263, train_err=0.2107
Eval: 421_h1=0.0692, 421_l2=0.0113
[127] time=245.86, avg_loss=0.0063, train_err=0.1506
[132] time=130.36, avg_loss=0.0263, train_err=0.2107
Eval: 128_h1=0.0098, 128_l2=0.0068
Eval: 421_h1=0.0690, 421_l2=0.0113
[133] time=130.35, avg_loss=0.0265, train_err=0.2121
Eval: 421_h1=0.0691, 421_l2=0.0114
[68] time=453.93, avg_loss=0.0123, train_err=0.2953
Eval: 128_h1=0.0140, 128_l2=0.0087
[128] time=246.83, avg_loss=0.0065, train_err=0.1559
Eval: 128_h1=0.0098, 128_l2=0.0069
[134] time=130.36, avg_loss=0.0262, train_err=0.2096
Eval: 421_h1=0.0692, 421_l2=0.0115
[135] time=130.35, avg_loss=0.0267, train_err=0.2140
Eval: 421_h1=0.0696, 421_l2=0.0132
[129] time=257.93, avg_loss=0.0067, train_err=0.1605
Eval: 128_h1=0.0087, 128_l2=0.0061
[136] time=130.36, avg_loss=0.0265, train_err=0.2122
Eval: 421_h1=0.0694, 421_l2=0.0117
[69] time=476.43, avg_loss=0.0118, train_err=0.2823
[137] time=130.36, avg_loss=0.0265, train_err=0.2121
Eval: 128_h1=0.0141, 128_l2=0.0087
Eval: 421_h1=0.0695, 421_l2=0.0119
[130] time=247.08, avg_loss=0.0064, train_err=0.1535
Eval: 128_h1=0.0086, 128_l2=0.0059
[138] time=130.37, avg_loss=0.0274, train_err=0.2192
Eval: 421_h1=0.0694, 421_l2=0.0116
[139] time=130.33, avg_loss=0.0266, train_err=0.2131
Eval: 421_h1=0.0696, 421_l2=0.0120
[131] time=245.51, avg_loss=0.0062, train_err=0.1486
Eval: 128_h1=0.0088, 128_l2=0.0060
[140] time=130.34, avg_loss=0.0263, train_err=0.2107
Eval: 421_h1=0.0696, 421_l2=0.0118
[70] time=453.24, avg_loss=0.0120, train_err=0.2870
Eval: 128_h1=0.0141, 128_l2=0.0085
[141] time=130.34, avg_loss=0.0259, train_err=0.2068
Eval: 421_h1=0.0693, 421_l2=0.0113
[132] time=250.97, avg_loss=0.0061, train_err=0.1464
Eval: 128_h1=0.0089, 128_l2=0.0061
[142] time=130.34, avg_loss=0.0256, train_err=0.2052
Eval: 421_h1=0.0697, 421_l2=0.0113
[143] time=130.33, avg_loss=0.0265, train_err=0.2120
Eval: 421_h1=0.0699, 421_l2=0.0123
[133] time=260.52, avg_loss=0.0060, train_err=0.1446
Eval: 128_h1=0.0089, 128_l2=0.0060
[71] time=481.69, avg_loss=0.0133, train_err=0.3185
Eval: 128_h1=0.0209, 128_l2=0.0140
[144] time=130.35, avg_loss=0.0264, train_err=0.2115
Eval: 421_h1=0.0695, 421_l2=0.0113
[134] time=245.43, avg_loss=0.0059, train_err=0.1425
[145] time=130.35, avg_loss=0.0257, train_err=0.2057
Eval: 128_h1=0.0089, 128_l2=0.0060
Eval: 421_h1=0.0695, 421_l2=0.0118
[146] time=130.35, avg_loss=0.0258, train_err=0.2060
Eval: 421_h1=0.0694, 421_l2=0.0116
[135] time=248.05, avg_loss=0.0060, train_err=0.1437
Eval: 128_h1=0.0081, 128_l2=0.0052
[147] time=130.37, avg_loss=0.0258, train_err=0.2063
Eval: 421_h1=0.0698, 421_l2=0.0124
[72] time=455.73, avg_loss=0.0148, train_err=0.3544
Eval: 128_h1=0.0175, 128_l2=0.0112
[148] time=130.34, avg_loss=0.0258, train_err=0.2065
Eval: 421_h1=0.0693, 421_l2=0.0115
[136] time=254.21, avg_loss=0.0062, train_err=0.1475
Eval: 128_h1=0.0080, 128_l2=0.0051
[149] time=130.33, avg_loss=0.0261, train_err=0.2086
Eval: 421_h1=0.0696, 421_l2=0.0118
[150] time=130.35, avg_loss=0.0258, train_err=0.2064
Eval: 421_h1=0.0707, 421_l2=0.0141
[137] time=255.43, avg_loss=0.0057, train_err=0.1372
Eval: 128_h1=0.0083, 128_l2=0.0054
[73] time=478.68, avg_loss=0.0138, train_err=0.3305
Eval: 128_h1=0.0166, 128_l2=0.0108
[151] time=130.36, avg_loss=0.0260, train_err=0.2077
Eval: 421_h1=0.0696, 421_l2=0.0115
[152] time=130.37, avg_loss=0.0254, train_err=0.2034
Eval: 421_h1=0.0698, 421_l2=0.0113
[138] time=244.92, avg_loss=0.0056, train_err=0.1340
Eval: 128_h1=0.0077, 128_l2=0.0048
[153] time=130.36, avg_loss=0.0252, train_err=0.2018
Eval: 421_h1=0.0696, 421_l2=0.0119
[74] time=454.33, avg_loss=0.0125, train_err=0.2987
[154] time=130.37, avg_loss=0.0260, train_err=0.2084
Eval: 421_h1=0.0699, 421_l2=0.0116
[139] time=247.16, avg_loss=0.0056, train_err=0.1339
Eval: 128_h1=0.0162, 128_l2=0.0107
Eval: 128_h1=0.0077, 128_l2=0.0049
[155] time=130.34, avg_loss=0.0253, train_err=0.2027
Eval: 421_h1=0.0697, 421_l2=0.0113
[156] time=130.45, avg_loss=0.0255, train_err=0.2043
Eval: 421_h1=0.0699, 421_l2=0.0113
[140] time=260.78, avg_loss=0.0056, train_err=0.1332
Eval: 128_h1=0.0077, 128_l2=0.0051
[157] time=130.40, avg_loss=0.0254, train_err=0.2030
Eval: 421_h1=0.0699, 421_l2=0.0114
[75] time=479.44, avg_loss=0.0120, train_err=0.2881
Eval: 128_h1=0.0162, 128_l2=0.0108
[141] time=246.96, avg_loss=0.0054, train_err=0.1307
[158] time=130.42, avg_loss=0.0251, train_err=0.2008
Eval: 128_h1=0.0082, 128_l2=0.0054
Eval: 421_h1=0.0701, 421_l2=0.0118
[159] time=130.40, avg_loss=0.0250, train_err=0.1997
Eval: 421_h1=0.0701, 421_l2=0.0114
[142] time=246.16, avg_loss=0.0054, train_err=0.1304
Eval: 128_h1=0.0081, 128_l2=0.0053
[160] time=130.43, avg_loss=0.0256, train_err=0.2051
Eval: 421_h1=0.0697, 421_l2=0.0115
[76] time=454.79, avg_loss=0.0115, train_err=0.2764
[161] time=130.40, avg_loss=0.0263, train_err=0.2107
Eval: 128_h1=0.0160, 128_l2=0.0106
Eval: 421_h1=0.0701, 421_l2=0.0121
[143] time=248.17, avg_loss=0.0056, train_err=0.1348
Eval: 128_h1=0.0078, 128_l2=0.0059
[162] time=130.42, avg_loss=0.0267, train_err=0.2136
Eval: 421_h1=0.0703, 421_l2=0.0114
[163] time=130.40, avg_loss=0.0252, train_err=0.2019
Eval: 421_h1=0.0700, 421_l2=0.0114
[144] time=253.34, avg_loss=0.0060, train_err=0.1451
Eval: 128_h1=0.0077, 128_l2=0.0058
[164] time=130.44, avg_loss=0.0249, train_err=0.1995
Eval: 421_h1=0.0699, 421_l2=0.0116
[77] time=465.57, avg_loss=0.0114, train_err=0.2734
Eval: 128_h1=0.0158, 128_l2=0.0101
[165] time=130.40, avg_loss=0.0249, train_err=0.1988
Eval: 421_h1=0.0701, 421_l2=0.0114
[145] time=245.57, avg_loss=0.0056, train_err=0.1334
Eval: 128_h1=0.0077, 128_l2=0.0059
[166] time=130.41, avg_loss=0.0247, train_err=0.1978
Eval: 421_h1=0.0700, 421_l2=0.0114
[167] time=130.40, avg_loss=0.0250, train_err=0.2002
Eval: 421_h1=0.0702, 421_l2=0.0112
[146] time=258.33, avg_loss=0.0055, train_err=0.1316
Eval: 128_h1=0.0075, 128_l2=0.0054
[78] time=477.67, avg_loss=0.0115, train_err=0.2756
[168] time=130.42, avg_loss=0.0250, train_err=0.2004
Eval: 128_h1=0.0140, 128_l2=0.0083
Eval: 421_h1=0.0700, 421_l2=0.0115
[169] time=130.40, avg_loss=0.0250, train_err=0.1996
[147] time=251.62, avg_loss=0.0057, train_err=0.1365
Eval: 421_h1=0.0703, 421_l2=0.0116
Eval: 128_h1=0.0075, 128_l2=0.0049
[170] time=130.43, avg_loss=0.0251, train_err=0.2011
Eval: 421_h1=0.0703, 421_l2=0.0114
[148] time=247.55, avg_loss=0.0057, train_err=0.1357
[171] time=130.41, avg_loss=0.0250, train_err=0.2002
Eval: 128_h1=0.0075, 128_l2=0.0047
Eval: 421_h1=0.0702, 421_l2=0.0116
[79] time=458.50, avg_loss=0.0127, train_err=0.3040
Eval: 128_h1=0.0148, 128_l2=0.0087
[172] time=130.43, avg_loss=0.0258, train_err=0.2061
Eval: 421_h1=0.0705, 421_l2=0.0118
[149] time=244.93, avg_loss=0.0056, train_err=0.1354
Eval: 128_h1=0.0086, 128_l2=0.0057
[173] time=130.42, avg_loss=0.0254, train_err=0.2032
Eval: 421_h1=0.0706, 421_l2=0.0121
[174] time=130.42, avg_loss=0.0253, train_err=0.2026
Eval: 421_h1=0.0701, 421_l2=0.0117
[150] time=259.69, avg_loss=0.0060, train_err=0.1440
[80] time=474.19, avg_loss=0.0133, train_err=0.3189
Eval: 128_h1=0.0081, 128_l2=0.0053
Eval: 128_h1=0.0160, 128_l2=0.0102
[175] time=130.41, avg_loss=0.0248, train_err=0.1985
Eval: 421_h1=0.0701, 421_l2=0.0115
[176] time=130.43, avg_loss=0.0244, train_err=0.1952
Eval: 421_h1=0.0704, 421_l2=0.0115
[151] time=250.58, avg_loss=0.0060, train_err=0.1439
Eval: 128_h1=0.0080, 128_l2=0.0053
[177] time=130.41, avg_loss=0.0247, train_err=0.1974
Eval: 421_h1=0.0706, 421_l2=0.0115
[178] time=130.44, avg_loss=0.0244, train_err=0.1955
Eval: 421_h1=0.0701, 421_l2=0.0118
[81] time=462.03, avg_loss=0.0127, train_err=0.3036
Eval: 128_h1=0.0167, 128_l2=0.0109
[152] time=248.75, avg_loss=0.0059, train_err=0.1421
Eval: 128_h1=0.0079, 128_l2=0.0050
[179] time=130.41, avg_loss=0.0252, train_err=0.2016
Eval: 421_h1=0.0708, 421_l2=0.0122
[180] time=130.43, avg_loss=0.0239, train_err=0.1910
Eval: 421_h1=0.0702, 421_l2=0.0112
[153] time=246.32, avg_loss=0.0057, train_err=0.1375
Eval: 128_h1=0.0077, 128_l2=0.0051
[181] time=130.41, avg_loss=0.0227, train_err=0.1815
Eval: 421_h1=0.0705, 421_l2=0.0112
[82] time=470.11, avg_loss=0.0129, train_err=0.3101
Eval: 128_h1=0.0147, 128_l2=0.0093
[182] time=130.42, avg_loss=0.0224, train_err=0.1794
Eval: 421_h1=0.0708, 421_l2=0.0111
[154] time=260.32, avg_loss=0.0056, train_err=0.1345
Eval: 128_h1=0.0077, 128_l2=0.0050
[183] time=130.39, avg_loss=0.0223, train_err=0.1785
Eval: 421_h1=0.0709, 421_l2=0.0113
[155] time=251.00, avg_loss=0.0056, train_err=0.1355
[184] time=130.43, avg_loss=0.0223, train_err=0.1780
Eval: 128_h1=0.0078, 128_l2=0.0052
Eval: 421_h1=0.0710, 421_l2=0.0112
[185] time=130.42, avg_loss=0.0222, train_err=0.1776
[83] time=467.14, avg_loss=0.0128, train_err=0.3069
Eval: 421_h1=0.0712, 421_l2=0.0110
Eval: 128_h1=0.0141, 128_l2=0.0090
[156] time=249.46, avg_loss=0.0053, train_err=0.1272
Eval: 128_h1=0.0075, 128_l2=0.0053
[186] time=130.43, avg_loss=0.0222, train_err=0.1776
Eval: 421_h1=0.0713, 421_l2=0.0111
[187] time=130.40, avg_loss=0.0222, train_err=0.1772
Eval: 421_h1=0.0713, 421_l2=0.0111
[157] time=247.62, avg_loss=0.0051, train_err=0.1233
Eval: 128_h1=0.0073, 128_l2=0.0051
[188] time=130.42, avg_loss=0.0221, train_err=0.1771
Eval: 421_h1=0.0714, 421_l2=0.0113
[84] time=468.01, avg_loss=0.0113, train_err=0.2710
Eval: 128_h1=0.0137, 128_l2=0.0092
[189] time=130.40, avg_loss=0.0222, train_err=0.1773
Eval: 421_h1=0.0715, 421_l2=0.0112
[158] time=260.68, avg_loss=0.0051, train_err=0.1219
Eval: 128_h1=0.0073, 128_l2=0.0054
[190] time=130.41, avg_loss=0.0222, train_err=0.1778
Eval: 421_h1=0.0713, 421_l2=0.0112
[191] time=130.42, avg_loss=0.0224, train_err=0.1790
Eval: 421_h1=0.0718, 421_l2=0.0111
[159] time=249.29, avg_loss=0.0051, train_err=0.1235
Eval: 128_h1=0.0074, 128_l2=0.0052
[192] time=130.45, avg_loss=0.0225, train_err=0.1802
[85] time=468.97, avg_loss=0.0107, train_err=0.2558
Eval: 421_h1=0.0717, 421_l2=0.0112
Eval: 128_h1=0.0144, 128_l2=0.0101
[193] time=130.41, avg_loss=0.0225, train_err=0.1801
Eval: 421_h1=0.0716, 421_l2=0.0113
[160] time=251.34, avg_loss=0.0053, train_err=0.1277
Eval: 128_h1=0.0075, 128_l2=0.0045
[194] time=130.48, avg_loss=0.0224, train_err=0.1793
Eval: 421_h1=0.0714, 421_l2=0.0113
[195] time=130.41, avg_loss=0.0226, train_err=0.1805
Eval: 421_h1=0.0716, 421_l2=0.0113
[161] time=251.12, avg_loss=0.0053, train_err=0.1264
Eval: 128_h1=0.0073, 128_l2=0.0048
[86] time=469.85, avg_loss=0.0105, train_err=0.2518
Eval: 128_h1=0.0143, 128_l2=0.0097
[196] time=130.42, avg_loss=0.0224, train_err=0.1794
Eval: 421_h1=0.0719, 421_l2=0.0114
[197] time=130.39, avg_loss=0.0224, train_err=0.1788
[162] time=258.03, avg_loss=0.0052, train_err=0.1244
Eval: 421_h1=0.0714, 421_l2=0.0111
Eval: 128_h1=0.0079, 128_l2=0.0049
[198] time=130.41, avg_loss=0.0223, train_err=0.1785
Eval: 421_h1=0.0714, 421_l2=0.0113
[163] time=248.93, avg_loss=0.0053, train_err=0.1276
[87] time=470.40, avg_loss=0.0104, train_err=0.2494
[199] time=130.42, avg_loss=0.0226, train_err=0.1805
Eval: 128_h1=0.0078, 128_l2=0.0053
Eval: 421_h1=0.0716, 421_l2=0.0112
Eval: 128_h1=0.0138, 128_l2=0.0091
[200] time=130.42, avg_loss=0.0223, train_err=0.1784
Eval: 421_h1=0.0717, 421_l2=0.0113
[164] time=249.90, avg_loss=0.0053, train_err=0.1273
Eval: 128_h1=0.0074, 128_l2=0.0050
[201] time=130.41, avg_loss=0.0224, train_err=0.1794
Eval: 421_h1=0.0719, 421_l2=0.0112
[202] time=130.42, avg_loss=0.0222, train_err=0.1778
Eval: 421_h1=0.0716, 421_l2=0.0112
[88] time=458.97, avg_loss=0.0112, train_err=0.2689
Eval: 128_h1=0.0138, 128_l2=0.0080
[165] time=247.68, avg_loss=0.0056, train_err=0.1338
Eval: 128_h1=0.0078, 128_l2=0.0049
[203] time=130.41, avg_loss=0.0223, train_err=0.1783
Eval: 421_h1=0.0720, 421_l2=0.0114
[204] time=130.41, avg_loss=0.0225, train_err=0.1797
Eval: 421_h1=0.0719, 421_l2=0.0110
[166] time=249.23, avg_loss=0.0061, train_err=0.1470
Eval: 128_h1=0.0077, 128_l2=0.0051
[205] time=130.42, avg_loss=0.0222, train_err=0.1773
Eval: 421_h1=0.0718, 421_l2=0.0112
[89] time=449.14, avg_loss=0.0113, train_err=0.2709
Eval: 128_h1=0.0134, 128_l2=0.0082
[206] time=130.42, avg_loss=0.0222, train_err=0.1773
Eval: 421_h1=0.0721, 421_l2=0.0112
[167] time=234.47, avg_loss=0.0060, train_err=0.1435
Eval: 128_h1=0.0080, 128_l2=0.0053
[207] time=130.42, avg_loss=0.0221, train_err=0.1765
Eval: 421_h1=0.0720, 421_l2=0.0111
[168] time=235.40, avg_loss=0.0059, train_err=0.1427
[208] time=130.45, avg_loss=0.0221, train_err=0.1771
Eval: 128_h1=0.0079, 128_l2=0.0055
Eval: 421_h1=0.0721, 421_l2=0.0112
[90] time=432.26, avg_loss=0.0106, train_err=0.2535
[209] time=130.42, avg_loss=0.0221, train_err=0.1766
Eval: 128_h1=0.0131, 128_l2=0.0083
Eval: 421_h1=0.0720, 421_l2=0.0114
[169] time=247.00, avg_loss=0.0058, train_err=0.1401
Eval: 128_h1=0.0079, 128_l2=0.0057
[210] time=130.41, avg_loss=0.0221, train_err=0.1765
Eval: 421_h1=0.0721, 421_l2=0.0114
[211] time=130.40, avg_loss=0.0220, train_err=0.1764
Eval: 421_h1=0.0721, 421_l2=0.0114
[170] time=248.48, avg_loss=0.0057, train_err=0.1378
Eval: 128_h1=0.0079, 128_l2=0.0057
[212] time=130.42, avg_loss=0.0220, train_err=0.1762
Eval: 421_h1=0.0722, 421_l2=0.0112
[91] time=457.08, avg_loss=0.0103, train_err=0.2462
Eval: 128_h1=0.0129, 128_l2=0.0082
[213] time=130.40, avg_loss=0.0218, train_err=0.1748
Eval: 421_h1=0.0723, 421_l2=0.0112
[171] time=233.79, avg_loss=0.0056, train_err=0.1346
Eval: 128_h1=0.0078, 128_l2=0.0060
[214] time=130.41, avg_loss=0.0219, train_err=0.1753
Eval: 421_h1=0.0725, 421_l2=0.0113
[215] time=130.42, avg_loss=0.0219, train_err=0.1754
[172] time=235.41, avg_loss=0.0055, train_err=0.1309
Eval: 421_h1=0.0725, 421_l2=0.0114
Eval: 128_h1=0.0077, 128_l2=0.0059
[92] time=429.90, avg_loss=0.0100, train_err=0.2393
Eval: 128_h1=0.0130, 128_l2=0.0081
[216] time=130.42, avg_loss=0.0220, train_err=0.1760
Eval: 421_h1=0.0724, 421_l2=0.0112
[173] time=248.68, avg_loss=0.0053, train_err=0.1280
Eval: 128_h1=0.0075, 128_l2=0.0058
[217] time=130.42, avg_loss=0.0219, train_err=0.1754
Eval: 421_h1=0.0725, 421_l2=0.0115
[218] time=130.43, avg_loss=0.0219, train_err=0.1750
Eval: 421_h1=0.0725, 421_l2=0.0112
[174] time=256.54, avg_loss=0.0052, train_err=0.1259
Eval: 128_h1=0.0075, 128_l2=0.0059
[93] time=479.58, avg_loss=0.0098, train_err=0.2361
[219] time=130.40, avg_loss=0.0218, train_err=0.1745
Eval: 421_h1=0.0723, 421_l2=0.0113
Eval: 128_h1=0.0136, 128_l2=0.0088
[220] time=130.40, avg_loss=0.0218, train_err=0.1743
Eval: 421_h1=0.0723, 421_l2=0.0112
[175] time=260.75, avg_loss=0.0052, train_err=0.1255
Eval: 128_h1=0.0075, 128_l2=0.0060
[221] time=130.38, avg_loss=0.0218, train_err=0.1743
Eval: 421_h1=0.0724, 421_l2=0.0112
[222] time=130.43, avg_loss=0.0218, train_err=0.1743
Eval: 421_h1=0.0727, 421_l2=0.0113
[94] time=491.51, avg_loss=0.0101, train_err=0.2413
[176] time=259.94, avg_loss=0.0052, train_err=0.1240
Eval: 128_h1=0.0075, 128_l2=0.0059
Eval: 128_h1=0.0131, 128_l2=0.0080
[223] time=130.41, avg_loss=0.0218, train_err=0.1740
Eval: 421_h1=0.0723, 421_l2=0.0115
[224] time=130.42, avg_loss=0.0218, train_err=0.1746
Eval: 421_h1=0.0728, 421_l2=0.0114
[177] time=261.74, avg_loss=0.0051, train_err=0.1225
Eval: 128_h1=0.0075, 128_l2=0.0063
[225] time=130.40, avg_loss=0.0217, train_err=0.1738
Eval: 421_h1=0.0729, 421_l2=0.0113
[226] time=130.42, avg_loss=0.0219, train_err=0.1755
Eval: 421_h1=0.0728, 421_l2=0.0113
[95] time=515.72, avg_loss=0.0102, train_err=0.2452
Eval: 128_h1=0.0140, 128_l2=0.0084
[178] time=273.21, avg_loss=0.0054, train_err=0.1296
Eval: 128_h1=0.0081, 128_l2=0.0062
[227] time=130.38, avg_loss=0.0216, train_err=0.1731
Eval: 421_h1=0.0727, 421_l2=0.0114
[228] time=130.42, avg_loss=0.0216, train_err=0.1731
Eval: 421_h1=0.0726, 421_l2=0.0112
[179] time=250.71, avg_loss=0.0058, train_err=0.1387
Eval: 128_h1=0.0077, 128_l2=0.0052
[229] time=130.39, avg_loss=0.0215, train_err=0.1719
Eval: 421_h1=0.0728, 421_l2=0.0113
[96] time=468.46, avg_loss=0.0116, train_err=0.2778
[230] time=130.41, avg_loss=0.0215, train_err=0.1720
Eval: 128_h1=0.0175, 128_l2=0.0108
Eval: 421_h1=0.0730, 421_l2=0.0112
[180] time=251.85, avg_loss=0.0059, train_err=0.1406
Eval: 128_h1=0.0075, 128_l2=0.0048
[231] time=130.38, avg_loss=0.0216, train_err=0.1730
Eval: 421_h1=0.0727, 421_l2=0.0111
[232] time=130.39, avg_loss=0.0215, train_err=0.1719
Eval: 421_h1=0.0728, 421_l2=0.0111
[181] time=258.97, avg_loss=0.0058, train_err=0.1386
Eval: 128_h1=0.0075, 128_l2=0.0046
[233] time=130.37, avg_loss=0.0214, train_err=0.1710
Eval: 421_h1=0.0728, 421_l2=0.0114
[97] time=498.60, avg_loss=0.0119, train_err=0.2865
Eval: 128_h1=0.0167, 128_l2=0.0107
[234] time=130.39, avg_loss=0.0214, train_err=0.1715
Eval: 421_h1=0.0727, 421_l2=0.0115
[182] time=266.57, avg_loss=0.0059, train_err=0.1425
Eval: 128_h1=0.0077, 128_l2=0.0045
[235] time=130.38, avg_loss=0.0215, train_err=0.1718
Eval: 421_h1=0.0729, 421_l2=0.0111
[236] time=130.39, avg_loss=0.0213, train_err=0.1706
Eval: 421_h1=0.0725, 421_l2=0.0112
[183] time=255.74, avg_loss=0.0059, train_err=0.1416
Eval: 128_h1=0.0076, 128_l2=0.0046
[237] time=130.38, avg_loss=0.0213, train_err=0.1704
[98] time=480.82, avg_loss=0.0124, train_err=0.2964
Eval: 421_h1=0.0731, 421_l2=0.0113
Eval: 128_h1=0.0141, 128_l2=0.0090
[238] time=130.40, avg_loss=0.0213, train_err=0.1708
[184] time=256.72, avg_loss=0.0056, train_err=0.1346
Eval: 421_h1=0.0728, 421_l2=0.0114
Eval: 128_h1=0.0075, 128_l2=0.0045
[239] time=130.39, avg_loss=0.0215, train_err=0.1718
Eval: 421_h1=0.0728, 421_l2=0.0113
[240] time=130.40, avg_loss=0.0211, train_err=0.1685
[185] time=272.41, avg_loss=0.0053, train_err=0.1281
Eval: 421_h1=0.0728, 421_l2=0.0112
Eval: 128_h1=0.0073, 128_l2=0.0045
[99] time=518.65, avg_loss=0.0118, train_err=0.2831
[241] time=130.41, avg_loss=0.0205, train_err=0.1640
Eval: 421_h1=0.0733, 421_l2=0.0112
Eval: 128_h1=0.0129, 128_l2=0.0076
[186] time=261.74, avg_loss=0.0051, train_err=0.1227
[242] time=130.40, avg_loss=0.0204, train_err=0.1631
Eval: 128_h1=0.0077, 128_l2=0.0054
Eval: 421_h1=0.0734, 421_l2=0.0112
[243] time=130.42, avg_loss=0.0203, train_err=0.1628
Eval: 421_h1=0.0734, 421_l2=0.0112
[187] time=257.63, avg_loss=0.0050, train_err=0.1201
Eval: 128_h1=0.0071, 128_l2=0.0052
[244] time=130.40, avg_loss=0.0203, train_err=0.1625
Eval: 421_h1=0.0735, 421_l2=0.0112
[100] time=481.45, avg_loss=0.0100, train_err=0.2407
Eval: 128_h1=0.0120, 128_l2=0.0068
[245] time=130.37, avg_loss=0.0203, train_err=0.1624
Eval: 421_h1=0.0736, 421_l2=0.0112
[188] time=258.88, avg_loss=0.0049, train_err=0.1181
Eval: 128_h1=0.0071, 128_l2=0.0053
[246] time=130.39, avg_loss=0.0203, train_err=0.1622
Eval: 421_h1=0.0737, 421_l2=0.0112
[247] time=130.39, avg_loss=0.0203, train_err=0.1620
Eval: 421_h1=0.0737, 421_l2=0.0111
[189] time=269.48, avg_loss=0.0049, train_err=0.1171
Eval: 128_h1=0.0071, 128_l2=0.0053
[248] time=130.38, avg_loss=0.0202, train_err=0.1619
Eval: 421_h1=0.0738, 421_l2=0.0112
[101] time=507.50, avg_loss=0.0095, train_err=0.2290
Eval: 128_h1=0.0116, 128_l2=0.0065
[249] time=130.38, avg_loss=0.0202, train_err=0.1618
Eval: 421_h1=0.0738, 421_l2=0.0111
[190] time=249.28, avg_loss=0.0049, train_err=0.1163
Eval: 128_h1=0.0071, 128_l2=0.0056
[250] time=130.41, avg_loss=0.0202, train_err=0.1617
Eval: 421_h1=0.0739, 421_l2=0.0112
[251] time=130.41, avg_loss=0.0202, train_err=0.1616
Eval: 421_h1=0.0739, 421_l2=0.0112
[191] time=254.46, avg_loss=0.0050, train_err=0.1194
Eval: 128_h1=0.0073, 128_l2=0.0048
[102] time=468.76, avg_loss=0.0093, train_err=0.2228
Eval: 128_h1=0.0114, 128_l2=0.0063
[252] time=130.41, avg_loss=0.0202, train_err=0.1616
Eval: 421_h1=0.0739, 421_l2=0.0111
[253] time=130.43, avg_loss=0.0202, train_err=0.1615
Eval: 421_h1=0.0741, 421_l2=0.0113
[192] time=265.55, avg_loss=0.0050, train_err=0.1193
Eval: 128_h1=0.0072, 128_l2=0.0045
[254] time=130.40, avg_loss=0.0202, train_err=0.1617
Eval: 421_h1=0.0741, 421_l2=0.0112
[255] time=130.40, avg_loss=0.0202, train_err=0.1619
Eval: 421_h1=0.0742, 421_l2=0.0112
[103] time=518.00, avg_loss=0.0091, train_err=0.2171
[193] time=269.56, avg_loss=0.0051, train_err=0.1228
Eval: 128_h1=0.0077, 128_l2=0.0050
Eval: 128_h1=0.0112, 128_l2=0.0062
[256] time=130.45, avg_loss=0.0203, train_err=0.1627
Eval: 421_h1=0.0744, 421_l2=0.0113
[257] time=130.39, avg_loss=0.0203, train_err=0.1628
Eval: 421_h1=0.0743, 421_l2=0.0111
[194] time=250.31, avg_loss=0.0055, train_err=0.1308
Eval: 128_h1=0.0078, 128_l2=0.0050
[258] time=130.42, avg_loss=0.0203, train_err=0.1627
Eval: 421_h1=0.0740, 421_l2=0.0112
[104] time=470.28, avg_loss=0.0089, train_err=0.2126
[259] time=130.40, avg_loss=0.0204, train_err=0.1629
Eval: 421_h1=0.0744, 421_l2=0.0112
Eval: 128_h1=0.0111, 128_l2=0.0061
[195] time=255.59, avg_loss=0.0053, train_err=0.1262
Eval: 128_h1=0.0073, 128_l2=0.0045
[260] time=130.41, avg_loss=0.0203, train_err=0.1625
Eval: 421_h1=0.0741, 421_l2=0.0112
[261] time=130.39, avg_loss=0.0203, train_err=0.1623
Eval: 421_h1=0.0744, 421_l2=0.0112
[196] time=259.25, avg_loss=0.0051, train_err=0.1234
Eval: 128_h1=0.0077, 128_l2=0.0050
[262] time=130.39, avg_loss=0.0203, train_err=0.1620
Eval: 421_h1=0.0743, 421_l2=0.0113
[105] time=483.18, avg_loss=0.0087, train_err=0.2093
Eval: 128_h1=0.0110, 128_l2=0.0059
[263] time=130.38, avg_loss=0.0202, train_err=0.1619
[197] time=253.88, avg_loss=0.0053, train_err=0.1275
Eval: 421_h1=0.0744, 421_l2=0.0112
Eval: 128_h1=0.0080, 128_l2=0.0052
[264] time=130.39, avg_loss=0.0202, train_err=0.1617
Eval: 421_h1=0.0743, 421_l2=0.0112
[198] time=254.23, avg_loss=0.0050, train_err=0.1210
[265] time=130.38, avg_loss=0.0201, train_err=0.1609
Eval: 128_h1=0.0076, 128_l2=0.0050
Eval: 421_h1=0.0745, 421_l2=0.0112
[266] time=130.39, avg_loss=0.0201, train_err=0.1612
[106] time=473.67, avg_loss=0.0086, train_err=0.2060
Eval: 421_h1=0.0747, 421_l2=0.0113
Eval: 128_h1=0.0109, 128_l2=0.0058
[199] time=253.84, avg_loss=0.0051, train_err=0.1225
Eval: 128_h1=0.0076, 128_l2=0.0048
[267] time=130.38, avg_loss=0.0202, train_err=0.1616
Eval: 421_h1=0.0747, 421_l2=0.0112
[268] time=130.42, avg_loss=0.0201, train_err=0.1605
Eval: 421_h1=0.0745, 421_l2=0.0112
[200] time=257.70, avg_loss=0.0055, train_err=0.1330
Eval: 128_h1=0.0072, 128_l2=0.0047
[269] time=130.39, avg_loss=0.0200, train_err=0.1603
Eval: 421_h1=0.0745, 421_l2=0.0112
[107] time=481.51, avg_loss=0.0085, train_err=0.2029
Eval: 128_h1=0.0107, 128_l2=0.0057
[270] time=130.39, avg_loss=0.0200, train_err=0.1601
Eval: 421_h1=0.0747, 421_l2=0.0112
[201] time=256.62, avg_loss=0.0053, train_err=0.1261
Eval: 128_h1=0.0070, 128_l2=0.0047
[271] time=130.38, avg_loss=0.0201, train_err=0.1605
Eval: 421_h1=0.0747, 421_l2=0.0111
[272] time=130.39, avg_loss=0.0200, train_err=0.1602
Eval: 421_h1=0.0748, 421_l2=0.0111
[202] time=268.27, avg_loss=0.0051, train_err=0.1225
Eval: 128_h1=0.0069, 128_l2=0.0047
[273] time=130.39, avg_loss=0.0200, train_err=0.1601
Eval: 421_h1=0.0749, 421_l2=0.0112
[108] time=501.24, avg_loss=0.0083, train_err=0.2000
Eval: 128_h1=0.0106, 128_l2=0.0056
[274] time=130.46, avg_loss=0.0200, train_err=0.1598
Eval: 421_h1=0.0747, 421_l2=0.0112
[203] time=249.76, avg_loss=0.0050, train_err=0.1200
Eval: 128_h1=0.0069, 128_l2=0.0048
[275] time=130.42, avg_loss=0.0200, train_err=0.1596
Eval: 421_h1=0.0747, 421_l2=0.0112
[276] time=130.42, avg_loss=0.0199, train_err=0.1595
Eval: 421_h1=0.0748, 421_l2=0.0112
[204] time=257.76, avg_loss=0.0049, train_err=0.1180
Eval: 128_h1=0.0068, 128_l2=0.0048
[109] time=476.68, avg_loss=0.0082, train_err=0.1976
Eval: 128_h1=0.0105, 128_l2=0.0056
[277] time=130.40, avg_loss=0.0199, train_err=0.1595
Eval: 421_h1=0.0748, 421_l2=0.0112
[278] time=130.43, avg_loss=0.0200, train_err=0.1597
Eval: 421_h1=0.0749, 421_l2=0.0113
[205] time=264.35, avg_loss=0.0049, train_err=0.1164
Eval: 128_h1=0.0068, 128_l2=0.0049
[279] time=130.42, avg_loss=0.0199, train_err=0.1593
Eval: 421_h1=0.0748, 421_l2=0.0112
[280] time=130.38, avg_loss=0.0199, train_err=0.1594
Eval: 421_h1=0.0751, 421_l2=0.0112
[206] time=260.30, avg_loss=0.0048, train_err=0.1149
Eval: 128_h1=0.0068, 128_l2=0.0049
[110] time=496.76, avg_loss=0.0083, train_err=0.1988
Eval: 128_h1=0.0104, 128_l2=0.0055
[281] time=130.39, avg_loss=0.0199, train_err=0.1593
Eval: 421_h1=0.0750, 421_l2=0.0112
[282] time=130.44, avg_loss=0.0198, train_err=0.1588
Eval: 421_h1=0.0750, 421_l2=0.0112
[207] time=257.86, avg_loss=0.0047, train_err=0.1137
Eval: 128_h1=0.0068, 128_l2=0.0050
[283] time=130.39, avg_loss=0.0198, train_err=0.1586
Eval: 421_h1=0.0750, 421_l2=0.0112
[284] time=130.39, avg_loss=0.0198, train_err=0.1585
[111] time=486.27, avg_loss=0.0083, train_err=0.1981
[208] time=258.75, avg_loss=0.0047, train_err=0.1126
Eval: 421_h1=0.0751, 421_l2=0.0112
Eval: 128_h1=0.0068, 128_l2=0.0050
Eval: 128_h1=0.0104, 128_l2=0.0056
[285] time=130.39, avg_loss=0.0198, train_err=0.1584
Eval: 421_h1=0.0752, 421_l2=0.0112
[286] time=130.38, avg_loss=0.0198, train_err=0.1584
[209] time=264.39, avg_loss=0.0047, train_err=0.1115
Eval: 421_h1=0.0750, 421_l2=0.0112
Eval: 128_h1=0.0068, 128_l2=0.0051
[287] time=130.38, avg_loss=0.0198, train_err=0.1584
Eval: 421_h1=0.0755, 421_l2=0.0112
[112] time=506.34, avg_loss=0.0083, train_err=0.1982
Eval: 128_h1=0.0102, 128_l2=0.0055
[210] time=264.78, avg_loss=0.0046, train_err=0.1106
[288] time=130.38, avg_loss=0.0198, train_err=0.1583
Eval: 421_h1=0.0755, 421_l2=0.0112
Eval: 128_h1=0.0068, 128_l2=0.0051
[289] time=130.37, avg_loss=0.0197, train_err=0.1579
Eval: 421_h1=0.0750, 421_l2=0.0113
[211] time=264.77, avg_loss=0.0046, train_err=0.1097
[290] time=130.39, avg_loss=0.0197, train_err=0.1579
Eval: 128_h1=0.0069, 128_l2=0.0052
Eval: 421_h1=0.0753, 421_l2=0.0113
[291] time=130.38, avg_loss=0.0198, train_err=0.1580
Eval: 421_h1=0.0752, 421_l2=0.0112
[113] time=502.70, avg_loss=0.0079, train_err=0.1890
Eval: 128_h1=0.0101, 128_l2=0.0054
[212] time=263.43, avg_loss=0.0045, train_err=0.1089
[292] time=130.41, avg_loss=0.0197, train_err=0.1576
Eval: 128_h1=0.0069, 128_l2=0.0053
Eval: 421_h1=0.0755, 421_l2=0.0113
[293] time=130.38, avg_loss=0.0197, train_err=0.1574
Eval: 421_h1=0.0753, 421_l2=0.0112
[213] time=267.86, avg_loss=0.0045, train_err=0.1083
[294] time=130.42, avg_loss=0.0197, train_err=0.1574
Eval: 128_h1=0.0069, 128_l2=0.0053
Eval: 421_h1=0.0754, 421_l2=0.0112
[295] time=130.41, avg_loss=0.0197, train_err=0.1579
Eval: 421_h1=0.0757, 421_l2=0.0112
[114] time=506.85, avg_loss=0.0074, train_err=0.1781
Eval: 128_h1=0.0101, 128_l2=0.0055
[214] time=260.37, avg_loss=0.0045, train_err=0.1077
Eval: 128_h1=0.0070, 128_l2=0.0054
[296] time=130.41, avg_loss=0.0197, train_err=0.1573
Eval: 421_h1=0.0753, 421_l2=0.0114
[297] time=130.38, avg_loss=0.0196, train_err=0.1568
Eval: 421_h1=0.0756, 421_l2=0.0112
[215] time=257.90, avg_loss=0.0045, train_err=0.1072
Eval: 128_h1=0.0069, 128_l2=0.0054
[298] time=130.40, avg_loss=0.0196, train_err=0.1565
Eval: 421_h1=0.0754, 421_l2=0.0112
[115] time=476.93, avg_loss=0.0073, train_err=0.1761
Eval: 128_h1=0.0100, 128_l2=0.0055
[299] time=130.41, avg_loss=0.0196, train_err=0.1565
Eval: 421_h1=0.0758, 421_l2=0.0112
[216] time=249.89, avg_loss=0.0044, train_err=0.1066
Eval: 128_h1=0.0069, 128_l2=0.0053
[217] time=302.84, avg_loss=0.0044, train_err=0.1062
Eval: 128_h1=0.0069, 128_l2=0.0053
[116] time=555.92, avg_loss=0.0072, train_err=0.1732
Eval: 128_h1=0.0099, 128_l2=0.0052
[218] time=284.00, avg_loss=0.0044, train_err=0.1059
Eval: 128_h1=0.0068, 128_l2=0.0052
[219] time=281.72, avg_loss=0.0044, train_err=0.1063
Eval: 128_h1=0.0067, 128_l2=0.0051
[117] time=546.84, avg_loss=0.0071, train_err=0.1702
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260129_060014__L8HC2_421.log
Eval: 128_h1=0.0100, 128_l2=0.0053
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260129_060051__L8HC2_sta421.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [32, 32], 'hidden_channels': 32, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5, 'n_epochs': 300}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/Darcy_pt', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 421, 'n_tests': [224], 'test_resolutions': [421], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 421 with 224 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 32, 17]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 32, eps=1e-05, affine=True)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f2ba14bb4c0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f2ba14bba60>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f2ba14bba60>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f2ba14bba90>}

### Beginning Training...


n_params: 8935281
Training on 800 samples
Testing on [224] samples         on resolutions [421].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 421, 421])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260129_060151__L8HC2staNS.log
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260129_060203__L8HC2staNS.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_medium2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 4, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': False}, 'opt': {'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.0003, 'weight_decay': 0.0001, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 100, 'gamma': 0.5, 'n_epochs': 600}, 'data': {'_config_name': 'navierstokesdatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/V1e-3_N5000_T50', 'batch_size': 24, 'n_train': 10000, 'train_resolution': 128, 'n_tests': [2000], 'test_resolutions': [128], 'test_batch_sizes': [24], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'ns128_hc_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 128 with 2000 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 64, eps=1e-05, affine=True)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0001
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7fd1325de4f0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7fd1325de6a0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7fd1325de6a0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7fd1325de6d0>}

### Beginning Training...


n_params: 138506129
Training on 10000 samples
Testing on [2000] samples         on resolutions [128].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([24, 1, 128, 128])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=120.02, avg_loss=0.3519, train_err=2.8151
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
[220] time=295.26, avg_loss=0.0045, train_err=0.1074
Eval: 421_h1=0.1894, 421_l2=0.1026
Eval: 128_h1=0.0066, 128_l2=0.0050
[0] time=147.82, avg_loss=0.1155, train_err=2.7689
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 128_h1=0.0776, 128_l2=0.0542
[1] time=117.20, avg_loss=0.1641, train_err=1.3128
Eval: 421_h1=0.1422, 421_l2=0.0831
[1] time=146.42, avg_loss=0.0681, train_err=1.6337
[2] time=117.20, avg_loss=0.1381, train_err=1.1047
Eval: 128_h1=0.0625, 128_l2=0.0530
[221] time=258.46, avg_loss=0.0045, train_err=0.1069
Eval: 421_h1=0.1283, 421_l2=0.0761
Eval: 128_h1=0.0066, 128_l2=0.0049
[118] time=509.80, avg_loss=0.0070, train_err=0.1677
Eval: 128_h1=0.0099, 128_l2=0.0054
[3] time=117.22, avg_loss=0.1228, train_err=0.9826
Eval: 421_h1=0.1436, 421_l2=0.0839
[2] time=146.42, avg_loss=0.0566, train_err=1.3566
Eval: 128_h1=0.0545, 128_l2=0.0527
[4] time=117.20, avg_loss=0.1121, train_err=0.8969
[222] time=251.69, avg_loss=0.0045, train_err=0.1070
Eval: 421_h1=0.1103, 421_l2=0.0706
Eval: 128_h1=0.0066, 128_l2=0.0048
[3] time=146.46, avg_loss=0.0502, train_err=1.2034
Eval: 128_h1=0.0498, 128_l2=0.0514
[5] time=117.21, avg_loss=0.1017, train_err=0.8140
Eval: 421_h1=0.1026, 421_l2=0.0631
[4] time=146.43, avg_loss=0.0457, train_err=1.0950
Eval: 128_h1=0.0465, 128_l2=0.0498
[6] time=117.19, avg_loss=0.0987, train_err=0.7900
[223] time=247.32, avg_loss=0.0045, train_err=0.1082
Eval: 421_h1=0.0950, 421_l2=0.0535
Eval: 128_h1=0.0068, 128_l2=0.0049
[119] time=460.63, avg_loss=0.0070, train_err=0.1672
Eval: 128_h1=0.0099, 128_l2=0.0054
[5] time=146.45, avg_loss=0.0422, train_err=1.0124
Eval: 128_h1=0.0438, 128_l2=0.0479
[7] time=117.19, avg_loss=0.0913, train_err=0.7303
Eval: 421_h1=0.1002, 421_l2=0.0572
[6] time=146.43, avg_loss=0.0395, train_err=0.9466
Eval: 128_h1=0.0416, 128_l2=0.0460
[8] time=117.19, avg_loss=0.0844, train_err=0.6754
Eval: 421_h1=0.0886, 421_l2=0.0494
[224] time=259.00, avg_loss=0.0045, train_err=0.1069
Eval: 128_h1=0.0067, 128_l2=0.0047
[9] time=117.19, avg_loss=0.0820, train_err=0.6557
[7] time=146.44, avg_loss=0.0372, train_err=0.8918
Eval: 128_h1=0.0397, 128_l2=0.0440
Eval: 421_h1=0.0916, 421_l2=0.0466
[10] time=117.21, avg_loss=0.0817, train_err=0.6540
[120] time=461.29, avg_loss=0.0069, train_err=0.1650
[225] time=238.47, avg_loss=0.0044, train_err=0.1053
Eval: 421_h1=0.0857, 421_l2=0.0427
Eval: 128_h1=0.0067, 128_l2=0.0046
[8] time=146.50, avg_loss=0.0353, train_err=0.8454
Eval: 128_h1=0.0101, 128_l2=0.0056
Eval: 128_h1=0.0380, 128_l2=0.0421
[11] time=117.20, avg_loss=0.0825, train_err=0.6598
Eval: 421_h1=0.0842, 421_l2=0.0406
[9] time=146.43, avg_loss=0.0336, train_err=0.8055
Eval: 128_h1=0.0365, 128_l2=0.0402
[226] time=237.54, avg_loss=0.0043, train_err=0.1037
[12] time=117.19, avg_loss=0.0734, train_err=0.5874
Eval: 128_h1=0.0065, 128_l2=0.0044
Eval: 421_h1=0.0797, 421_l2=0.0384
[10] time=146.50, avg_loss=0.0321, train_err=0.7708
Eval: 128_h1=0.0353, 128_l2=0.0384
[13] time=117.19, avg_loss=0.0720, train_err=0.5759
Eval: 421_h1=0.0812, 421_l2=0.0383
[121] time=439.72, avg_loss=0.0067, train_err=0.1613
[11] time=146.53, avg_loss=0.0309, train_err=0.7410
Eval: 128_h1=0.0096, 128_l2=0.0052
Eval: 128_h1=0.0344, 128_l2=0.0367
[227] time=244.11, avg_loss=0.0042, train_err=0.1014
[14] time=117.19, avg_loss=0.0725, train_err=0.5799
Eval: 128_h1=0.0065, 128_l2=0.0045
Eval: 421_h1=0.0834, 421_l2=0.0381
[12] time=146.43, avg_loss=0.0298, train_err=0.7151
[15] time=117.19, avg_loss=0.0681, train_err=0.5450
Eval: 128_h1=0.0340, 128_l2=0.0353
Eval: 421_h1=0.0791, 421_l2=0.0360
[228] time=255.12, avg_loss=0.0042, train_err=0.1000
[16] time=117.18, avg_loss=0.0657, train_err=0.5256
Eval: 128_h1=0.0066, 128_l2=0.0046
Eval: 421_h1=0.0788, 421_l2=0.0364
[13] time=146.49, avg_loss=0.0289, train_err=0.6926
Eval: 128_h1=0.0329, 128_l2=0.0337
[17] time=117.19, avg_loss=0.0657, train_err=0.5258
Eval: 421_h1=0.0762, 421_l2=0.0309
[122] time=459.50, avg_loss=0.0066, train_err=0.1593
[14] time=146.43, avg_loss=0.0286, train_err=0.6854
Eval: 128_h1=0.0304, 128_l2=0.0312
Eval: 128_h1=0.0096, 128_l2=0.0051
[229] time=235.31, avg_loss=0.0041, train_err=0.0989
Eval: 128_h1=0.0067, 128_l2=0.0047
[18] time=117.19, avg_loss=0.0635, train_err=0.5081
Eval: 421_h1=0.0796, 421_l2=0.0355
[15] time=146.42, avg_loss=0.0292, train_err=0.6999
Eval: 128_h1=0.0291, 128_l2=0.0298
[19] time=117.19, avg_loss=0.0678, train_err=0.5425
Eval: 421_h1=0.0736, 421_l2=0.0275
[16] time=146.52, avg_loss=0.0269, train_err=0.6452
Eval: 128_h1=0.0284, 128_l2=0.0288
[230] time=237.48, avg_loss=0.0041, train_err=0.0977
Eval: 128_h1=0.0065, 128_l2=0.0044
[20] time=117.19, avg_loss=0.0620, train_err=0.4963
Eval: 421_h1=0.0744, 421_l2=0.0263
[123] time=434.71, avg_loss=0.0067, train_err=0.1599
[17] time=146.49, avg_loss=0.0258, train_err=0.6195
Eval: 128_h1=0.0095, 128_l2=0.0051
Eval: 128_h1=0.0276, 128_l2=0.0275
[21] time=117.20, avg_loss=0.0605, train_err=0.4843
Eval: 421_h1=0.0840, 421_l2=0.0403
[231] time=245.84, avg_loss=0.0040, train_err=0.0968
Eval: 128_h1=0.0064, 128_l2=0.0041
[22] time=117.18, avg_loss=0.0624, train_err=0.4988
[18] time=146.45, avg_loss=0.0251, train_err=0.6031
Eval: 421_h1=0.0746, 421_l2=0.0299
Eval: 128_h1=0.0268, 128_l2=0.0259
[23] time=117.18, avg_loss=0.0637, train_err=0.5097
Eval: 421_h1=0.0731, 421_l2=0.0261
[19] time=146.43, avg_loss=0.0245, train_err=0.5887
Eval: 128_h1=0.0262, 128_l2=0.0246
[232] time=253.00, avg_loss=0.0040, train_err=0.0959
Eval: 128_h1=0.0064, 128_l2=0.0040
[24] time=117.19, avg_loss=0.0638, train_err=0.5102
Eval: 421_h1=0.0743, 421_l2=0.0283
[124] time=461.91, avg_loss=0.0066, train_err=0.1575
[20] time=146.48, avg_loss=0.0247, train_err=0.5928
Eval: 128_h1=0.0274, 128_l2=0.0242
Eval: 128_h1=0.0094, 128_l2=0.0050
[25] time=117.21, avg_loss=0.0584, train_err=0.4675
Eval: 421_h1=0.0728, 421_l2=0.0255
[21] time=146.42, avg_loss=0.0240, train_err=0.5762
[233] time=232.52, avg_loss=0.0040, train_err=0.0954
Eval: 128_h1=0.0264, 128_l2=0.0225
Eval: 128_h1=0.0064, 128_l2=0.0041
[26] time=117.22, avg_loss=0.0549, train_err=0.4394
Eval: 421_h1=0.0763, 421_l2=0.0310
[22] time=146.44, avg_loss=0.0232, train_err=0.5575
Eval: 128_h1=0.0252, 128_l2=0.0213
[27] time=117.20, avg_loss=0.0631, train_err=0.5045
Eval: 421_h1=0.0785, 421_l2=0.0304
[234] time=236.19, avg_loss=0.0040, train_err=0.0948
Eval: 128_h1=0.0063, 128_l2=0.0039
[125] time=427.18, avg_loss=0.0064, train_err=0.1543
[23] time=146.45, avg_loss=0.0228, train_err=0.5463
Eval: 128_h1=0.0094, 128_l2=0.0050
[28] time=117.19, avg_loss=0.0550, train_err=0.4403
Eval: 128_h1=0.0241, 128_l2=0.0203
Eval: 421_h1=0.0706, 421_l2=0.0234
[29] time=117.19, avg_loss=0.0593, train_err=0.4745
Eval: 421_h1=0.0743, 421_l2=0.0266
[24] time=146.50, avg_loss=0.0220, train_err=0.5271
Eval: 128_h1=0.0228, 128_l2=0.0198
[235] time=243.49, avg_loss=0.0039, train_err=0.0942
Eval: 128_h1=0.0063, 128_l2=0.0039
[30] time=117.18, avg_loss=0.0530, train_err=0.4238
Eval: 421_h1=0.0715, 421_l2=0.0224
[25] time=146.42, avg_loss=0.0215, train_err=0.5167
Eval: 128_h1=0.0228, 128_l2=0.0189
[31] time=117.19, avg_loss=0.0525, train_err=0.4201
Eval: 421_h1=0.0749, 421_l2=0.0286
[126] time=464.42, avg_loss=0.0065, train_err=0.1548
[26] time=146.49, avg_loss=0.0212, train_err=0.5077
[236] time=252.84, avg_loss=0.0039, train_err=0.0938
Eval: 128_h1=0.0234, 128_l2=0.0181
Eval: 128_h1=0.0063, 128_l2=0.0038
Eval: 128_h1=0.0094, 128_l2=0.0050
[32] time=117.19, avg_loss=0.0578, train_err=0.4627
Eval: 421_h1=0.0733, 421_l2=0.0233
[27] time=146.49, avg_loss=0.0210, train_err=0.5034
Eval: 128_h1=0.0238, 128_l2=0.0178
[33] time=117.21, avg_loss=0.0534, train_err=0.4272
Eval: 421_h1=0.0756, 421_l2=0.0294
[237] time=233.83, avg_loss=0.0039, train_err=0.0935
Eval: 128_h1=0.0062, 128_l2=0.0038
[28] time=146.48, avg_loss=0.0219, train_err=0.5251
Eval: 128_h1=0.0212, 128_l2=0.0165
[34] time=117.21, avg_loss=0.0540, train_err=0.4317
Eval: 421_h1=0.0689, 421_l2=0.0214
[127] time=428.98, avg_loss=0.0066, train_err=0.1576
[35] time=117.19, avg_loss=0.0514, train_err=0.4111
[29] time=146.46, avg_loss=0.0204, train_err=0.4889
Eval: 421_h1=0.0713, 421_l2=0.0259
Eval: 128_h1=0.0094, 128_l2=0.0050
Eval: 128_h1=0.0212, 128_l2=0.0160
[238] time=237.39, avg_loss=0.0039, train_err=0.0935
Eval: 128_h1=0.0062, 128_l2=0.0038
[36] time=117.19, avg_loss=0.0508, train_err=0.4063
Eval: 421_h1=0.0688, 421_l2=0.0209
[30] time=146.43, avg_loss=0.0194, train_err=0.4649
Eval: 128_h1=0.0207, 128_l2=0.0156
[37] time=117.19, avg_loss=0.0513, train_err=0.4103
Eval: 421_h1=0.0724, 421_l2=0.0289
[239] time=247.70, avg_loss=0.0039, train_err=0.0941
Eval: 128_h1=0.0062, 128_l2=0.0037
[31] time=146.49, avg_loss=0.0188, train_err=0.4508
Eval: 128_h1=0.0203, 128_l2=0.0151
[38] time=117.19, avg_loss=0.0515, train_err=0.4118
Eval: 421_h1=0.0702, 421_l2=0.0234
[32] time=146.44, avg_loss=0.0186, train_err=0.4472
[128] time=463.31, avg_loss=0.0070, train_err=0.1681
Eval: 128_h1=0.0198, 128_l2=0.0148
Eval: 128_h1=0.0100, 128_l2=0.0056
[39] time=117.19, avg_loss=0.0492, train_err=0.3939
Eval: 421_h1=0.0706, 421_l2=0.0240
[240] time=249.79, avg_loss=0.0040, train_err=0.0967
Eval: 128_h1=0.0064, 128_l2=0.0046
[33] time=146.49, avg_loss=0.0185, train_err=0.4443
Eval: 128_h1=0.0195, 128_l2=0.0143
[40] time=117.19, avg_loss=0.0517, train_err=0.4132
Eval: 421_h1=0.0701, 421_l2=0.0215
[34] time=146.46, avg_loss=0.0184, train_err=0.4409
[41] time=117.19, avg_loss=0.0481, train_err=0.3850
Eval: 128_h1=0.0194, 128_l2=0.0143
Eval: 421_h1=0.0707, 421_l2=0.0238
[241] time=235.89, avg_loss=0.0041, train_err=0.0983
Eval: 128_h1=0.0063, 128_l2=0.0042
[42] time=117.21, avg_loss=0.0472, train_err=0.3778
[129] time=432.69, avg_loss=0.0073, train_err=0.1756
Eval: 421_h1=0.0696, 421_l2=0.0186
[35] time=146.45, avg_loss=0.0190, train_err=0.4549
Eval: 128_h1=0.0195, 128_l2=0.0144
Eval: 128_h1=0.0105, 128_l2=0.0059
[43] time=117.22, avg_loss=0.0522, train_err=0.4179
[242] time=236.69, avg_loss=0.0041, train_err=0.0976
Eval: 421_h1=0.0823, 421_l2=0.0312
Eval: 128_h1=0.0064, 128_l2=0.0041
[36] time=146.48, avg_loss=0.0186, train_err=0.4472
Eval: 128_h1=0.0190, 128_l2=0.0137
[44] time=117.22, avg_loss=0.0510, train_err=0.4078
Eval: 421_h1=0.0707, 421_l2=0.0231
[37] time=148.28, avg_loss=0.0180, train_err=0.4321
Eval: 128_h1=0.0190, 128_l2=0.0136
[45] time=117.20, avg_loss=0.0465, train_err=0.3720
[243] time=247.12, avg_loss=0.0041, train_err=0.0980
Eval: 421_h1=0.0689, 421_l2=0.0182
Eval: 128_h1=0.0065, 128_l2=0.0044
[130] time=454.66, avg_loss=0.0071, train_err=0.1698
[38] time=148.10, avg_loss=0.0176, train_err=0.4213
Eval: 128_h1=0.0189, 128_l2=0.0136
Eval: 128_h1=0.0103, 128_l2=0.0058
[46] time=117.21, avg_loss=0.0465, train_err=0.3721
Eval: 421_h1=0.0686, 421_l2=0.0196
[39] time=146.40, avg_loss=0.0174, train_err=0.4170
Eval: 128_h1=0.0188, 128_l2=0.0132
[47] time=117.20, avg_loss=0.0532, train_err=0.4254
[244] time=249.45, avg_loss=0.0043, train_err=0.1024
Eval: 421_h1=0.0689, 421_l2=0.0191
Eval: 128_h1=0.0072, 128_l2=0.0055
[48] time=117.20, avg_loss=0.0467, train_err=0.3732
Eval: 421_h1=0.0737, 421_l2=0.0286
[40] time=161.27, avg_loss=0.0171, train_err=0.4103
Eval: 128_h1=0.0185, 128_l2=0.0128
[245] time=238.80, avg_loss=0.0043, train_err=0.1028
[49] time=117.23, avg_loss=0.0494, train_err=0.3949
Eval: 128_h1=0.0067, 128_l2=0.0050
Eval: 421_h1=0.0690, 421_l2=0.0192
[131] time=442.40, avg_loss=0.0071, train_err=0.1709
Eval: 128_h1=0.0104, 128_l2=0.0060
[41] time=165.76, avg_loss=0.0182, train_err=0.4375
Eval: 128_h1=0.0290, 128_l2=0.0201
[50] time=117.21, avg_loss=0.0457, train_err=0.3652
Eval: 421_h1=0.0677, 421_l2=0.0183
[246] time=238.60, avg_loss=0.0042, train_err=0.1006
[42] time=166.32, avg_loss=0.0192, train_err=0.4598
Eval: 128_h1=0.0257, 128_l2=0.0168
Eval: 128_h1=0.0066, 128_l2=0.0048
[51] time=117.22, avg_loss=0.0482, train_err=0.3853
Eval: 421_h1=0.0697, 421_l2=0.0215
[52] time=117.22, avg_loss=0.0450, train_err=0.3598
Eval: 421_h1=0.0678, 421_l2=0.0169
[43] time=166.34, avg_loss=0.0179, train_err=0.4286
Eval: 128_h1=0.0268, 128_l2=0.0177
[247] time=255.91, avg_loss=0.0042, train_err=0.1000
[132] time=459.95, avg_loss=0.0071, train_err=0.1703
[53] time=117.23, avg_loss=0.0442, train_err=0.3534
Eval: 128_h1=0.0066, 128_l2=0.0049
Eval: 421_h1=0.0707, 421_l2=0.0216
Eval: 128_h1=0.0102, 128_l2=0.0058
[44] time=166.47, avg_loss=0.0174, train_err=0.4177
Eval: 128_h1=0.0267, 128_l2=0.0179
[54] time=117.21, avg_loss=0.0445, train_err=0.3557
Eval: 421_h1=0.0757, 421_l2=0.0305
[45] time=166.35, avg_loss=0.0170, train_err=0.4070
[248] time=249.66, avg_loss=0.0041, train_err=0.0993
Eval: 128_h1=0.0247, 128_l2=0.0167
[55] time=117.22, avg_loss=0.0460, train_err=0.3679
Eval: 128_h1=0.0066, 128_l2=0.0049
Eval: 421_h1=0.0680, 421_l2=0.0180
[56] time=117.22, avg_loss=0.0445, train_err=0.3563
Eval: 421_h1=0.0706, 421_l2=0.0181
[46] time=165.88, avg_loss=0.0165, train_err=0.3946
Eval: 128_h1=0.0212, 128_l2=0.0137
[133] time=450.15, avg_loss=0.0071, train_err=0.1700
Eval: 128_h1=0.0096, 128_l2=0.0052
[249] time=238.99, avg_loss=0.0041, train_err=0.0986
Eval: 128_h1=0.0067, 128_l2=0.0050
[57] time=117.26, avg_loss=0.0449, train_err=0.3593
Eval: 421_h1=0.0689, 421_l2=0.0180
[47] time=166.07, avg_loss=0.0155, train_err=0.3724
Eval: 128_h1=0.0174, 128_l2=0.0109
[58] time=117.22, avg_loss=0.0450, train_err=0.3602
Eval: 421_h1=0.0768, 421_l2=0.0320
[250] time=240.53, avg_loss=0.0041, train_err=0.0977
Eval: 128_h1=0.0067, 128_l2=0.0050
[48] time=166.42, avg_loss=0.0146, train_err=0.3503
[59] time=117.22, avg_loss=0.0489, train_err=0.3915
Eval: 128_h1=0.0169, 128_l2=0.0111
Eval: 421_h1=0.0701, 421_l2=0.0216
[60] time=117.21, avg_loss=0.0381, train_err=0.3047
Eval: 421_h1=0.0656, 421_l2=0.0153
[134] time=453.55, avg_loss=0.0070, train_err=0.1681
[49] time=166.37, avg_loss=0.0145, train_err=0.3475
Eval: 128_h1=0.0170, 128_l2=0.0107
Eval: 128_h1=0.0096, 128_l2=0.0051
[251] time=256.47, avg_loss=0.0040, train_err=0.0965
Eval: 128_h1=0.0065, 128_l2=0.0046
[61] time=117.21, avg_loss=0.0354, train_err=0.2831
Eval: 421_h1=0.0661, 421_l2=0.0161
[50] time=166.56, avg_loss=0.0145, train_err=0.3466
Eval: 128_h1=0.0171, 128_l2=0.0106
[62] time=117.31, avg_loss=0.0346, train_err=0.2765
Eval: 421_h1=0.0666, 421_l2=0.0159
[252] time=246.55, avg_loss=0.0040, train_err=0.0951
Eval: 128_h1=0.0064, 128_l2=0.0042
[51] time=166.58, avg_loss=0.0144, train_err=0.3460
[63] time=117.22, avg_loss=0.0347, train_err=0.2777
Eval: 128_h1=0.0166, 128_l2=0.0105
Eval: 421_h1=0.0662, 421_l2=0.0152
[135] time=457.41, avg_loss=0.0067, train_err=0.1596
[64] time=117.22, avg_loss=0.0339, train_err=0.2711
Eval: 128_h1=0.0095, 128_l2=0.0052
Eval: 421_h1=0.0662, 421_l2=0.0148
[52] time=166.48, avg_loss=0.0154, train_err=0.3693
Eval: 128_h1=0.0173, 128_l2=0.0118
[253] time=244.99, avg_loss=0.0039, train_err=0.0939
Eval: 128_h1=0.0064, 128_l2=0.0042
[65] time=117.21, avg_loss=0.0341, train_err=0.2726
Eval: 421_h1=0.0664, 421_l2=0.0146
[53] time=166.04, avg_loss=0.0148, train_err=0.3561
Eval: 128_h1=0.0166, 128_l2=0.0106
[66] time=117.21, avg_loss=0.0338, train_err=0.2703
Eval: 421_h1=0.0663, 421_l2=0.0141
[254] time=249.36, avg_loss=0.0039, train_err=0.0932
Eval: 128_h1=0.0064, 128_l2=0.0043
[54] time=166.42, avg_loss=0.0146, train_err=0.3506
[67] time=117.23, avg_loss=0.0340, train_err=0.2717
Eval: 128_h1=0.0165, 128_l2=0.0102
Eval: 421_h1=0.0665, 421_l2=0.0143
[136] time=466.89, avg_loss=0.0065, train_err=0.1552
Eval: 128_h1=0.0094, 128_l2=0.0052
[68] time=117.21, avg_loss=0.0343, train_err=0.2741
Eval: 421_h1=0.0668, 421_l2=0.0143
[55] time=166.58, avg_loss=0.0145, train_err=0.3475
Eval: 128_h1=0.0164, 128_l2=0.0102
[255] time=258.90, avg_loss=0.0039, train_err=0.0923
Eval: 128_h1=0.0064, 128_l2=0.0042
[69] time=117.22, avg_loss=0.0367, train_err=0.2939
Eval: 421_h1=0.0690, 421_l2=0.0180
[56] time=166.10, avg_loss=0.0136, train_err=0.3251
Eval: 128_h1=0.0161, 128_l2=0.0099
[70] time=117.26, avg_loss=0.0357, train_err=0.2860
Eval: 421_h1=0.0682, 421_l2=0.0185
[256] time=243.11, avg_loss=0.0038, train_err=0.0916
Eval: 128_h1=0.0063, 128_l2=0.0040
[71] time=117.22, avg_loss=0.0364, train_err=0.2916
[57] time=166.39, avg_loss=0.0137, train_err=0.3282
Eval: 128_h1=0.0167, 128_l2=0.0108
Eval: 421_h1=0.0675, 421_l2=0.0160
[137] time=460.45, avg_loss=0.0064, train_err=0.1537
Eval: 128_h1=0.0092, 128_l2=0.0051
[72] time=117.22, avg_loss=0.0341, train_err=0.2727
Eval: 421_h1=0.0670, 421_l2=0.0141
[58] time=166.42, avg_loss=0.0139, train_err=0.3333
Eval: 128_h1=0.0160, 128_l2=0.0101
[257] time=240.90, avg_loss=0.0038, train_err=0.0911
Eval: 128_h1=0.0062, 128_l2=0.0039
[73] time=117.23, avg_loss=0.0358, train_err=0.2864
Eval: 421_h1=0.0678, 421_l2=0.0161
[59] time=166.57, avg_loss=0.0148, train_err=0.3545
Eval: 128_h1=0.0165, 128_l2=0.0102
[74] time=117.23, avg_loss=0.0350, train_err=0.2798
Eval: 421_h1=0.0673, 421_l2=0.0149
[258] time=250.58, avg_loss=0.0038, train_err=0.0907
Eval: 128_h1=0.0062, 128_l2=0.0038
[138] time=458.76, avg_loss=0.0063, train_err=0.1510
[75] time=117.22, avg_loss=0.0344, train_err=0.2753
[60] time=166.67, avg_loss=0.0160, train_err=0.3839
Eval: 421_h1=0.0674, 421_l2=0.0143
Eval: 128_h1=0.0092, 128_l2=0.0052
Eval: 128_h1=0.0185, 128_l2=0.0120
[76] time=117.23, avg_loss=0.0344, train_err=0.2750
Eval: 421_h1=0.0675, 421_l2=0.0151
[61] time=166.55, avg_loss=0.0158, train_err=0.3790
Eval: 128_h1=0.0249, 128_l2=0.0185
[259] time=247.99, avg_loss=0.0038, train_err=0.0906
Eval: 128_h1=0.0061, 128_l2=0.0037
[77] time=117.22, avg_loss=0.0341, train_err=0.2731
Eval: 421_h1=0.0674, 421_l2=0.0136
[62] time=166.79, avg_loss=0.0155, train_err=0.3727
Eval: 128_h1=0.0216, 128_l2=0.0151
[78] time=117.22, avg_loss=0.0338, train_err=0.2701
Eval: 421_h1=0.0675, 421_l2=0.0138
[139] time=456.46, avg_loss=0.0065, train_err=0.1560
[260] time=245.78, avg_loss=0.0038, train_err=0.0904
Eval: 128_h1=0.0110, 128_l2=0.0065
Eval: 128_h1=0.0061, 128_l2=0.0037
[79] time=117.22, avg_loss=0.0374, train_err=0.2991
[63] time=158.85, avg_loss=0.0145, train_err=0.3472
Eval: 128_h1=0.0200, 128_l2=0.0135
Eval: 421_h1=0.0755, 421_l2=0.0258
[80] time=117.21, avg_loss=0.0369, train_err=0.2952
Eval: 421_h1=0.0676, 421_l2=0.0141
[64] time=148.19, avg_loss=0.0139, train_err=0.3342
Eval: 128_h1=0.0178, 128_l2=0.0114
[261] time=245.21, avg_loss=0.0038, train_err=0.0904
Eval: 128_h1=0.0061, 128_l2=0.0037
[81] time=117.22, avg_loss=0.0337, train_err=0.2697
Eval: 421_h1=0.0679, 421_l2=0.0152
[65] time=149.92, avg_loss=0.0138, train_err=0.3305
Eval: 128_h1=0.0170, 128_l2=0.0106
[82] time=117.22, avg_loss=0.0334, train_err=0.2670
Eval: 421_h1=0.0691, 421_l2=0.0178
[140] time=459.88, avg_loss=0.0065, train_err=0.1553
Eval: 128_h1=0.0097, 128_l2=0.0054
[66] time=146.38, avg_loss=0.0135, train_err=0.3229
Eval: 128_h1=0.0171, 128_l2=0.0106
[262] time=254.51, avg_loss=0.0038, train_err=0.0906
Eval: 128_h1=0.0061, 128_l2=0.0038
[83] time=117.21, avg_loss=0.0337, train_err=0.2700
Eval: 421_h1=0.0674, 421_l2=0.0136
[67] time=146.47, avg_loss=0.0134, train_err=0.3219
Eval: 128_h1=0.0183, 128_l2=0.0118
[84] time=117.22, avg_loss=0.0328, train_err=0.2621
Eval: 421_h1=0.0681, 421_l2=0.0154
[263] time=243.20, avg_loss=0.0038, train_err=0.0911
Eval: 128_h1=0.0063, 128_l2=0.0043
[68] time=146.40, avg_loss=0.0135, train_err=0.3241
[85] time=117.23, avg_loss=0.0333, train_err=0.2664
Eval: 128_h1=0.0178, 128_l2=0.0112
Eval: 421_h1=0.0689, 421_l2=0.0153
[141] time=443.01, avg_loss=0.0062, train_err=0.1484
Eval: 128_h1=0.0095, 128_l2=0.0051
[86] time=117.22, avg_loss=0.0349, train_err=0.2788
Eval: 421_h1=0.0685, 421_l2=0.0160
[69] time=146.45, avg_loss=0.0133, train_err=0.3189
Eval: 128_h1=0.0178, 128_l2=0.0112
[264] time=233.90, avg_loss=0.0039, train_err=0.0937
Eval: 128_h1=0.0064, 128_l2=0.0046
[87] time=117.22, avg_loss=0.0358, train_err=0.2861
Eval: 421_h1=0.0684, 421_l2=0.0155
[70] time=148.20, avg_loss=0.0148, train_err=0.3541
Eval: 128_h1=0.0164, 128_l2=0.0113
[88] time=117.21, avg_loss=0.0340, train_err=0.2722
Eval: 421_h1=0.0678, 421_l2=0.0146
[265] time=236.61, avg_loss=0.0040, train_err=0.0955
Eval: 128_h1=0.0062, 128_l2=0.0041
[71] time=150.00, avg_loss=0.0126, train_err=0.3028
Eval: 128_h1=0.0153, 128_l2=0.0090
[89] time=117.22, avg_loss=0.0347, train_err=0.2774
Eval: 421_h1=0.0708, 421_l2=0.0208
[142] time=436.94, avg_loss=0.0061, train_err=0.1464
Eval: 128_h1=0.0092, 128_l2=0.0050
[72] time=148.18, avg_loss=0.0120, train_err=0.2879
Eval: 128_h1=0.0147, 128_l2=0.0084
[90] time=117.21, avg_loss=0.0338, train_err=0.2701
Eval: 421_h1=0.0679, 421_l2=0.0134
[266] time=252.72, avg_loss=0.0039, train_err=0.0946
Eval: 128_h1=0.0062, 128_l2=0.0040
[73] time=146.35, avg_loss=0.0117, train_err=0.2798
[91] time=117.23, avg_loss=0.0325, train_err=0.2599
Eval: 128_h1=0.0143, 128_l2=0.0084
Eval: 421_h1=0.0680, 421_l2=0.0136
[92] time=117.21, avg_loss=0.0332, train_err=0.2653
Eval: 421_h1=0.0679, 421_l2=0.0137
[74] time=146.37, avg_loss=0.0117, train_err=0.2798
Eval: 128_h1=0.0144, 128_l2=0.0085
[267] time=242.35, avg_loss=0.0039, train_err=0.0940
Eval: 128_h1=0.0062, 128_l2=0.0039
[143] time=453.04, avg_loss=0.0060, train_err=0.1442
[93] time=117.21, avg_loss=0.0333, train_err=0.2665
Eval: 128_h1=0.0092, 128_l2=0.0049
Eval: 421_h1=0.0686, 421_l2=0.0148
[75] time=146.40, avg_loss=0.0116, train_err=0.2782
Eval: 128_h1=0.0146, 128_l2=0.0090
[94] time=117.20, avg_loss=0.0333, train_err=0.2663
Eval: 421_h1=0.0680, 421_l2=0.0141
[268] time=233.72, avg_loss=0.0039, train_err=0.0938
Eval: 128_h1=0.0062, 128_l2=0.0039
[76] time=146.43, avg_loss=0.0118, train_err=0.2820
Eval: 128_h1=0.0149, 128_l2=0.0087
[95] time=117.20, avg_loss=0.0325, train_err=0.2597
Eval: 421_h1=0.0674, 421_l2=0.0133
[77] time=146.38, avg_loss=0.0124, train_err=0.2973
Eval: 128_h1=0.0146, 128_l2=0.0093
[96] time=117.20, avg_loss=0.0323, train_err=0.2587
Eval: 421_h1=0.0677, 421_l2=0.0131
[269] time=235.67, avg_loss=0.0039, train_err=0.0937
Eval: 128_h1=0.0062, 128_l2=0.0040
[144] time=429.72, avg_loss=0.0061, train_err=0.1463
Eval: 128_h1=0.0092, 128_l2=0.0050
[78] time=146.49, avg_loss=0.0130, train_err=0.3108
Eval: 128_h1=0.0147, 128_l2=0.0093
[97] time=117.20, avg_loss=0.0317, train_err=0.2534
Eval: 421_h1=0.0675, 421_l2=0.0137
[98] time=117.20, avg_loss=0.0334, train_err=0.2674
[79] time=146.49, avg_loss=0.0132, train_err=0.3170
Eval: 421_h1=0.0687, 421_l2=0.0141
Eval: 128_h1=0.0151, 128_l2=0.0089
[270] time=253.55, avg_loss=0.0039, train_err=0.0936
Eval: 128_h1=0.0062, 128_l2=0.0040
[99] time=117.21, avg_loss=0.0355, train_err=0.2844
Eval: 421_h1=0.0716, 421_l2=0.0160
[80] time=146.37, avg_loss=0.0127, train_err=0.3042
Eval: 128_h1=0.0147, 128_l2=0.0085
[100] time=117.20, avg_loss=0.0354, train_err=0.2836
[145] time=462.06, avg_loss=0.0065, train_err=0.1558
Eval: 421_h1=0.0695, 421_l2=0.0171
[271] time=242.09, avg_loss=0.0039, train_err=0.0934
Eval: 128_h1=0.0107, 128_l2=0.0059
Eval: 128_h1=0.0062, 128_l2=0.0039
[81] time=146.43, avg_loss=0.0122, train_err=0.2933
Eval: 128_h1=0.0144, 128_l2=0.0086
[101] time=117.20, avg_loss=0.0341, train_err=0.2729
Eval: 421_h1=0.0683, 421_l2=0.0140
[82] time=146.44, avg_loss=0.0119, train_err=0.2854
Eval: 128_h1=0.0146, 128_l2=0.0088
[102] time=117.21, avg_loss=0.0322, train_err=0.2577
[272] time=234.11, avg_loss=0.0039, train_err=0.0930
Eval: 421_h1=0.0690, 421_l2=0.0138
Eval: 128_h1=0.0062, 128_l2=0.0039
[83] time=146.38, avg_loss=0.0113, train_err=0.2711
Eval: 128_h1=0.0144, 128_l2=0.0087
[103] time=117.21, avg_loss=0.0314, train_err=0.2514
Eval: 421_h1=0.0697, 421_l2=0.0155
[146] time=428.49, avg_loss=0.0072, train_err=0.1720
Eval: 128_h1=0.0098, 128_l2=0.0054
[273] time=236.95, avg_loss=0.0039, train_err=0.0926
[84] time=146.41, avg_loss=0.0109, train_err=0.2605
[104] time=117.20, avg_loss=0.0315, train_err=0.2521
Eval: 128_h1=0.0139, 128_l2=0.0083
Eval: 128_h1=0.0062, 128_l2=0.0038
Eval: 421_h1=0.0680, 421_l2=0.0137
[105] time=117.20, avg_loss=0.0331, train_err=0.2650
Eval: 421_h1=0.0685, 421_l2=0.0139
[85] time=146.47, avg_loss=0.0108, train_err=0.2598
Eval: 128_h1=0.0144, 128_l2=0.0090
[274] time=239.56, avg_loss=0.0038, train_err=0.0923
Eval: 128_h1=0.0062, 128_l2=0.0038
[106] time=117.19, avg_loss=0.0334, train_err=0.2668
Eval: 421_h1=0.0689, 421_l2=0.0156
[86] time=146.44, avg_loss=0.0111, train_err=0.2664
Eval: 128_h1=0.0158, 128_l2=0.0108
[107] time=117.20, avg_loss=0.0317, train_err=0.2534
[147] time=443.22, avg_loss=0.0074, train_err=0.1765
Eval: 421_h1=0.0682, 421_l2=0.0135
Eval: 128_h1=0.0103, 128_l2=0.0059
[87] time=146.42, avg_loss=0.0119, train_err=0.2865
Eval: 128_h1=0.0149, 128_l2=0.0095
[275] time=245.96, avg_loss=0.0038, train_err=0.0919
Eval: 128_h1=0.0062, 128_l2=0.0038
[108] time=117.19, avg_loss=0.0314, train_err=0.2511
Eval: 421_h1=0.0687, 421_l2=0.0151
[88] time=146.40, avg_loss=0.0129, train_err=0.3101
Eval: 128_h1=0.0180, 128_l2=0.0109
[109] time=117.19, avg_loss=0.0327, train_err=0.2612
Eval: 421_h1=0.0686, 421_l2=0.0138
[276] time=242.62, avg_loss=0.0038, train_err=0.0915
[89] time=146.40, avg_loss=0.0142, train_err=0.3406
Eval: 128_h1=0.0062, 128_l2=0.0038
Eval: 128_h1=0.0154, 128_l2=0.0108
[110] time=117.19, avg_loss=0.0332, train_err=0.2655
Eval: 421_h1=0.0685, 421_l2=0.0139
[148] time=448.59, avg_loss=0.0075, train_err=0.1798
Eval: 128_h1=0.0115, 128_l2=0.0069
[111] time=117.19, avg_loss=0.0326, train_err=0.2604
[90] time=146.46, avg_loss=0.0124, train_err=0.2973
Eval: 421_h1=0.0686, 421_l2=0.0138
Eval: 128_h1=0.0141, 128_l2=0.0087
[277] time=242.74, avg_loss=0.0038, train_err=0.0910
Eval: 128_h1=0.0062, 128_l2=0.0037
[112] time=117.19, avg_loss=0.0316, train_err=0.2529
Eval: 421_h1=0.0683, 421_l2=0.0127
[91] time=146.46, avg_loss=0.0113, train_err=0.2708
Eval: 128_h1=0.0158, 128_l2=0.0107
[113] time=117.20, avg_loss=0.0319, train_err=0.2551
Eval: 421_h1=0.0719, 421_l2=0.0206
[92] time=146.45, avg_loss=0.0109, train_err=0.2608
Eval: 128_h1=0.0140, 128_l2=0.0091
[278] time=246.79, avg_loss=0.0038, train_err=0.0905
Eval: 128_h1=0.0062, 128_l2=0.0037
[114] time=117.18, avg_loss=0.0320, train_err=0.2561
Eval: 421_h1=0.0684, 421_l2=0.0138
[149] time=452.88, avg_loss=0.0073, train_err=0.1760
Eval: 128_h1=0.0099, 128_l2=0.0052
[93] time=146.50, avg_loss=0.0105, train_err=0.2524
Eval: 128_h1=0.0136, 128_l2=0.0089
[115] time=117.19, avg_loss=0.0337, train_err=0.2700
Eval: 421_h1=0.0694, 421_l2=0.0169
[279] time=249.17, avg_loss=0.0038, train_err=0.0900
[94] time=146.47, avg_loss=0.0105, train_err=0.2509
Eval: 128_h1=0.0061, 128_l2=0.0037
Eval: 128_h1=0.0137, 128_l2=0.0099
[116] time=117.19, avg_loss=0.0320, train_err=0.2557
Eval: 421_h1=0.0688, 421_l2=0.0140
[95] time=146.44, avg_loss=0.0102, train_err=0.2447
[117] time=117.18, avg_loss=0.0313, train_err=0.2505
Eval: 128_h1=0.0133, 128_l2=0.0095
Eval: 421_h1=0.0688, 421_l2=0.0135
[280] time=250.11, avg_loss=0.0037, train_err=0.0897
Eval: 128_h1=0.0061, 128_l2=0.0037
[150] time=464.21, avg_loss=0.0073, train_err=0.1746
[118] time=117.21, avg_loss=0.0305, train_err=0.2441
Eval: 421_h1=0.0686, 421_l2=0.0140
Eval: 128_h1=0.0100, 128_l2=0.0052
[96] time=146.47, avg_loss=0.0122, train_err=0.2918
Eval: 128_h1=0.0158, 128_l2=0.0095
[119] time=117.21, avg_loss=0.0303, train_err=0.2426
Eval: 421_h1=0.0685, 421_l2=0.0129
[97] time=146.41, avg_loss=0.0127, train_err=0.3041
Eval: 128_h1=0.0147, 128_l2=0.0087
[281] time=247.10, avg_loss=0.0037, train_err=0.0894
Eval: 128_h1=0.0061, 128_l2=0.0037
[120] time=117.19, avg_loss=0.0285, train_err=0.2278
Eval: 421_h1=0.0678, 421_l2=0.0126
[98] time=146.52, avg_loss=0.0120, train_err=0.2872
Eval: 128_h1=0.0142, 128_l2=0.0094
[121] time=117.20, avg_loss=0.0269, train_err=0.2150
Eval: 421_h1=0.0682, 421_l2=0.0122
[151] time=457.23, avg_loss=0.0075, train_err=0.1796
[282] time=246.48, avg_loss=0.0037, train_err=0.0893
[99] time=146.49, avg_loss=0.0105, train_err=0.2521
Eval: 128_h1=0.0061, 128_l2=0.0037
Eval: 128_h1=0.0136, 128_l2=0.0092
Eval: 128_h1=0.0105, 128_l2=0.0059
[122] time=117.19, avg_loss=0.0264, train_err=0.2109
Eval: 421_h1=0.0684, 421_l2=0.0123
[100] time=146.43, avg_loss=0.0102, train_err=0.2452
Eval: 128_h1=0.0128, 128_l2=0.0072
[123] time=117.18, avg_loss=0.0262, train_err=0.2097
Eval: 421_h1=0.0684, 421_l2=0.0122
[283] time=249.72, avg_loss=0.0037, train_err=0.0894
Eval: 128_h1=0.0063, 128_l2=0.0037
[124] time=117.19, avg_loss=0.0261, train_err=0.2087
[101] time=146.45, avg_loss=0.0097, train_err=0.2332
Eval: 421_h1=0.0685, 421_l2=0.0120
Eval: 128_h1=0.0123, 128_l2=0.0069
[125] time=117.21, avg_loss=0.0260, train_err=0.2078
Eval: 421_h1=0.0688, 421_l2=0.0130
[102] time=146.38, avg_loss=0.0095, train_err=0.2283
[152] time=465.17, avg_loss=0.0078, train_err=0.1867
Eval: 128_h1=0.0121, 128_l2=0.0068
Eval: 128_h1=0.0103, 128_l2=0.0059
[284] time=249.95, avg_loss=0.0038, train_err=0.0920
Eval: 128_h1=0.0063, 128_l2=0.0040
[126] time=117.19, avg_loss=0.0261, train_err=0.2089
Eval: 421_h1=0.0687, 421_l2=0.0122
[103] time=146.46, avg_loss=0.0093, train_err=0.2242
Eval: 128_h1=0.0119, 128_l2=0.0065
[127] time=117.19, avg_loss=0.0259, train_err=0.2074
Eval: 421_h1=0.0690, 421_l2=0.0120
[104] time=146.44, avg_loss=0.0092, train_err=0.2207
[285] time=246.84, avg_loss=0.0040, train_err=0.0970
Eval: 128_h1=0.0116, 128_l2=0.0063
Eval: 128_h1=0.0063, 128_l2=0.0046
[128] time=117.19, avg_loss=0.0262, train_err=0.2096
Eval: 421_h1=0.0689, 421_l2=0.0121
[105] time=146.44, avg_loss=0.0091, train_err=0.2176
Eval: 128_h1=0.0115, 128_l2=0.0061
[153] time=458.01, avg_loss=0.0076, train_err=0.1814
[129] time=117.18, avg_loss=0.0263, train_err=0.2100
Eval: 421_h1=0.0688, 421_l2=0.0122
Eval: 128_h1=0.0099, 128_l2=0.0055
[286] time=248.12, avg_loss=0.0044, train_err=0.1052
Eval: 128_h1=0.0064, 128_l2=0.0046
[106] time=146.43, avg_loss=0.0090, train_err=0.2148
[130] time=117.20, avg_loss=0.0263, train_err=0.2103
Eval: 128_h1=0.0115, 128_l2=0.0062
Eval: 421_h1=0.0690, 421_l2=0.0121
[131] time=117.19, avg_loss=0.0263, train_err=0.2106
Eval: 421_h1=0.0688, 421_l2=0.0120
[107] time=146.48, avg_loss=0.0088, train_err=0.2122
Eval: 128_h1=0.0116, 128_l2=0.0063
[287] time=248.31, avg_loss=0.0045, train_err=0.1085
Eval: 128_h1=0.0067, 128_l2=0.0051
[132] time=117.19, avg_loss=0.0263, train_err=0.2104
Eval: 421_h1=0.0692, 421_l2=0.0120
[108] time=146.47, avg_loss=0.0087, train_err=0.2097
Eval: 128_h1=0.0116, 128_l2=0.0064
[154] time=462.25, avg_loss=0.0072, train_err=0.1723
Eval: 128_h1=0.0095, 128_l2=0.0050
[133] time=117.21, avg_loss=0.0265, train_err=0.2118
Eval: 421_h1=0.0692, 421_l2=0.0121
[109] time=146.42, avg_loss=0.0087, train_err=0.2074
Eval: 128_h1=0.0116, 128_l2=0.0064
[288] time=251.70, avg_loss=0.0045, train_err=0.1081
Eval: 128_h1=0.0064, 128_l2=0.0048
[134] time=117.19, avg_loss=0.0267, train_err=0.2139
Eval: 421_h1=0.0694, 421_l2=0.0122
[110] time=146.42, avg_loss=0.0086, train_err=0.2055
Eval: 128_h1=0.0116, 128_l2=0.0064
[135] time=117.18, avg_loss=0.0267, train_err=0.2137
Eval: 421_h1=0.0694, 421_l2=0.0119
[289] time=249.75, avg_loss=0.0045, train_err=0.1076
Eval: 128_h1=0.0063, 128_l2=0.0046
[111] time=146.43, avg_loss=0.0085, train_err=0.2039
Eval: 128_h1=0.0115, 128_l2=0.0064
[136] time=117.19, avg_loss=0.0267, train_err=0.2136
Eval: 421_h1=0.0694, 421_l2=0.0121
[155] time=464.43, avg_loss=0.0068, train_err=0.1629
Eval: 128_h1=0.0093, 128_l2=0.0047
[137] time=117.17, avg_loss=0.0267, train_err=0.2137
[112] time=146.46, avg_loss=0.0084, train_err=0.2025
Eval: 421_h1=0.0695, 421_l2=0.0123
Eval: 128_h1=0.0115, 128_l2=0.0063
[290] time=249.61, avg_loss=0.0045, train_err=0.1069
Eval: 128_h1=0.0063, 128_l2=0.0045
[138] time=117.18, avg_loss=0.0270, train_err=0.2157
Eval: 421_h1=0.0695, 421_l2=0.0124
[113] time=146.42, avg_loss=0.0084, train_err=0.2014
Eval: 128_h1=0.0115, 128_l2=0.0063
[139] time=117.19, avg_loss=0.0264, train_err=0.2112
Eval: 421_h1=0.0695, 421_l2=0.0125
[114] time=146.49, avg_loss=0.0084, train_err=0.2004
Eval: 128_h1=0.0115, 128_l2=0.0064
[291] time=250.69, avg_loss=0.0044, train_err=0.1055
Eval: 128_h1=0.0063, 128_l2=0.0045
[140] time=117.18, avg_loss=0.0262, train_err=0.2096
[156] time=465.40, avg_loss=0.0065, train_err=0.1567
Eval: 421_h1=0.0694, 421_l2=0.0124
Eval: 128_h1=0.0090, 128_l2=0.0045
[115] time=146.47, avg_loss=0.0084, train_err=0.2009
Eval: 128_h1=0.0116, 128_l2=0.0063
[141] time=117.19, avg_loss=0.0261, train_err=0.2091
Eval: 421_h1=0.0699, 421_l2=0.0130
[292] time=252.66, avg_loss=0.0043, train_err=0.1036
Eval: 128_h1=0.0063, 128_l2=0.0045
[116] time=146.40, avg_loss=0.0086, train_err=0.2066
Eval: 128_h1=0.0118, 128_l2=0.0065
[142] time=117.19, avg_loss=0.0265, train_err=0.2118
Eval: 421_h1=0.0697, 421_l2=0.0119
[117] time=146.40, avg_loss=0.0088, train_err=0.2101
[143] time=117.19, avg_loss=0.0264, train_err=0.2109
Eval: 128_h1=0.0116, 128_l2=0.0062
Eval: 421_h1=0.0696, 421_l2=0.0129
[293] time=247.60, avg_loss=0.0042, train_err=0.1015
Eval: 128_h1=0.0063, 128_l2=0.0046
[157] time=462.68, avg_loss=0.0063, train_err=0.1513
Eval: 128_h1=0.0089, 128_l2=0.0044
[144] time=117.19, avg_loss=0.0261, train_err=0.2090
Eval: 421_h1=0.0697, 421_l2=0.0121
[118] time=146.39, avg_loss=0.0085, train_err=0.2035
Eval: 128_h1=0.0114, 128_l2=0.0060
[145] time=117.21, avg_loss=0.0261, train_err=0.2084
Eval: 421_h1=0.0698, 421_l2=0.0119
[119] time=146.43, avg_loss=0.0083, train_err=0.1981
Eval: 128_h1=0.0109, 128_l2=0.0057
[294] time=238.41, avg_loss=0.0041, train_err=0.0994
Eval: 128_h1=0.0063, 128_l2=0.0046
[146] time=117.20, avg_loss=0.0260, train_err=0.2079
Eval: 421_h1=0.0696, 421_l2=0.0123
[120] time=146.43, avg_loss=0.0080, train_err=0.1923
Eval: 128_h1=0.0106, 128_l2=0.0056
[147] time=117.21, avg_loss=0.0262, train_err=0.2093
Eval: 421_h1=0.0696, 421_l2=0.0126
[158] time=432.73, avg_loss=0.0062, train_err=0.1478
Eval: 128_h1=0.0088, 128_l2=0.0044
[295] time=238.17, avg_loss=0.0040, train_err=0.0971
Eval: 128_h1=0.0063, 128_l2=0.0046
[121] time=146.44, avg_loss=0.0077, train_err=0.1847
Eval: 128_h1=0.0107, 128_l2=0.0059
[148] time=117.19, avg_loss=0.0264, train_err=0.2109
Eval: 421_h1=0.0699, 421_l2=0.0130
[122] time=146.44, avg_loss=0.0075, train_err=0.1794
Eval: 128_h1=0.0107, 128_l2=0.0061
[149] time=117.19, avg_loss=0.0262, train_err=0.2099
Eval: 421_h1=0.0704, 421_l2=0.0120
[296] time=254.38, avg_loss=0.0040, train_err=0.0947
Eval: 128_h1=0.0062, 128_l2=0.0045
[150] time=117.19, avg_loss=0.0261, train_err=0.2085
[123] time=146.42, avg_loss=0.0073, train_err=0.1742
Eval: 421_h1=0.0699, 421_l2=0.0129
Eval: 128_h1=0.0106, 128_l2=0.0063
[159] time=452.45, avg_loss=0.0060, train_err=0.1430
[151] time=117.18, avg_loss=0.0263, train_err=0.2106
Eval: 128_h1=0.0089, 128_l2=0.0047
Eval: 421_h1=0.0704, 421_l2=0.0133
[124] time=146.47, avg_loss=0.0071, train_err=0.1710
Eval: 128_h1=0.0104, 128_l2=0.0061
[297] time=232.09, avg_loss=0.0039, train_err=0.0925
Eval: 128_h1=0.0061, 128_l2=0.0042
[152] time=117.20, avg_loss=0.0283, train_err=0.2264
Eval: 421_h1=0.0701, 421_l2=0.0124
[125] time=146.38, avg_loss=0.0070, train_err=0.1685
Eval: 128_h1=0.0102, 128_l2=0.0058
[153] time=117.20, avg_loss=0.0259, train_err=0.2075
Eval: 421_h1=0.0702, 421_l2=0.0121
[298] time=237.74, avg_loss=0.0038, train_err=0.0908
Eval: 128_h1=0.0060, 128_l2=0.0039
[126] time=146.43, avg_loss=0.0070, train_err=0.1676
Eval: 128_h1=0.0100, 128_l2=0.0055
[154] time=117.19, avg_loss=0.0256, train_err=0.2049
Eval: 421_h1=0.0704, 421_l2=0.0126
[160] time=433.99, avg_loss=0.0058, train_err=0.1380
Eval: 128_h1=0.0093, 128_l2=0.0053
[127] time=146.40, avg_loss=0.0070, train_err=0.1682
Eval: 128_h1=0.0100, 128_l2=0.0056
[155] time=117.19, avg_loss=0.0254, train_err=0.2029
Eval: 421_h1=0.0702, 421_l2=0.0121
[299] time=242.05, avg_loss=0.0037, train_err=0.0897
Eval: 128_h1=0.0061, 128_l2=0.0039
[128] time=146.40, avg_loss=0.0070, train_err=0.1685
[156] time=117.21, avg_loss=0.0257, train_err=0.2053
Eval: 128_h1=0.0102, 128_l2=0.0060
Eval: 421_h1=0.0700, 421_l2=0.0124
[157] time=117.18, avg_loss=0.0255, train_err=0.2041
Eval: 421_h1=0.0703, 421_l2=0.0127
[129] time=146.40, avg_loss=0.0072, train_err=0.1735
Eval: 128_h1=0.0103, 128_l2=0.0058
[300] time=254.38, avg_loss=0.0043, train_err=0.1043
Eval: 128_h1=0.0062, 128_l2=0.0035
[158] time=117.19, avg_loss=0.0257, train_err=0.2052
[161] time=461.65, avg_loss=0.0057, train_err=0.1373
Eval: 421_h1=0.0700, 421_l2=0.0120
Eval: 128_h1=0.0092, 128_l2=0.0054
[130] time=146.38, avg_loss=0.0075, train_err=0.1787
Eval: 128_h1=0.0105, 128_l2=0.0057
[159] time=117.19, avg_loss=0.0254, train_err=0.2032
Eval: 421_h1=0.0704, 421_l2=0.0118
[301] time=234.07, avg_loss=0.0042, train_err=0.1006
Eval: 128_h1=0.0062, 128_l2=0.0035
[131] time=146.45, avg_loss=0.0076, train_err=0.1814
Eval: 128_h1=0.0107, 128_l2=0.0059
[160] time=117.19, avg_loss=0.0253, train_err=0.2026
Eval: 421_h1=0.0704, 421_l2=0.0125
[132] time=146.43, avg_loss=0.0074, train_err=0.1771
Eval: 128_h1=0.0106, 128_l2=0.0058
[161] time=117.18, avg_loss=0.0253, train_err=0.2023
[302] time=237.83, avg_loss=0.0041, train_err=0.0981
Eval: 421_h1=0.0704, 421_l2=0.0119
Eval: 128_h1=0.0061, 128_l2=0.0035
[162] time=430.44, avg_loss=0.0059, train_err=0.1424
Eval: 128_h1=0.0091, 128_l2=0.0052
[133] time=147.59, avg_loss=0.0071, train_err=0.1702
Eval: 128_h1=0.0105, 128_l2=0.0058
[162] time=117.21, avg_loss=0.0253, train_err=0.2020
Eval: 421_h1=0.0704, 421_l2=0.0123
[163] time=117.19, avg_loss=0.0253, train_err=0.2025
[303] time=247.28, avg_loss=0.0040, train_err=0.0965
[134] time=146.42, avg_loss=0.0069, train_err=0.1650
Eval: 421_h1=0.0702, 421_l2=0.0120
Eval: 128_h1=0.0061, 128_l2=0.0034
Eval: 128_h1=0.0103, 128_l2=0.0057
[164] time=117.18, avg_loss=0.0252, train_err=0.2013
Eval: 421_h1=0.0703, 421_l2=0.0126
[135] time=146.38, avg_loss=0.0067, train_err=0.1616
Eval: 128_h1=0.0101, 128_l2=0.0058
[165] time=117.18, avg_loss=0.0259, train_err=0.2071
[304] time=251.13, avg_loss=0.0040, train_err=0.0953
Eval: 421_h1=0.0703, 421_l2=0.0129
Eval: 128_h1=0.0061, 128_l2=0.0034
[163] time=465.03, avg_loss=0.0061, train_err=0.1455
Eval: 128_h1=0.0090, 128_l2=0.0049
[136] time=146.46, avg_loss=0.0066, train_err=0.1591
Eval: 128_h1=0.0099, 128_l2=0.0057
[166] time=117.21, avg_loss=0.0259, train_err=0.2071
Eval: 421_h1=0.0704, 421_l2=0.0120
[137] time=146.49, avg_loss=0.0066, train_err=0.1587
Eval: 128_h1=0.0099, 128_l2=0.0055
[305] time=231.45, avg_loss=0.0039, train_err=0.0943
[167] time=117.19, avg_loss=0.0251, train_err=0.2006
Eval: 128_h1=0.0061, 128_l2=0.0034
Eval: 421_h1=0.0702, 421_l2=0.0119
[138] time=146.44, avg_loss=0.0067, train_err=0.1595
Eval: 128_h1=0.0100, 128_l2=0.0055
[168] time=117.21, avg_loss=0.0252, train_err=0.2014
Eval: 421_h1=0.0702, 421_l2=0.0121
[164] time=424.12, avg_loss=0.0058, train_err=0.1397
Eval: 128_h1=0.0087, 128_l2=0.0045
[306] time=235.02, avg_loss=0.0039, train_err=0.0935
Eval: 128_h1=0.0061, 128_l2=0.0034
[169] time=117.20, avg_loss=0.0251, train_err=0.2012
[139] time=146.49, avg_loss=0.0070, train_err=0.1689
Eval: 128_h1=0.0101, 128_l2=0.0064
Eval: 421_h1=0.0707, 421_l2=0.0117
[170] time=117.21, avg_loss=0.0252, train_err=0.2014
Eval: 421_h1=0.0705, 421_l2=0.0125
[140] time=146.45, avg_loss=0.0077, train_err=0.1852
Eval: 128_h1=0.0109, 128_l2=0.0057
[307] time=247.05, avg_loss=0.0039, train_err=0.0928
Eval: 128_h1=0.0060, 128_l2=0.0034
[171] time=117.19, avg_loss=0.0251, train_err=0.2009
Eval: 421_h1=0.0702, 421_l2=0.0121
[141] time=146.46, avg_loss=0.0080, train_err=0.1930
Eval: 128_h1=0.0108, 128_l2=0.0055
[172] time=117.18, avg_loss=0.0247, train_err=0.1978
Eval: 421_h1=0.0706, 421_l2=0.0121
[165] time=461.88, avg_loss=0.0059, train_err=0.1413
Eval: 128_h1=0.0094, 128_l2=0.0051
[142] time=146.48, avg_loss=0.0078, train_err=0.1881
Eval: 128_h1=0.0109, 128_l2=0.0058
[308] time=249.22, avg_loss=0.0038, train_err=0.0922
Eval: 128_h1=0.0060, 128_l2=0.0034
[173] time=117.20, avg_loss=0.0250, train_err=0.1999
Eval: 421_h1=0.0711, 421_l2=0.0129
[143] time=146.44, avg_loss=0.0077, train_err=0.1846
Eval: 128_h1=0.0109, 128_l2=0.0060
[174] time=117.19, avg_loss=0.0255, train_err=0.2037
Eval: 421_h1=0.0712, 421_l2=0.0137
[309] time=233.74, avg_loss=0.0038, train_err=0.0916
Eval: 128_h1=0.0060, 128_l2=0.0034
[144] time=146.43, avg_loss=0.0075, train_err=0.1788
Eval: 128_h1=0.0109, 128_l2=0.0062
[175] time=117.19, avg_loss=0.0260, train_err=0.2083
Eval: 421_h1=0.0707, 421_l2=0.0125
[166] time=429.33, avg_loss=0.0060, train_err=0.1446
Eval: 128_h1=0.0088, 128_l2=0.0046
[176] time=117.19, avg_loss=0.0259, train_err=0.2073
[145] time=146.43, avg_loss=0.0071, train_err=0.1715
Eval: 421_h1=0.0705, 421_l2=0.0120
Eval: 128_h1=0.0106, 128_l2=0.0057
[310] time=238.60, avg_loss=0.0038, train_err=0.0911
Eval: 128_h1=0.0060, 128_l2=0.0033
[177] time=117.21, avg_loss=0.0253, train_err=0.2021
Eval: 421_h1=0.0703, 421_l2=0.0123
[146] time=146.43, avg_loss=0.0068, train_err=0.1627
Eval: 128_h1=0.0100, 128_l2=0.0050
[178] time=117.20, avg_loss=0.0248, train_err=0.1982
Eval: 421_h1=0.0706, 421_l2=0.0121
[147] time=146.45, avg_loss=0.0065, train_err=0.1560
Eval: 128_h1=0.0097, 128_l2=0.0050
[311] time=249.95, avg_loss=0.0038, train_err=0.0906
Eval: 128_h1=0.0060, 128_l2=0.0033
[179] time=117.19, avg_loss=0.0245, train_err=0.1962
Eval: 421_h1=0.0706, 421_l2=0.0119
[167] time=461.37, avg_loss=0.0061, train_err=0.1452
Eval: 128_h1=0.0092, 128_l2=0.0051
[148] time=146.44, avg_loss=0.0063, train_err=0.1518
Eval: 128_h1=0.0094, 128_l2=0.0050
[180] time=117.22, avg_loss=0.0238, train_err=0.1906
Eval: 421_h1=0.0703, 421_l2=0.0118
[312] time=251.59, avg_loss=0.0038, train_err=0.0901
Eval: 128_h1=0.0060, 128_l2=0.0033
[149] time=146.42, avg_loss=0.0063, train_err=0.1517
Eval: 128_h1=0.0094, 128_l2=0.0053
[181] time=117.19, avg_loss=0.0229, train_err=0.1830
Eval: 421_h1=0.0709, 421_l2=0.0117
[182] time=117.19, avg_loss=0.0227, train_err=0.1816
[150] time=146.39, avg_loss=0.0064, train_err=0.1540
Eval: 128_h1=0.0094, 128_l2=0.0055
Eval: 421_h1=0.0709, 421_l2=0.0119
[313] time=234.06, avg_loss=0.0037, train_err=0.0897
Eval: 128_h1=0.0060, 128_l2=0.0033
[168] time=435.25, avg_loss=0.0069, train_err=0.1662
[183] time=117.21, avg_loss=0.0226, train_err=0.1806
Eval: 128_h1=0.0094, 128_l2=0.0049
Eval: 421_h1=0.0710, 421_l2=0.0117
[151] time=146.38, avg_loss=0.0064, train_err=0.1533
Eval: 128_h1=0.0096, 128_l2=0.0058
[184] time=117.19, avg_loss=0.0225, train_err=0.1801
Eval: 421_h1=0.0711, 421_l2=0.0118
[314] time=235.85, avg_loss=0.0037, train_err=0.0893
[152] time=146.46, avg_loss=0.0065, train_err=0.1563
Eval: 128_h1=0.0060, 128_l2=0.0033
Eval: 128_h1=0.0096, 128_l2=0.0055
[185] time=117.18, avg_loss=0.0225, train_err=0.1800
Eval: 421_h1=0.0713, 421_l2=0.0117
[153] time=146.44, avg_loss=0.0071, train_err=0.1708
Eval: 128_h1=0.0112, 128_l2=0.0065
[186] time=117.20, avg_loss=0.0224, train_err=0.1794
Eval: 421_h1=0.0713, 421_l2=0.0117
[315] time=244.44, avg_loss=0.0037, train_err=0.0889
[169] time=440.71, avg_loss=0.0071, train_err=0.1702
Eval: 128_h1=0.0060, 128_l2=0.0033
Eval: 128_h1=0.0103, 128_l2=0.0064
[154] time=146.46, avg_loss=0.0070, train_err=0.1675
Eval: 128_h1=0.0104, 128_l2=0.0055
[187] time=117.19, avg_loss=0.0224, train_err=0.1790
Eval: 421_h1=0.0714, 421_l2=0.0117
[155] time=146.43, avg_loss=0.0073, train_err=0.1753
[188] time=117.18, avg_loss=0.0224, train_err=0.1788
Eval: 128_h1=0.0101, 128_l2=0.0050
Eval: 421_h1=0.0715, 421_l2=0.0118
[316] time=251.50, avg_loss=0.0037, train_err=0.0885
Eval: 128_h1=0.0059, 128_l2=0.0033
[189] time=117.20, avg_loss=0.0224, train_err=0.1789
[156] time=146.47, avg_loss=0.0070, train_err=0.1689
Eval: 421_h1=0.0716, 421_l2=0.0118
Eval: 128_h1=0.0101, 128_l2=0.0051
[170] time=445.16, avg_loss=0.0075, train_err=0.1801
[190] time=117.19, avg_loss=0.0223, train_err=0.1787
Eval: 421_h1=0.0716, 421_l2=0.0117
Eval: 128_h1=0.0099, 128_l2=0.0066
[317] time=233.65, avg_loss=0.0037, train_err=0.0882
[157] time=146.44, avg_loss=0.0072, train_err=0.1726
Eval: 128_h1=0.0059, 128_l2=0.0033
Eval: 128_h1=0.0103, 128_l2=0.0055
[191] time=117.17, avg_loss=0.0224, train_err=0.1790
Eval: 421_h1=0.0717, 421_l2=0.0118
[158] time=146.47, avg_loss=0.0072, train_err=0.1730
Eval: 128_h1=0.0104, 128_l2=0.0058
[192] time=117.18, avg_loss=0.0224, train_err=0.1796
[318] time=238.46, avg_loss=0.0037, train_err=0.0878
Eval: 421_h1=0.0719, 421_l2=0.0117
Eval: 128_h1=0.0059, 128_l2=0.0033
[159] time=146.46, avg_loss=0.0071, train_err=0.1695
Eval: 128_h1=0.0105, 128_l2=0.0059
[193] time=117.19, avg_loss=0.0226, train_err=0.1804
Eval: 421_h1=0.0717, 421_l2=0.0117
[171] time=438.65, avg_loss=0.0071, train_err=0.1699
Eval: 128_h1=0.0098, 128_l2=0.0067
[160] time=146.43, avg_loss=0.0070, train_err=0.1669
Eval: 128_h1=0.0105, 128_l2=0.0059
[194] time=117.19, avg_loss=0.0227, train_err=0.1813
[319] time=243.92, avg_loss=0.0036, train_err=0.0875
Eval: 421_h1=0.0719, 421_l2=0.0116
Eval: 128_h1=0.0059, 128_l2=0.0033
[195] time=117.18, avg_loss=0.0229, train_err=0.1831
[161] time=146.43, avg_loss=0.0068, train_err=0.1641
Eval: 128_h1=0.0104, 128_l2=0.0058
Eval: 421_h1=0.0719, 421_l2=0.0119
[196] time=117.19, avg_loss=0.0228, train_err=0.1828
[320] time=248.02, avg_loss=0.0036, train_err=0.0872
Eval: 421_h1=0.0717, 421_l2=0.0117
Eval: 128_h1=0.0059, 128_l2=0.0033
[162] time=146.41, avg_loss=0.0066, train_err=0.1591
Eval: 128_h1=0.0102, 128_l2=0.0055
[197] time=117.19, avg_loss=0.0227, train_err=0.1816
[172] time=449.52, avg_loss=0.0067, train_err=0.1615
Eval: 421_h1=0.0717, 421_l2=0.0118
Eval: 128_h1=0.0097, 128_l2=0.0066
[163] time=146.44, avg_loss=0.0064, train_err=0.1524
Eval: 128_h1=0.0099, 128_l2=0.0053
[321] time=232.67, avg_loss=0.0036, train_err=0.0869
[198] time=117.20, avg_loss=0.0226, train_err=0.1809
Eval: 128_h1=0.0059, 128_l2=0.0033
Eval: 421_h1=0.0719, 421_l2=0.0118
[164] time=146.46, avg_loss=0.0061, train_err=0.1461
Eval: 128_h1=0.0096, 128_l2=0.0050
[199] time=117.18, avg_loss=0.0228, train_err=0.1823
Eval: 421_h1=0.0720, 421_l2=0.0119
[165] time=146.41, avg_loss=0.0060, train_err=0.1433
[322] time=237.05, avg_loss=0.0036, train_err=0.0866
Eval: 128_h1=0.0095, 128_l2=0.0048
Eval: 128_h1=0.0059, 128_l2=0.0033
[200] time=117.19, avg_loss=0.0227, train_err=0.1813
Eval: 421_h1=0.0722, 421_l2=0.0118
[173] time=433.16, avg_loss=0.0063, train_err=0.1510
Eval: 128_h1=0.0092, 128_l2=0.0057
[166] time=146.47, avg_loss=0.0060, train_err=0.1438
[201] time=117.18, avg_loss=0.0229, train_err=0.1834
Eval: 128_h1=0.0098, 128_l2=0.0054
Eval: 421_h1=0.0720, 421_l2=0.0119
[323] time=247.65, avg_loss=0.0036, train_err=0.0863
Eval: 128_h1=0.0059, 128_l2=0.0033
[202] time=117.19, avg_loss=0.0225, train_err=0.1801
Eval: 421_h1=0.0721, 421_l2=0.0118
[167] time=146.43, avg_loss=0.0062, train_err=0.1484
Eval: 128_h1=0.0096, 128_l2=0.0049
[203] time=117.18, avg_loss=0.0224, train_err=0.1792
Eval: 421_h1=0.0721, 421_l2=0.0118
[168] time=146.41, avg_loss=0.0065, train_err=0.1552
Eval: 128_h1=0.0095, 128_l2=0.0047
[324] time=253.94, avg_loss=0.0036, train_err=0.0860
Eval: 128_h1=0.0059, 128_l2=0.0033
[204] time=117.19, avg_loss=0.0223, train_err=0.1788
Eval: 421_h1=0.0723, 421_l2=0.0119
[174] time=469.33, avg_loss=0.0059, train_err=0.1419
Eval: 128_h1=0.0088, 128_l2=0.0054
[169] time=146.43, avg_loss=0.0062, train_err=0.1480
Eval: 128_h1=0.0092, 128_l2=0.0045
[205] time=117.19, avg_loss=0.0224, train_err=0.1791
Eval: 421_h1=0.0721, 421_l2=0.0117
[170] time=146.42, avg_loss=0.0060, train_err=0.1429
Eval: 128_h1=0.0091, 128_l2=0.0044
[325] time=244.04, avg_loss=0.0036, train_err=0.0858
Eval: 128_h1=0.0059, 128_l2=0.0033
[206] time=117.20, avg_loss=0.0224, train_err=0.1791
Eval: 421_h1=0.0723, 421_l2=0.0119
[171] time=146.44, avg_loss=0.0061, train_err=0.1460
Eval: 128_h1=0.0092, 128_l2=0.0045
[207] time=117.21, avg_loss=0.0224, train_err=0.1789
Eval: 421_h1=0.0722, 421_l2=0.0120
[326] time=237.40, avg_loss=0.0036, train_err=0.0855
[175] time=440.10, avg_loss=0.0058, train_err=0.1391
Eval: 128_h1=0.0059, 128_l2=0.0033
Eval: 128_h1=0.0088, 128_l2=0.0053
[208] time=117.19, avg_loss=0.0223, train_err=0.1780
[172] time=146.38, avg_loss=0.0064, train_err=0.1535
Eval: 128_h1=0.0119, 128_l2=0.0079
Eval: 421_h1=0.0721, 421_l2=0.0117
[209] time=117.18, avg_loss=0.0223, train_err=0.1785
Eval: 421_h1=0.0723, 421_l2=0.0118
[173] time=146.40, avg_loss=0.0067, train_err=0.1612
Eval: 128_h1=0.0108, 128_l2=0.0066
[327] time=248.75, avg_loss=0.0036, train_err=0.0852
Eval: 128_h1=0.0059, 128_l2=0.0033
[210] time=117.19, avg_loss=0.0224, train_err=0.1788
Eval: 421_h1=0.0723, 421_l2=0.0120
[174] time=146.39, avg_loss=0.0068, train_err=0.1636
Eval: 128_h1=0.0107, 128_l2=0.0070
[211] time=117.19, avg_loss=0.0223, train_err=0.1782
Eval: 421_h1=0.0723, 421_l2=0.0117
[176] time=462.90, avg_loss=0.0060, train_err=0.1434
[175] time=146.50, avg_loss=0.0069, train_err=0.1666
Eval: 128_h1=0.0099, 128_l2=0.0063
Eval: 128_h1=0.0100, 128_l2=0.0062
[328] time=246.92, avg_loss=0.0035, train_err=0.0850
Eval: 128_h1=0.0059, 128_l2=0.0033
[212] time=117.18, avg_loss=0.0223, train_err=0.1787
Eval: 421_h1=0.0728, 421_l2=0.0120
[176] time=146.42, avg_loss=0.0071, train_err=0.1708
Eval: 128_h1=0.0097, 128_l2=0.0060
[213] time=117.19, avg_loss=0.0222, train_err=0.1777
Eval: 421_h1=0.0723, 421_l2=0.0117
[329] time=241.81, avg_loss=0.0035, train_err=0.0848
Eval: 128_h1=0.0059, 128_l2=0.0033
[177] time=146.46, avg_loss=0.0073, train_err=0.1754
[214] time=117.18, avg_loss=0.0221, train_err=0.1769
Eval: 128_h1=0.0098, 128_l2=0.0057
Eval: 421_h1=0.0725, 421_l2=0.0118
[215] time=117.18, avg_loss=0.0220, train_err=0.1764
[177] time=446.88, avg_loss=0.0056, train_err=0.1346
Eval: 421_h1=0.0724, 421_l2=0.0117
[178] time=146.44, avg_loss=0.0070, train_err=0.1691
Eval: 128_h1=0.0099, 128_l2=0.0056
Eval: 128_h1=0.0089, 128_l2=0.0051
[330] time=244.08, avg_loss=0.0035, train_err=0.0845
Eval: 128_h1=0.0059, 128_l2=0.0033
[216] time=117.20, avg_loss=0.0221, train_err=0.1767
Eval: 421_h1=0.0725, 421_l2=0.0118
[179] time=146.46, avg_loss=0.0068, train_err=0.1634
Eval: 128_h1=0.0100, 128_l2=0.0058
[217] time=117.19, avg_loss=0.0222, train_err=0.1774
Eval: 421_h1=0.0727, 421_l2=0.0118
[180] time=146.50, avg_loss=0.0065, train_err=0.1560
Eval: 128_h1=0.0098, 128_l2=0.0055
[331] time=251.78, avg_loss=0.0035, train_err=0.0843
Eval: 128_h1=0.0058, 128_l2=0.0033
[218] time=117.19, avg_loss=0.0222, train_err=0.1772
Eval: 421_h1=0.0727, 421_l2=0.0118
[181] time=146.50, avg_loss=0.0061, train_err=0.1469
[178] time=466.01, avg_loss=0.0055, train_err=0.1309
Eval: 128_h1=0.0095, 128_l2=0.0052
Eval: 128_h1=0.0087, 128_l2=0.0048
[219] time=117.19, avg_loss=0.0222, train_err=0.1774
Eval: 421_h1=0.0726, 421_l2=0.0121
[332] time=248.12, avg_loss=0.0035, train_err=0.0841
Eval: 128_h1=0.0058, 128_l2=0.0033
[182] time=146.52, avg_loss=0.0058, train_err=0.1401
Eval: 128_h1=0.0093, 128_l2=0.0050
[220] time=117.22, avg_loss=0.0222, train_err=0.1778
Eval: 421_h1=0.0729, 421_l2=0.0120
[221] time=117.19, avg_loss=0.0223, train_err=0.1785
[183] time=146.43, avg_loss=0.0057, train_err=0.1360
Eval: 421_h1=0.0727, 421_l2=0.0119
Eval: 128_h1=0.0091, 128_l2=0.0048
[333] time=240.15, avg_loss=0.0035, train_err=0.0838
Eval: 128_h1=0.0058, 128_l2=0.0033
[222] time=117.20, avg_loss=0.0220, train_err=0.1757
Eval: 421_h1=0.0730, 421_l2=0.0117
[184] time=146.46, avg_loss=0.0057, train_err=0.1359
[179] time=441.48, avg_loss=0.0053, train_err=0.1280
Eval: 128_h1=0.0089, 128_l2=0.0046
Eval: 128_h1=0.0084, 128_l2=0.0046
[223] time=117.19, avg_loss=0.0219, train_err=0.1752
Eval: 421_h1=0.0728, 421_l2=0.0119
[185] time=146.50, avg_loss=0.0056, train_err=0.1345
[334] time=239.55, avg_loss=0.0035, train_err=0.0836
Eval: 128_h1=0.0090, 128_l2=0.0047
Eval: 128_h1=0.0058, 128_l2=0.0033
[224] time=117.21, avg_loss=0.0219, train_err=0.1751
Eval: 421_h1=0.0726, 421_l2=0.0118
[186] time=146.44, avg_loss=0.0056, train_err=0.1350
Eval: 128_h1=0.0090, 128_l2=0.0046
[225] time=117.20, avg_loss=0.0219, train_err=0.1749
Eval: 421_h1=0.0729, 421_l2=0.0118
[335] time=244.32, avg_loss=0.0035, train_err=0.0834
Eval: 128_h1=0.0058, 128_l2=0.0033
[187] time=146.43, avg_loss=0.0059, train_err=0.1403
Eval: 128_h1=0.0090, 128_l2=0.0048
[180] time=448.07, avg_loss=0.0053, train_err=0.1282
[226] time=117.18, avg_loss=0.0219, train_err=0.1748
Eval: 128_h1=0.0082, 128_l2=0.0043
Eval: 421_h1=0.0728, 421_l2=0.0119
[188] time=146.43, avg_loss=0.0062, train_err=0.1487
[227] time=117.19, avg_loss=0.0218, train_err=0.1746
Eval: 128_h1=0.0104, 128_l2=0.0063
Eval: 421_h1=0.0729, 421_l2=0.0117
[336] time=247.36, avg_loss=0.0035, train_err=0.0832
Eval: 128_h1=0.0058, 128_l2=0.0033
[228] time=117.23, avg_loss=0.0220, train_err=0.1763
Eval: 421_h1=0.0731, 421_l2=0.0117
[189] time=146.51, avg_loss=0.0061, train_err=0.1473
Eval: 128_h1=0.0094, 128_l2=0.0050
[229] time=117.20, avg_loss=0.0218, train_err=0.1745
Eval: 421_h1=0.0733, 421_l2=0.0120
[190] time=146.39, avg_loss=0.0060, train_err=0.1434
[337] time=249.94, avg_loss=0.0035, train_err=0.0830
Eval: 128_h1=0.0092, 128_l2=0.0049
Eval: 128_h1=0.0058, 128_l2=0.0033
[181] time=461.32, avg_loss=0.0053, train_err=0.1271
Eval: 128_h1=0.0083, 128_l2=0.0043
[230] time=117.22, avg_loss=0.0226, train_err=0.1807
Eval: 421_h1=0.0728, 421_l2=0.0117
[191] time=146.42, avg_loss=0.0061, train_err=0.1458
Eval: 128_h1=0.0102, 128_l2=0.0056
[231] time=117.20, avg_loss=0.0220, train_err=0.1763
Eval: 421_h1=0.0734, 421_l2=0.0121
[338] time=248.13, avg_loss=0.0035, train_err=0.0828
Eval: 128_h1=0.0058, 128_l2=0.0033
[192] time=146.47, avg_loss=0.0064, train_err=0.1539
Eval: 128_h1=0.0103, 128_l2=0.0059
[232] time=117.19, avg_loss=0.0218, train_err=0.1742
Eval: 421_h1=0.0730, 421_l2=0.0121
[193] time=146.44, avg_loss=0.0065, train_err=0.1549
Eval: 128_h1=0.0098, 128_l2=0.0053
[233] time=117.18, avg_loss=0.0216, train_err=0.1729
Eval: 421_h1=0.0729, 421_l2=0.0120
[182] time=467.40, avg_loss=0.0054, train_err=0.1299
[339] time=254.09, avg_loss=0.0034, train_err=0.0826
Eval: 128_h1=0.0084, 128_l2=0.0043
Eval: 128_h1=0.0058, 128_l2=0.0033
[234] time=117.19, avg_loss=0.0215, train_err=0.1722
[194] time=146.51, avg_loss=0.0064, train_err=0.1537
Eval: 421_h1=0.0732, 421_l2=0.0118
Eval: 128_h1=0.0097, 128_l2=0.0052
[235] time=117.18, avg_loss=0.0216, train_err=0.1728
Eval: 421_h1=0.0732, 421_l2=0.0119
[195] time=146.44, avg_loss=0.0063, train_err=0.1507
Eval: 128_h1=0.0098, 128_l2=0.0055
[340] time=249.66, avg_loss=0.0034, train_err=0.0823
Eval: 128_h1=0.0058, 128_l2=0.0033
[236] time=117.21, avg_loss=0.0215, train_err=0.1724
Eval: 421_h1=0.0734, 421_l2=0.0120
[196] time=146.43, avg_loss=0.0061, train_err=0.1458
Eval: 128_h1=0.0096, 128_l2=0.0054
[183] time=460.75, avg_loss=0.0061, train_err=0.1459
[237] time=117.19, avg_loss=0.0215, train_err=0.1724
Eval: 421_h1=0.0732, 421_l2=0.0118
Eval: 128_h1=0.0091, 128_l2=0.0053
[341] time=247.36, avg_loss=0.0034, train_err=0.0821
Eval: 128_h1=0.0058, 128_l2=0.0033
[197] time=146.47, avg_loss=0.0059, train_err=0.1412
Eval: 128_h1=0.0095, 128_l2=0.0051
[238] time=117.20, avg_loss=0.0215, train_err=0.1723
Eval: 421_h1=0.0733, 421_l2=0.0118
[198] time=146.43, avg_loss=0.0057, train_err=0.1372
Eval: 128_h1=0.0092, 128_l2=0.0048
[239] time=117.20, avg_loss=0.0216, train_err=0.1730
Eval: 421_h1=0.0733, 421_l2=0.0119
[342] time=243.19, avg_loss=0.0034, train_err=0.0819
Eval: 128_h1=0.0058, 128_l2=0.0033
[199] time=146.44, avg_loss=0.0056, train_err=0.1341
[240] time=117.20, avg_loss=0.0213, train_err=0.1701
Eval: 128_h1=0.0089, 128_l2=0.0043
Eval: 421_h1=0.0733, 421_l2=0.0118
[184] time=448.60, avg_loss=0.0059, train_err=0.1410
Eval: 128_h1=0.0089, 128_l2=0.0047
[241] time=117.19, avg_loss=0.0208, train_err=0.1661
Eval: 421_h1=0.0735, 421_l2=0.0117
[200] time=146.46, avg_loss=0.0068, train_err=0.1630
Eval: 128_h1=0.0090, 128_l2=0.0051
[343] time=245.68, avg_loss=0.0034, train_err=0.0816
Eval: 128_h1=0.0057, 128_l2=0.0033
[242] time=117.19, avg_loss=0.0207, train_err=0.1653
Eval: 421_h1=0.0736, 421_l2=0.0117
[201] time=146.46, avg_loss=0.0064, train_err=0.1537
Eval: 128_h1=0.0088, 128_l2=0.0049
[243] time=117.19, avg_loss=0.0206, train_err=0.1650
Eval: 421_h1=0.0737, 421_l2=0.0117
[344] time=246.77, avg_loss=0.0034, train_err=0.0814
Eval: 128_h1=0.0057, 128_l2=0.0033
[202] time=146.41, avg_loss=0.0062, train_err=0.1478
Eval: 128_h1=0.0087, 128_l2=0.0048
[244] time=117.19, avg_loss=0.0206, train_err=0.1648
Eval: 421_h1=0.0737, 421_l2=0.0118
[185] time=455.85, avg_loss=0.0058, train_err=0.1387
Eval: 128_h1=0.0090, 128_l2=0.0053
[203] time=146.41, avg_loss=0.0060, train_err=0.1439
Eval: 128_h1=0.0087, 128_l2=0.0047
[245] time=117.18, avg_loss=0.0206, train_err=0.1646
Eval: 421_h1=0.0738, 421_l2=0.0117
[345] time=244.49, avg_loss=0.0034, train_err=0.0812
Eval: 128_h1=0.0057, 128_l2=0.0033
[204] time=146.38, avg_loss=0.0059, train_err=0.1411
Eval: 128_h1=0.0087, 128_l2=0.0047
[246] time=117.22, avg_loss=0.0206, train_err=0.1644
Eval: 421_h1=0.0738, 421_l2=0.0117
[247] time=117.20, avg_loss=0.0205, train_err=0.1643
[205] time=146.46, avg_loss=0.0058, train_err=0.1387
Eval: 421_h1=0.0739, 421_l2=0.0118
Eval: 128_h1=0.0086, 128_l2=0.0047
[346] time=244.25, avg_loss=0.0034, train_err=0.0809
Eval: 128_h1=0.0057, 128_l2=0.0033
[186] time=451.24, avg_loss=0.0063, train_err=0.1522
[248] time=117.20, avg_loss=0.0205, train_err=0.1641
Eval: 128_h1=0.0093, 128_l2=0.0059
Eval: 421_h1=0.0739, 421_l2=0.0117
[206] time=146.39, avg_loss=0.0057, train_err=0.1367
Eval: 128_h1=0.0086, 128_l2=0.0047
[249] time=117.18, avg_loss=0.0205, train_err=0.1640
Eval: 421_h1=0.0741, 421_l2=0.0117
[347] time=246.19, avg_loss=0.0034, train_err=0.0807
Eval: 128_h1=0.0057, 128_l2=0.0033
[207] time=146.40, avg_loss=0.0056, train_err=0.1350
Eval: 128_h1=0.0086, 128_l2=0.0047
[250] time=117.22, avg_loss=0.0205, train_err=0.1639
Eval: 421_h1=0.0741, 421_l2=0.0117
[208] time=146.40, avg_loss=0.0056, train_err=0.1334
Eval: 128_h1=0.0086, 128_l2=0.0046
[251] time=117.22, avg_loss=0.0205, train_err=0.1637
Eval: 421_h1=0.0741, 421_l2=0.0118
[348] time=250.50, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0057, 128_l2=0.0033
[187] time=461.76, avg_loss=0.0061, train_err=0.1456
Eval: 128_h1=0.0097, 128_l2=0.0065
[209] time=146.42, avg_loss=0.0055, train_err=0.1319
Eval: 128_h1=0.0086, 128_l2=0.0046
[252] time=117.19, avg_loss=0.0205, train_err=0.1636
Eval: 421_h1=0.0741, 421_l2=0.0117
[210] time=146.45, avg_loss=0.0054, train_err=0.1306
[253] time=117.21, avg_loss=0.0204, train_err=0.1635
Eval: 128_h1=0.0085, 128_l2=0.0046
Eval: 421_h1=0.0742, 421_l2=0.0117
[349] time=246.69, avg_loss=0.0033, train_err=0.0803
Eval: 128_h1=0.0057, 128_l2=0.0033
[254] time=117.20, avg_loss=0.0204, train_err=0.1635
Eval: 421_h1=0.0742, 421_l2=0.0117
[211] time=146.45, avg_loss=0.0054, train_err=0.1294
Eval: 128_h1=0.0085, 128_l2=0.0046
[255] time=117.19, avg_loss=0.0205, train_err=0.1636
Eval: 421_h1=0.0744, 421_l2=0.0118
[188] time=455.94, avg_loss=0.0062, train_err=0.1496
[350] time=246.26, avg_loss=0.0033, train_err=0.0801
Eval: 128_h1=0.0057, 128_l2=0.0033
[212] time=146.51, avg_loss=0.0053, train_err=0.1283
Eval: 128_h1=0.0098, 128_l2=0.0069
Eval: 128_h1=0.0085, 128_l2=0.0046
[256] time=117.22, avg_loss=0.0205, train_err=0.1638
Eval: 421_h1=0.0744, 421_l2=0.0118
[213] time=146.47, avg_loss=0.0053, train_err=0.1272
Eval: 128_h1=0.0085, 128_l2=0.0045
[257] time=117.20, avg_loss=0.0206, train_err=0.1645
[351] time=245.51, avg_loss=0.0033, train_err=0.0800
Eval: 421_h1=0.0744, 421_l2=0.0118
Eval: 128_h1=0.0057, 128_l2=0.0033
[214] time=146.43, avg_loss=0.0053, train_err=0.1262
Eval: 128_h1=0.0085, 128_l2=0.0045
[258] time=117.18, avg_loss=0.0206, train_err=0.1649
Eval: 421_h1=0.0743, 421_l2=0.0117
[189] time=455.54, avg_loss=0.0063, train_err=0.1510
[215] time=146.45, avg_loss=0.0052, train_err=0.1252
Eval: 128_h1=0.0085, 128_l2=0.0045
Eval: 128_h1=0.0097, 128_l2=0.0071
[259] time=117.20, avg_loss=0.0206, train_err=0.1649
[352] time=247.53, avg_loss=0.0033, train_err=0.0799
Eval: 421_h1=0.0743, 421_l2=0.0118
Eval: 128_h1=0.0057, 128_l2=0.0033
[260] time=117.19, avg_loss=0.0206, train_err=0.1650
[216] time=146.42, avg_loss=0.0052, train_err=0.1243
Eval: 421_h1=0.0746, 421_l2=0.0118
Eval: 128_h1=0.0084, 128_l2=0.0045
[261] time=117.19, avg_loss=0.0206, train_err=0.1648
[353] time=249.89, avg_loss=0.0033, train_err=0.0798
Eval: 421_h1=0.0745, 421_l2=0.0118
Eval: 128_h1=0.0057, 128_l2=0.0033
[217] time=146.40, avg_loss=0.0051, train_err=0.1234
Eval: 128_h1=0.0084, 128_l2=0.0045
[262] time=117.20, avg_loss=0.0206, train_err=0.1647
Eval: 421_h1=0.0745, 421_l2=0.0118
[218] time=146.45, avg_loss=0.0051, train_err=0.1226
[190] time=459.72, avg_loss=0.0066, train_err=0.1591
Eval: 128_h1=0.0084, 128_l2=0.0045
Eval: 128_h1=0.0103, 128_l2=0.0074
[263] time=117.21, avg_loss=0.0206, train_err=0.1646
[354] time=245.06, avg_loss=0.0033, train_err=0.0797
Eval: 421_h1=0.0745, 421_l2=0.0118
Eval: 128_h1=0.0057, 128_l2=0.0033
[219] time=146.43, avg_loss=0.0051, train_err=0.1218
Eval: 128_h1=0.0084, 128_l2=0.0045
[264] time=117.21, avg_loss=0.0205, train_err=0.1641
Eval: 421_h1=0.0746, 421_l2=0.0118
[220] time=146.44, avg_loss=0.0050, train_err=0.1210
Eval: 128_h1=0.0084, 128_l2=0.0045
[265] time=117.20, avg_loss=0.0204, train_err=0.1632
[355] time=245.05, avg_loss=0.0033, train_err=0.0797
Eval: 421_h1=0.0747, 421_l2=0.0117
Eval: 128_h1=0.0057, 128_l2=0.0032
[221] time=146.45, avg_loss=0.0050, train_err=0.1203
[266] time=117.20, avg_loss=0.0204, train_err=0.1629
Eval: 128_h1=0.0084, 128_l2=0.0045
[191] time=452.90, avg_loss=0.0066, train_err=0.1589
Eval: 421_h1=0.0746, 421_l2=0.0118
Eval: 128_h1=0.0099, 128_l2=0.0068
[267] time=117.19, avg_loss=0.0203, train_err=0.1627
[356] time=247.33, avg_loss=0.0033, train_err=0.0797
Eval: 421_h1=0.0748, 421_l2=0.0117
Eval: 128_h1=0.0057, 128_l2=0.0032
[222] time=146.47, avg_loss=0.0050, train_err=0.1196
Eval: 128_h1=0.0084, 128_l2=0.0045
[268] time=117.19, avg_loss=0.0203, train_err=0.1625
Eval: 421_h1=0.0747, 421_l2=0.0117
[223] time=146.51, avg_loss=0.0050, train_err=0.1189
Eval: 128_h1=0.0084, 128_l2=0.0045
[269] time=117.19, avg_loss=0.0203, train_err=0.1625
[357] time=248.92, avg_loss=0.0033, train_err=0.0798
Eval: 421_h1=0.0747, 421_l2=0.0117
Eval: 128_h1=0.0057, 128_l2=0.0032
[224] time=146.45, avg_loss=0.0049, train_err=0.1182
Eval: 128_h1=0.0084, 128_l2=0.0045
[192] time=460.08, avg_loss=0.0063, train_err=0.1508
Eval: 128_h1=0.0094, 128_l2=0.0062
[270] time=117.20, avg_loss=0.0203, train_err=0.1622
Eval: 421_h1=0.0749, 421_l2=0.0118
[225] time=146.45, avg_loss=0.0049, train_err=0.1177
Eval: 128_h1=0.0084, 128_l2=0.0045
[358] time=243.89, avg_loss=0.0034, train_err=0.0805
[271] time=117.20, avg_loss=0.0203, train_err=0.1622
Eval: 128_h1=0.0059, 128_l2=0.0034
Eval: 421_h1=0.0750, 421_l2=0.0117
[226] time=146.39, avg_loss=0.0049, train_err=0.1171
Eval: 128_h1=0.0084, 128_l2=0.0045
[272] time=117.21, avg_loss=0.0203, train_err=0.1626
Eval: 421_h1=0.0749, 421_l2=0.0118
[359] time=236.81, avg_loss=0.0034, train_err=0.0818
Eval: 128_h1=0.0058, 128_l2=0.0033
[273] time=117.21, avg_loss=0.0203, train_err=0.1622
[227] time=146.44, avg_loss=0.0049, train_err=0.1166
Eval: 421_h1=0.0749, 421_l2=0.0118
Eval: 128_h1=0.0084, 128_l2=0.0046
[193] time=438.67, avg_loss=0.0060, train_err=0.1427
Eval: 128_h1=0.0095, 128_l2=0.0064
[274] time=117.20, avg_loss=0.0203, train_err=0.1620
Eval: 421_h1=0.0750, 421_l2=0.0118
[228] time=146.45, avg_loss=0.0048, train_err=0.1161
Eval: 128_h1=0.0084, 128_l2=0.0046
[360] time=253.57, avg_loss=0.0034, train_err=0.0814
[275] time=117.19, avg_loss=0.0202, train_err=0.1618
Eval: 128_h1=0.0058, 128_l2=0.0032
Eval: 421_h1=0.0748, 421_l2=0.0118
[229] time=146.41, avg_loss=0.0048, train_err=0.1156
Eval: 128_h1=0.0084, 128_l2=0.0046
[276] time=117.20, avg_loss=0.0202, train_err=0.1616
Eval: 421_h1=0.0750, 421_l2=0.0118
[230] time=146.49, avg_loss=0.0048, train_err=0.1151
Eval: 128_h1=0.0084, 128_l2=0.0045
[361] time=243.53, avg_loss=0.0034, train_err=0.0813
[194] time=461.08, avg_loss=0.0057, train_err=0.1358
Eval: 128_h1=0.0058, 128_l2=0.0032
[277] time=117.21, avg_loss=0.0202, train_err=0.1617
Eval: 421_h1=0.0750, 421_l2=0.0118
Eval: 128_h1=0.0089, 128_l2=0.0057
[231] time=146.49, avg_loss=0.0048, train_err=0.1144
Eval: 128_h1=0.0083, 128_l2=0.0045
[278] time=117.19, avg_loss=0.0202, train_err=0.1615
Eval: 421_h1=0.0750, 421_l2=0.0118
[362] time=233.24, avg_loss=0.0034, train_err=0.0812
Eval: 128_h1=0.0058, 128_l2=0.0032
[232] time=146.47, avg_loss=0.0047, train_err=0.1136
[279] time=117.20, avg_loss=0.0202, train_err=0.1616
Eval: 128_h1=0.0082, 128_l2=0.0044
Eval: 421_h1=0.0749, 421_l2=0.0118
[280] time=117.20, avg_loss=0.0202, train_err=0.1616
Eval: 421_h1=0.0752, 421_l2=0.0118
[233] time=146.46, avg_loss=0.0047, train_err=0.1126
Eval: 128_h1=0.0080, 128_l2=0.0042
[195] time=427.58, avg_loss=0.0054, train_err=0.1301
Eval: 128_h1=0.0088, 128_l2=0.0053
[363] time=236.35, avg_loss=0.0034, train_err=0.0812
Eval: 128_h1=0.0058, 128_l2=0.0032
[281] time=117.20, avg_loss=0.0201, train_err=0.1611
Eval: 421_h1=0.0751, 421_l2=0.0118
[234] time=146.43, avg_loss=0.0047, train_err=0.1119
Eval: 128_h1=0.0079, 128_l2=0.0041
[282] time=117.20, avg_loss=0.0201, train_err=0.1609
Eval: 421_h1=0.0753, 421_l2=0.0117
[235] time=146.45, avg_loss=0.0046, train_err=0.1115
Eval: 128_h1=0.0079, 128_l2=0.0041
[364] time=252.56, avg_loss=0.0034, train_err=0.0811
Eval: 128_h1=0.0058, 128_l2=0.0032
[283] time=117.19, avg_loss=0.0201, train_err=0.1607
Eval: 421_h1=0.0751, 421_l2=0.0118
[236] time=146.45, avg_loss=0.0046, train_err=0.1113
Eval: 128_h1=0.0079, 128_l2=0.0041
[284] time=117.20, avg_loss=0.0201, train_err=0.1612
[196] time=463.09, avg_loss=0.0053, train_err=0.1268
Eval: 421_h1=0.0752, 421_l2=0.0117
Eval: 128_h1=0.0085, 128_l2=0.0048
[365] time=241.06, avg_loss=0.0034, train_err=0.0808
Eval: 128_h1=0.0058, 128_l2=0.0032
[237] time=146.45, avg_loss=0.0047, train_err=0.1117
Eval: 128_h1=0.0080, 128_l2=0.0043
[285] time=117.20, avg_loss=0.0201, train_err=0.1610
Eval: 421_h1=0.0753, 421_l2=0.0120
[286] time=117.21, avg_loss=0.0201, train_err=0.1608
[238] time=146.47, avg_loss=0.0049, train_err=0.1176
Eval: 421_h1=0.0754, 421_l2=0.0118
Eval: 128_h1=0.0084, 128_l2=0.0047
[366] time=232.42, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0058, 128_l2=0.0032
[287] time=117.20, avg_loss=0.0200, train_err=0.1601
Eval: 421_h1=0.0753, 421_l2=0.0118
[239] time=146.42, avg_loss=0.0049, train_err=0.1164
Eval: 128_h1=0.0082, 128_l2=0.0043
[197] time=423.21, avg_loss=0.0054, train_err=0.1290
Eval: 128_h1=0.0085, 128_l2=0.0049
[288] time=117.19, avg_loss=0.0200, train_err=0.1600
Eval: 421_h1=0.0756, 421_l2=0.0118
[367] time=235.40, avg_loss=0.0033, train_err=0.0800
Eval: 128_h1=0.0057, 128_l2=0.0032
[240] time=146.53, avg_loss=0.0048, train_err=0.1151
Eval: 128_h1=0.0081, 128_l2=0.0043
[289] time=117.19, avg_loss=0.0200, train_err=0.1600
Eval: 421_h1=0.0754, 421_l2=0.0119
[241] time=146.47, avg_loss=0.0048, train_err=0.1143
Eval: 128_h1=0.0081, 128_l2=0.0042
[290] time=117.19, avg_loss=0.0200, train_err=0.1599
Eval: 421_h1=0.0755, 421_l2=0.0118
[368] time=252.22, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0057, 128_l2=0.0032
[242] time=146.44, avg_loss=0.0047, train_err=0.1138
Eval: 128_h1=0.0081, 128_l2=0.0042
[291] time=117.20, avg_loss=0.0200, train_err=0.1598
[198] time=461.66, avg_loss=0.0052, train_err=0.1258
Eval: 421_h1=0.0755, 421_l2=0.0120
Eval: 128_h1=0.0085, 128_l2=0.0050
[243] time=146.51, avg_loss=0.0047, train_err=0.1132
[292] time=117.21, avg_loss=0.0199, train_err=0.1595
Eval: 128_h1=0.0081, 128_l2=0.0042
Eval: 421_h1=0.0756, 421_l2=0.0118
[369] time=243.39, avg_loss=0.0033, train_err=0.0790
Eval: 128_h1=0.0057, 128_l2=0.0032
[293] time=117.20, avg_loss=0.0200, train_err=0.1597
Eval: 421_h1=0.0755, 421_l2=0.0118
[244] time=146.50, avg_loss=0.0047, train_err=0.1127
Eval: 128_h1=0.0080, 128_l2=0.0042
[294] time=117.21, avg_loss=0.0200, train_err=0.1596
Eval: 421_h1=0.0756, 421_l2=0.0118
[370] time=234.20, avg_loss=0.0033, train_err=0.0785
Eval: 128_h1=0.0057, 128_l2=0.0032
[245] time=146.50, avg_loss=0.0047, train_err=0.1118
Eval: 128_h1=0.0079, 128_l2=0.0041
[199] time=428.33, avg_loss=0.0052, train_err=0.1245
Eval: 128_h1=0.0085, 128_l2=0.0048
[295] time=117.20, avg_loss=0.0199, train_err=0.1592
Eval: 421_h1=0.0757, 421_l2=0.0118
[246] time=146.49, avg_loss=0.0046, train_err=0.1108
Eval: 128_h1=0.0079, 128_l2=0.0040
[296] time=117.19, avg_loss=0.0199, train_err=0.1592
[371] time=237.61, avg_loss=0.0033, train_err=0.0780
Eval: 421_h1=0.0758, 421_l2=0.0118
Eval: 128_h1=0.0056, 128_l2=0.0032
[247] time=146.41, avg_loss=0.0046, train_err=0.1105
Eval: 128_h1=0.0078, 128_l2=0.0040
[297] time=117.20, avg_loss=0.0199, train_err=0.1593
Eval: 421_h1=0.0757, 421_l2=0.0117
[248] time=146.51, avg_loss=0.0046, train_err=0.1107
Eval: 128_h1=0.0078, 128_l2=0.0039
[298] time=117.19, avg_loss=0.0199, train_err=0.1591
Eval: 421_h1=0.0758, 421_l2=0.0118
[372] time=254.42, avg_loss=0.0032, train_err=0.0775
[200] time=458.06, avg_loss=0.0064, train_err=0.1537
Eval: 128_h1=0.0056, 128_l2=0.0032
Eval: 128_h1=0.0083, 128_l2=0.0042
[299] time=117.21, avg_loss=0.0199, train_err=0.1590
[249] time=146.47, avg_loss=0.0046, train_err=0.1111
Eval: 421_h1=0.0756, 421_l2=0.0119
dracy.sh: 55: exit: Illegal number: 0CFILE 2>/dev/null || echo 1)
Eval: 128_h1=0.0078, 128_l2=0.0039
[373] time=239.42, avg_loss=0.0032, train_err=0.0771
Eval: 128_h1=0.0056, 128_l2=0.0033
[250] time=146.47, avg_loss=0.0047, train_err=0.1117
Eval: 128_h1=0.0078, 128_l2=0.0039
[251] time=146.44, avg_loss=0.0047, train_err=0.1130
Eval: 128_h1=0.0078, 128_l2=0.0038
[201] time=431.25, avg_loss=0.0062, train_err=0.1480
Eval: 128_h1=0.0081, 128_l2=0.0040
[374] time=235.76, avg_loss=0.0032, train_err=0.0768
Eval: 128_h1=0.0056, 128_l2=0.0032
[252] time=146.40, avg_loss=0.0049, train_err=0.1180
Eval: 128_h1=0.0085, 128_l2=0.0047
[253] time=146.43, avg_loss=0.0052, train_err=0.1243
[375] time=240.31, avg_loss=0.0032, train_err=0.0765
Eval: 128_h1=0.0082, 128_l2=0.0042
Eval: 128_h1=0.0056, 128_l2=0.0031
[254] time=146.45, avg_loss=0.0053, train_err=0.1272
Eval: 128_h1=0.0081, 128_l2=0.0041
[202] time=441.73, avg_loss=0.0059, train_err=0.1420
Eval: 128_h1=0.0080, 128_l2=0.0040
[376] time=240.96, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0056, 128_l2=0.0031
[255] time=146.48, avg_loss=0.0053, train_err=0.1272
Eval: 128_h1=0.0081, 128_l2=0.0041
[256] time=146.52, avg_loss=0.0052, train_err=0.1251
Eval: 128_h1=0.0081, 128_l2=0.0040
[377] time=241.72, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0056, 128_l2=0.0031
[257] time=146.48, avg_loss=0.0051, train_err=0.1229
Eval: 128_h1=0.0080, 128_l2=0.0040
[203] time=444.29, avg_loss=0.0058, train_err=0.1381
Eval: 128_h1=0.0080, 128_l2=0.0039
[378] time=240.85, avg_loss=0.0032, train_err=0.0759
[258] time=146.51, avg_loss=0.0050, train_err=0.1208
Eval: 128_h1=0.0056, 128_l2=0.0031
Eval: 128_h1=0.0079, 128_l2=0.0040
[259] time=146.47, avg_loss=0.0050, train_err=0.1188
Eval: 128_h1=0.0079, 128_l2=0.0039
[379] time=241.49, avg_loss=0.0032, train_err=0.0758
Eval: 128_h1=0.0056, 128_l2=0.0031
[260] time=146.41, avg_loss=0.0049, train_err=0.1164
Eval: 128_h1=0.0078, 128_l2=0.0038
[204] time=442.26, avg_loss=0.0056, train_err=0.1352
Eval: 128_h1=0.0079, 128_l2=0.0039
[261] time=146.43, avg_loss=0.0047, train_err=0.1137
Eval: 128_h1=0.0077, 128_l2=0.0038
[380] time=247.15, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0055, 128_l2=0.0031
[262] time=146.38, avg_loss=0.0046, train_err=0.1112
Eval: 128_h1=0.0076, 128_l2=0.0037
[381] time=252.28, avg_loss=0.0032, train_err=0.0756
[263] time=146.40, avg_loss=0.0046, train_err=0.1095
Eval: 128_h1=0.0055, 128_l2=0.0031
Eval: 128_h1=0.0076, 128_l2=0.0037
[205] time=465.22, avg_loss=0.0055, train_err=0.1329
Eval: 128_h1=0.0079, 128_l2=0.0039
[264] time=146.42, avg_loss=0.0045, train_err=0.1081
Eval: 128_h1=0.0076, 128_l2=0.0037
[382] time=233.50, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0055, 128_l2=0.0031
[265] time=146.42, avg_loss=0.0045, train_err=0.1070
Eval: 128_h1=0.0076, 128_l2=0.0037
[266] time=146.46, avg_loss=0.0044, train_err=0.1066
Eval: 128_h1=0.0076, 128_l2=0.0037
[383] time=237.29, avg_loss=0.0032, train_err=0.0757
[206] time=429.65, avg_loss=0.0055, train_err=0.1309
Eval: 128_h1=0.0055, 128_l2=0.0032
Eval: 128_h1=0.0079, 128_l2=0.0039
[267] time=146.41, avg_loss=0.0045, train_err=0.1072
Eval: 128_h1=0.0075, 128_l2=0.0037
[384] time=248.99, avg_loss=0.0032, train_err=0.0760
Eval: 128_h1=0.0057, 128_l2=0.0034
[268] time=146.39, avg_loss=0.0047, train_err=0.1134
Eval: 128_h1=0.0083, 128_l2=0.0045
[269] time=146.47, avg_loss=0.0047, train_err=0.1121
Eval: 128_h1=0.0080, 128_l2=0.0041
[207] time=463.71, avg_loss=0.0054, train_err=0.1292
Eval: 128_h1=0.0078, 128_l2=0.0039
[385] time=246.09, avg_loss=0.0032, train_err=0.0760
Eval: 128_h1=0.0057, 128_l2=0.0034
[270] time=146.49, avg_loss=0.0046, train_err=0.1092
Eval: 128_h1=0.0079, 128_l2=0.0040
[271] time=146.52, avg_loss=0.0045, train_err=0.1077
Eval: 128_h1=0.0078, 128_l2=0.0040
[386] time=234.07, avg_loss=0.0032, train_err=0.0759
Eval: 128_h1=0.0057, 128_l2=0.0034
[272] time=146.49, avg_loss=0.0044, train_err=0.1064
Eval: 128_h1=0.0077, 128_l2=0.0039
[208] time=427.16, avg_loss=0.0053, train_err=0.1277
Eval: 128_h1=0.0078, 128_l2=0.0039
[387] time=236.84, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0057, 128_l2=0.0034
[273] time=146.44, avg_loss=0.0044, train_err=0.1045
Eval: 128_h1=0.0075, 128_l2=0.0037
[274] time=146.47, avg_loss=0.0043, train_err=0.1027
Eval: 128_h1=0.0075, 128_l2=0.0036
[388] time=253.56, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0057, 128_l2=0.0033
[275] time=146.45, avg_loss=0.0042, train_err=0.1018
Eval: 128_h1=0.0075, 128_l2=0.0036
[209] time=465.44, avg_loss=0.0053, train_err=0.1264
Eval: 128_h1=0.0078, 128_l2=0.0039
[276] time=146.52, avg_loss=0.0042, train_err=0.1011
Eval: 128_h1=0.0074, 128_l2=0.0036
[389] time=243.10, avg_loss=0.0032, train_err=0.0768
Eval: 128_h1=0.0056, 128_l2=0.0031
[277] time=146.40, avg_loss=0.0042, train_err=0.1004
Eval: 128_h1=0.0074, 128_l2=0.0035
[390] time=236.01, avg_loss=0.0032, train_err=0.0772
Eval: 128_h1=0.0056, 128_l2=0.0031
[278] time=146.41, avg_loss=0.0042, train_err=0.0999
Eval: 128_h1=0.0074, 128_l2=0.0035
[210] time=430.76, avg_loss=0.0052, train_err=0.1252
Eval: 128_h1=0.0078, 128_l2=0.0040
[279] time=146.39, avg_loss=0.0042, train_err=0.0998
Eval: 128_h1=0.0073, 128_l2=0.0035
[391] time=237.59, avg_loss=0.0032, train_err=0.0773
Eval: 128_h1=0.0056, 128_l2=0.0031
[280] time=146.41, avg_loss=0.0042, train_err=0.0999
Eval: 128_h1=0.0074, 128_l2=0.0035
[281] time=146.42, avg_loss=0.0042, train_err=0.1004
[392] time=253.83, avg_loss=0.0032, train_err=0.0776
Eval: 128_h1=0.0074, 128_l2=0.0035
Eval: 128_h1=0.0056, 128_l2=0.0031
[211] time=460.37, avg_loss=0.0052, train_err=0.1241
Eval: 128_h1=0.0078, 128_l2=0.0040
[282] time=146.43, avg_loss=0.0042, train_err=0.1004
Eval: 128_h1=0.0074, 128_l2=0.0035
[393] time=237.13, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0056, 128_l2=0.0031
[283] time=146.51, avg_loss=0.0042, train_err=0.1006
Eval: 128_h1=0.0074, 128_l2=0.0036
[284] time=146.40, avg_loss=0.0043, train_err=0.1037
Eval: 128_h1=0.0074, 128_l2=0.0036
[394] time=238.54, avg_loss=0.0032, train_err=0.0777
[212] time=431.12, avg_loss=0.0051, train_err=0.1230
Eval: 128_h1=0.0056, 128_l2=0.0031
Eval: 128_h1=0.0078, 128_l2=0.0040
[285] time=146.39, avg_loss=0.0043, train_err=0.1039
Eval: 128_h1=0.0073, 128_l2=0.0035
[395] time=239.01, avg_loss=0.0032, train_err=0.0777
Eval: 128_h1=0.0056, 128_l2=0.0031
[286] time=146.38, avg_loss=0.0042, train_err=0.1007
Eval: 128_h1=0.0073, 128_l2=0.0035
[287] time=146.45, avg_loss=0.0041, train_err=0.0990
Eval: 128_h1=0.0073, 128_l2=0.0035
[213] time=454.17, avg_loss=0.0051, train_err=0.1221
Eval: 128_h1=0.0078, 128_l2=0.0040
[396] time=252.93, avg_loss=0.0033, train_err=0.0783
Eval: 128_h1=0.0057, 128_l2=0.0032
[288] time=146.42, avg_loss=0.0041, train_err=0.0981
Eval: 128_h1=0.0073, 128_l2=0.0035
[289] time=146.41, avg_loss=0.0041, train_err=0.0978
Eval: 128_h1=0.0073, 128_l2=0.0035
[397] time=236.65, avg_loss=0.0033, train_err=0.0787
Eval: 128_h1=0.0058, 128_l2=0.0033
[290] time=146.39, avg_loss=0.0041, train_err=0.0975
Eval: 128_h1=0.0073, 128_l2=0.0035
[214] time=431.75, avg_loss=0.0051, train_err=0.1212
Eval: 128_h1=0.0078, 128_l2=0.0041
[398] time=236.46, avg_loss=0.0033, train_err=0.0784
Eval: 128_h1=0.0057, 128_l2=0.0032
[291] time=146.40, avg_loss=0.0041, train_err=0.0975
Eval: 128_h1=0.0073, 128_l2=0.0035
[292] time=146.39, avg_loss=0.0041, train_err=0.0983
Eval: 128_h1=0.0073, 128_l2=0.0036
[399] time=244.66, avg_loss=0.0033, train_err=0.0780
Eval: 128_h1=0.0057, 128_l2=0.0032
[293] time=146.42, avg_loss=0.0042, train_err=0.1013
Eval: 128_h1=0.0073, 128_l2=0.0035
[215] time=456.79, avg_loss=0.0050, train_err=0.1203
Eval: 128_h1=0.0078, 128_l2=0.0041
[294] time=146.38, avg_loss=0.0043, train_err=0.1038
Eval: 128_h1=0.0073, 128_l2=0.0035
[400] time=252.65, avg_loss=0.0034, train_err=0.0823
Eval: 128_h1=0.0056, 128_l2=0.0030
[295] time=146.45, avg_loss=0.0044, train_err=0.1066
Eval: 128_h1=0.0074, 128_l2=0.0035
[401] time=234.02, avg_loss=0.0034, train_err=0.0810
Eval: 128_h1=0.0056, 128_l2=0.0030
[296] time=146.41, avg_loss=0.0046, train_err=0.1102
Eval: 128_h1=0.0078, 128_l2=0.0040
[216] time=433.67, avg_loss=0.0050, train_err=0.1195
Eval: 128_h1=0.0078, 128_l2=0.0041
[297] time=146.38, avg_loss=0.0046, train_err=0.1107
Eval: 128_h1=0.0078, 128_l2=0.0040
[402] time=235.00, avg_loss=0.0033, train_err=0.0801
Eval: 128_h1=0.0056, 128_l2=0.0030
[298] time=146.52, avg_loss=0.0045, train_err=0.1085
Eval: 128_h1=0.0077, 128_l2=0.0039
[403] time=241.51, avg_loss=0.0033, train_err=0.0794
[299] time=146.50, avg_loss=0.0045, train_err=0.1069
Eval: 128_h1=0.0076, 128_l2=0.0038
Eval: 128_h1=0.0056, 128_l2=0.0030
[217] time=439.36, avg_loss=0.0050, train_err=0.1187
Eval: 128_h1=0.0078, 128_l2=0.0041
[300] time=146.38, avg_loss=0.0047, train_err=0.1137
Eval: 128_h1=0.0076, 128_l2=0.0036
[404] time=242.52, avg_loss=0.0033, train_err=0.0790
Eval: 128_h1=0.0056, 128_l2=0.0031
[301] time=146.40, avg_loss=0.0046, train_err=0.1111
Eval: 128_h1=0.0075, 128_l2=0.0036
[302] time=146.45, avg_loss=0.0046, train_err=0.1091
Eval: 128_h1=0.0075, 128_l2=0.0036
[405] time=238.36, avg_loss=0.0033, train_err=0.0786
[218] time=440.08, avg_loss=0.0049, train_err=0.1180
Eval: 128_h1=0.0056, 128_l2=0.0031
Eval: 128_h1=0.0078, 128_l2=0.0041
[303] time=146.38, avg_loss=0.0045, train_err=0.1076
Eval: 128_h1=0.0074, 128_l2=0.0036
[406] time=243.61, avg_loss=0.0033, train_err=0.0782
Eval: 128_h1=0.0056, 128_l2=0.0031
[304] time=146.40, avg_loss=0.0044, train_err=0.1063
Eval: 128_h1=0.0074, 128_l2=0.0036
[305] time=146.38, avg_loss=0.0044, train_err=0.1052
Eval: 128_h1=0.0074, 128_l2=0.0035
[219] time=449.17, avg_loss=0.0049, train_err=0.1172
Eval: 128_h1=0.0078, 128_l2=0.0041
[407] time=244.36, avg_loss=0.0032, train_err=0.0779
Eval: 128_h1=0.0056, 128_l2=0.0031
[306] time=146.42, avg_loss=0.0043, train_err=0.1043
Eval: 128_h1=0.0073, 128_l2=0.0035
[307] time=146.38, avg_loss=0.0043, train_err=0.1035
Eval: 128_h1=0.0073, 128_l2=0.0035
[408] time=250.60, avg_loss=0.0032, train_err=0.0777
Eval: 128_h1=0.0056, 128_l2=0.0031
[308] time=146.39, avg_loss=0.0043, train_err=0.1027
Eval: 128_h1=0.0073, 128_l2=0.0035
[220] time=462.39, avg_loss=0.0049, train_err=0.1165
Eval: 128_h1=0.0078, 128_l2=0.0041
[409] time=247.61, avg_loss=0.0032, train_err=0.0774
[309] time=146.40, avg_loss=0.0043, train_err=0.1020
Eval: 128_h1=0.0056, 128_l2=0.0031
Eval: 128_h1=0.0073, 128_l2=0.0035
[310] time=146.39, avg_loss=0.0042, train_err=0.1013
Eval: 128_h1=0.0073, 128_l2=0.0035
[410] time=246.88, avg_loss=0.0032, train_err=0.0772
Eval: 128_h1=0.0056, 128_l2=0.0031
[311] time=146.41, avg_loss=0.0042, train_err=0.1007
Eval: 128_h1=0.0073, 128_l2=0.0035
[221] time=457.54, avg_loss=0.0048, train_err=0.1159
Eval: 128_h1=0.0078, 128_l2=0.0041
[312] time=146.41, avg_loss=0.0042, train_err=0.1001
Eval: 128_h1=0.0073, 128_l2=0.0035
[411] time=247.41, avg_loss=0.0032, train_err=0.0770
Eval: 128_h1=0.0056, 128_l2=0.0031
[313] time=146.40, avg_loss=0.0042, train_err=0.0996
Eval: 128_h1=0.0072, 128_l2=0.0035
[412] time=249.07, avg_loss=0.0032, train_err=0.0768
[314] time=146.37, avg_loss=0.0041, train_err=0.0991
Eval: 128_h1=0.0072, 128_l2=0.0035
Eval: 128_h1=0.0056, 128_l2=0.0030
[222] time=462.24, avg_loss=0.0048, train_err=0.1152
Eval: 128_h1=0.0078, 128_l2=0.0041
[315] time=146.40, avg_loss=0.0041, train_err=0.0986
Eval: 128_h1=0.0072, 128_l2=0.0035
[413] time=249.55, avg_loss=0.0032, train_err=0.0766
Eval: 128_h1=0.0056, 128_l2=0.0030
[316] time=146.39, avg_loss=0.0041, train_err=0.0981
Eval: 128_h1=0.0072, 128_l2=0.0035
[317] time=146.43, avg_loss=0.0041, train_err=0.0977
Eval: 128_h1=0.0072, 128_l2=0.0034
[414] time=247.18, avg_loss=0.0032, train_err=0.0764
Eval: 128_h1=0.0056, 128_l2=0.0030
[223] time=456.63, avg_loss=0.0048, train_err=0.1146
Eval: 128_h1=0.0078, 128_l2=0.0041
[318] time=146.44, avg_loss=0.0041, train_err=0.0973
Eval: 128_h1=0.0072, 128_l2=0.0034
[319] time=146.45, avg_loss=0.0040, train_err=0.0969
[415] time=246.11, avg_loss=0.0032, train_err=0.0762
Eval: 128_h1=0.0072, 128_l2=0.0034
Eval: 128_h1=0.0056, 128_l2=0.0030
[320] time=146.43, avg_loss=0.0040, train_err=0.0965
Eval: 128_h1=0.0072, 128_l2=0.0034
[416] time=248.22, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0056, 128_l2=0.0030
[224] time=458.63, avg_loss=0.0048, train_err=0.1140
Eval: 128_h1=0.0077, 128_l2=0.0041
[321] time=146.51, avg_loss=0.0040, train_err=0.0961
Eval: 128_h1=0.0072, 128_l2=0.0034
[322] time=146.46, avg_loss=0.0040, train_err=0.0957
Eval: 128_h1=0.0072, 128_l2=0.0034
[417] time=253.24, avg_loss=0.0032, train_err=0.0759
Eval: 128_h1=0.0056, 128_l2=0.0030
[323] time=146.41, avg_loss=0.0040, train_err=0.0954
Eval: 128_h1=0.0072, 128_l2=0.0034
[225] time=468.50, avg_loss=0.0047, train_err=0.1134
[324] time=146.41, avg_loss=0.0040, train_err=0.0950
Eval: 128_h1=0.0072, 128_l2=0.0034
[418] time=249.82, avg_loss=0.0032, train_err=0.0758
Eval: 128_h1=0.0077, 128_l2=0.0041
Eval: 128_h1=0.0056, 128_l2=0.0030
[325] time=146.40, avg_loss=0.0039, train_err=0.0947
Eval: 128_h1=0.0072, 128_l2=0.0034
[419] time=250.11, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0055, 128_l2=0.0030
[326] time=146.41, avg_loss=0.0039, train_err=0.0944
Eval: 128_h1=0.0072, 128_l2=0.0034
[327] time=146.39, avg_loss=0.0039, train_err=0.0940
Eval: 128_h1=0.0072, 128_l2=0.0034
[226] time=464.25, avg_loss=0.0047, train_err=0.1128
Eval: 128_h1=0.0077, 128_l2=0.0041
[420] time=249.94, avg_loss=0.0031, train_err=0.0755
Eval: 128_h1=0.0055, 128_l2=0.0030
[328] time=146.39, avg_loss=0.0039, train_err=0.0937
Eval: 128_h1=0.0072, 128_l2=0.0034
[329] time=146.44, avg_loss=0.0039, train_err=0.0934
Eval: 128_h1=0.0072, 128_l2=0.0034
[421] time=254.04, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0055, 128_l2=0.0030
[330] time=146.40, avg_loss=0.0039, train_err=0.0931
Eval: 128_h1=0.0071, 128_l2=0.0034
[227] time=470.45, avg_loss=0.0047, train_err=0.1123
Eval: 128_h1=0.0077, 128_l2=0.0041
[422] time=248.95, avg_loss=0.0031, train_err=0.0752
[331] time=146.40, avg_loss=0.0039, train_err=0.0928
Eval: 128_h1=0.0055, 128_l2=0.0030
Eval: 128_h1=0.0071, 128_l2=0.0034
[332] time=146.40, avg_loss=0.0039, train_err=0.0925
Eval: 128_h1=0.0071, 128_l2=0.0034
[423] time=245.08, avg_loss=0.0031, train_err=0.0751
Eval: 128_h1=0.0055, 128_l2=0.0030
[333] time=146.38, avg_loss=0.0038, train_err=0.0922
Eval: 128_h1=0.0071, 128_l2=0.0034
[228] time=452.76, avg_loss=0.0047, train_err=0.1119
Eval: 128_h1=0.0077, 128_l2=0.0041
[334] time=146.38, avg_loss=0.0038, train_err=0.0919
Eval: 128_h1=0.0071, 128_l2=0.0034
[424] time=245.29, avg_loss=0.0031, train_err=0.0750
Eval: 128_h1=0.0055, 128_l2=0.0030
[335] time=146.40, avg_loss=0.0038, train_err=0.0916
Eval: 128_h1=0.0071, 128_l2=0.0034
[425] time=242.90, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0055, 128_l2=0.0030
[336] time=146.44, avg_loss=0.0038, train_err=0.0913
Eval: 128_h1=0.0071, 128_l2=0.0034
[229] time=445.23, avg_loss=0.0047, train_err=0.1116
Eval: 128_h1=0.0077, 128_l2=0.0041
[337] time=146.39, avg_loss=0.0038, train_err=0.0910
Eval: 128_h1=0.0071, 128_l2=0.0034
[426] time=234.82, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0055, 128_l2=0.0030
[338] time=146.38, avg_loss=0.0038, train_err=0.0907
Eval: 128_h1=0.0071, 128_l2=0.0034
[339] time=146.47, avg_loss=0.0038, train_err=0.0903
Eval: 128_h1=0.0071, 128_l2=0.0034
[427] time=252.33, avg_loss=0.0031, train_err=0.0746
Eval: 128_h1=0.0055, 128_l2=0.0030
[230] time=455.88, avg_loss=0.0046, train_err=0.1115
Eval: 128_h1=0.0077, 128_l2=0.0042
[340] time=146.47, avg_loss=0.0037, train_err=0.0898
Eval: 128_h1=0.0071, 128_l2=0.0034
[428] time=242.64, avg_loss=0.0031, train_err=0.0745
Eval: 128_h1=0.0055, 128_l2=0.0030
[341] time=146.42, avg_loss=0.0037, train_err=0.0893
Eval: 128_h1=0.0071, 128_l2=0.0034
[342] time=146.40, avg_loss=0.0037, train_err=0.0888
Eval: 128_h1=0.0071, 128_l2=0.0034
[231] time=429.38, avg_loss=0.0047, train_err=0.1116
[429] time=232.86, avg_loss=0.0031, train_err=0.0744
Eval: 128_h1=0.0055, 128_l2=0.0030
Eval: 128_h1=0.0078, 128_l2=0.0042
[343] time=146.41, avg_loss=0.0037, train_err=0.0883
Eval: 128_h1=0.0071, 128_l2=0.0034
[344] time=146.45, avg_loss=0.0037, train_err=0.0881
[430] time=234.67, avg_loss=0.0031, train_err=0.0743
Eval: 128_h1=0.0071, 128_l2=0.0034
Eval: 128_h1=0.0055, 128_l2=0.0030
[345] time=146.39, avg_loss=0.0037, train_err=0.0879
Eval: 128_h1=0.0071, 128_l2=0.0034
[232] time=442.70, avg_loss=0.0047, train_err=0.1118
Eval: 128_h1=0.0078, 128_l2=0.0042
[431] time=251.18, avg_loss=0.0031, train_err=0.0742
Eval: 128_h1=0.0055, 128_l2=0.0030
[346] time=146.42, avg_loss=0.0037, train_err=0.0877
Eval: 128_h1=0.0071, 128_l2=0.0034
[347] time=146.50, avg_loss=0.0037, train_err=0.0876
Eval: 128_h1=0.0071, 128_l2=0.0034
[432] time=244.20, avg_loss=0.0031, train_err=0.0741
Eval: 128_h1=0.0055, 128_l2=0.0030
[348] time=146.39, avg_loss=0.0036, train_err=0.0874
Eval: 128_h1=0.0071, 128_l2=0.0034
[233] time=442.24, avg_loss=0.0047, train_err=0.1120
Eval: 128_h1=0.0077, 128_l2=0.0040
[433] time=232.42, avg_loss=0.0031, train_err=0.0740
[349] time=146.42, avg_loss=0.0036, train_err=0.0872
Eval: 128_h1=0.0055, 128_l2=0.0030
Eval: 128_h1=0.0071, 128_l2=0.0034
[350] time=146.40, avg_loss=0.0036, train_err=0.0870
Eval: 128_h1=0.0070, 128_l2=0.0034
[434] time=234.86, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0055, 128_l2=0.0030
[351] time=146.41, avg_loss=0.0036, train_err=0.0868
Eval: 128_h1=0.0070, 128_l2=0.0034
[234] time=432.66, avg_loss=0.0048, train_err=0.1142
Eval: 128_h1=0.0077, 128_l2=0.0040
[352] time=146.39, avg_loss=0.0036, train_err=0.0866
Eval: 128_h1=0.0070, 128_l2=0.0034
[435] time=249.78, avg_loss=0.0031, train_err=0.0738
Eval: 128_h1=0.0055, 128_l2=0.0029
[353] time=146.37, avg_loss=0.0036, train_err=0.0864
Eval: 128_h1=0.0070, 128_l2=0.0034
[436] time=245.75, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0055, 128_l2=0.0029
[354] time=146.40, avg_loss=0.0036, train_err=0.0862
Eval: 128_h1=0.0070, 128_l2=0.0034
[235] time=454.22, avg_loss=0.0049, train_err=0.1185
Eval: 128_h1=0.0081, 128_l2=0.0045
[355] time=146.42, avg_loss=0.0036, train_err=0.0860
Eval: 128_h1=0.0070, 128_l2=0.0033
[437] time=231.73, avg_loss=0.0031, train_err=0.0736
Eval: 128_h1=0.0055, 128_l2=0.0029
[356] time=146.40, avg_loss=0.0036, train_err=0.0859
Eval: 128_h1=0.0070, 128_l2=0.0033
[357] time=146.41, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0070, 128_l2=0.0033
[438] time=238.07, avg_loss=0.0031, train_err=0.0735
Eval: 128_h1=0.0055, 128_l2=0.0029
[236] time=430.36, avg_loss=0.0049, train_err=0.1173
Eval: 128_h1=0.0080, 128_l2=0.0044
[358] time=146.44, avg_loss=0.0036, train_err=0.0855
Eval: 128_h1=0.0070, 128_l2=0.0033
[439] time=239.48, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0055, 128_l2=0.0029
[359] time=146.47, avg_loss=0.0036, train_err=0.0854
Eval: 128_h1=0.0070, 128_l2=0.0033
[360] time=146.51, avg_loss=0.0036, train_err=0.0852
Eval: 128_h1=0.0070, 128_l2=0.0033
[237] time=440.49, avg_loss=0.0048, train_err=0.1161
[440] time=239.96, avg_loss=0.0031, train_err=0.0733
Eval: 128_h1=0.0079, 128_l2=0.0043
Eval: 128_h1=0.0055, 128_l2=0.0029
[361] time=146.51, avg_loss=0.0035, train_err=0.0850
Eval: 128_h1=0.0070, 128_l2=0.0033
[441] time=244.23, avg_loss=0.0031, train_err=0.0732
[362] time=146.41, avg_loss=0.0035, train_err=0.0848
Eval: 128_h1=0.0070, 128_l2=0.0033
Eval: 128_h1=0.0055, 128_l2=0.0029
[363] time=146.47, avg_loss=0.0035, train_err=0.0847
Eval: 128_h1=0.0070, 128_l2=0.0033
[238] time=453.46, avg_loss=0.0048, train_err=0.1147
Eval: 128_h1=0.0077, 128_l2=0.0041
[442] time=247.40, avg_loss=0.0031, train_err=0.0732
Eval: 128_h1=0.0055, 128_l2=0.0029
[364] time=146.53, avg_loss=0.0035, train_err=0.0845
Eval: 128_h1=0.0070, 128_l2=0.0033
[365] time=146.48, avg_loss=0.0035, train_err=0.0843
Eval: 128_h1=0.0070, 128_l2=0.0033
[443] time=248.61, avg_loss=0.0030, train_err=0.0731
Eval: 128_h1=0.0055, 128_l2=0.0029
[366] time=146.41, avg_loss=0.0035, train_err=0.0842
Eval: 128_h1=0.0070, 128_l2=0.0033
[239] time=461.45, avg_loss=0.0047, train_err=0.1125
Eval: 128_h1=0.0075, 128_l2=0.0037
[367] time=146.39, avg_loss=0.0035, train_err=0.0840
[444] time=249.01, avg_loss=0.0030, train_err=0.0730
Eval: 128_h1=0.0070, 128_l2=0.0033
Eval: 128_h1=0.0055, 128_l2=0.0029
[368] time=146.47, avg_loss=0.0035, train_err=0.0838
Eval: 128_h1=0.0070, 128_l2=0.0033
[445] time=249.97, avg_loss=0.0030, train_err=0.0729
Eval: 128_h1=0.0055, 128_l2=0.0029
[369] time=146.42, avg_loss=0.0035, train_err=0.0837
Eval: 128_h1=0.0069, 128_l2=0.0033
[240] time=463.59, avg_loss=0.0046, train_err=0.1099
Eval: 128_h1=0.0074, 128_l2=0.0037
[370] time=146.43, avg_loss=0.0035, train_err=0.0836
Eval: 128_h1=0.0069, 128_l2=0.0033
[446] time=249.42, avg_loss=0.0030, train_err=0.0728
Eval: 128_h1=0.0055, 128_l2=0.0029
[371] time=146.40, avg_loss=0.0035, train_err=0.0836
Eval: 128_h1=0.0069, 128_l2=0.0033
[372] time=146.46, avg_loss=0.0035, train_err=0.0836
Eval: 128_h1=0.0070, 128_l2=0.0033
[447] time=248.08, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0055, 128_l2=0.0029
[241] time=459.34, avg_loss=0.0045, train_err=0.1072
Eval: 128_h1=0.0074, 128_l2=0.0038
[373] time=146.40, avg_loss=0.0035, train_err=0.0837
Eval: 128_h1=0.0070, 128_l2=0.0033
[448] time=248.43, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0055, 128_l2=0.0029
[374] time=146.40, avg_loss=0.0035, train_err=0.0840
Eval: 128_h1=0.0070, 128_l2=0.0033
[375] time=146.50, avg_loss=0.0035, train_err=0.0848
Eval: 128_h1=0.0069, 128_l2=0.0033
[449] time=252.67, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0055, 128_l2=0.0029
[242] time=467.39, avg_loss=0.0044, train_err=0.1054
Eval: 128_h1=0.0074, 128_l2=0.0037
[376] time=146.40, avg_loss=0.0036, train_err=0.0866
Eval: 128_h1=0.0070, 128_l2=0.0033
[377] time=146.40, avg_loss=0.0037, train_err=0.0897
Eval: 128_h1=0.0070, 128_l2=0.0035
[450] time=247.18, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0055, 128_l2=0.0029
[378] time=146.47, avg_loss=0.0037, train_err=0.0899
Eval: 128_h1=0.0070, 128_l2=0.0035
[451] time=247.29, avg_loss=0.0030, train_err=0.0724
[243] time=456.92, avg_loss=0.0043, train_err=0.1040
Eval: 128_h1=0.0055, 128_l2=0.0029
[379] time=146.40, avg_loss=0.0037, train_err=0.0892
Eval: 128_h1=0.0070, 128_l2=0.0035
Eval: 128_h1=0.0073, 128_l2=0.0036
[380] time=146.43, avg_loss=0.0037, train_err=0.0888
Eval: 128_h1=0.0070, 128_l2=0.0034
[452] time=250.71, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0055, 128_l2=0.0029
[381] time=146.38, avg_loss=0.0037, train_err=0.0884
Eval: 128_h1=0.0070, 128_l2=0.0034
[382] time=146.40, avg_loss=0.0037, train_err=0.0879
[244] time=466.37, avg_loss=0.0043, train_err=0.1027
Eval: 128_h1=0.0069, 128_l2=0.0034
Eval: 128_h1=0.0073, 128_l2=0.0036
[453] time=250.23, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0055, 128_l2=0.0029
[383] time=146.40, avg_loss=0.0036, train_err=0.0874
Eval: 128_h1=0.0069, 128_l2=0.0033
[454] time=244.53, avg_loss=0.0030, train_err=0.0722
[384] time=146.39, avg_loss=0.0036, train_err=0.0868
Eval: 128_h1=0.0055, 128_l2=0.0029
Eval: 128_h1=0.0069, 128_l2=0.0033
[385] time=146.42, avg_loss=0.0036, train_err=0.0862
Eval: 128_h1=0.0069, 128_l2=0.0033
[245] time=448.85, avg_loss=0.0042, train_err=0.1016
Eval: 128_h1=0.0074, 128_l2=0.0038
[455] time=242.27, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0055, 128_l2=0.0029
[386] time=146.44, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0069, 128_l2=0.0033
[387] time=146.39, avg_loss=0.0036, train_err=0.0852
Eval: 128_h1=0.0069, 128_l2=0.0033
[456] time=244.88, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0055, 128_l2=0.0029
[388] time=146.39, avg_loss=0.0035, train_err=0.0847
Eval: 128_h1=0.0069, 128_l2=0.0033
[246] time=453.51, avg_loss=0.0042, train_err=0.1010
Eval: 128_h1=0.0073, 128_l2=0.0037
[457] time=249.81, avg_loss=0.0030, train_err=0.0719
[389] time=146.39, avg_loss=0.0035, train_err=0.0841
Eval: 128_h1=0.0055, 128_l2=0.0029
Eval: 128_h1=0.0069, 128_l2=0.0033
[390] time=146.40, avg_loss=0.0035, train_err=0.0834
Eval: 128_h1=0.0069, 128_l2=0.0034
[458] time=251.53, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0055, 128_l2=0.0029
[391] time=146.40, avg_loss=0.0034, train_err=0.0824
Eval: 128_h1=0.0069, 128_l2=0.0033
[247] time=464.03, avg_loss=0.0042, train_err=0.1009
Eval: 128_h1=0.0073, 128_l2=0.0037
[392] time=146.39, avg_loss=0.0034, train_err=0.0818
Eval: 128_h1=0.0068, 128_l2=0.0033
[459] time=242.87, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0055, 128_l2=0.0029
[393] time=146.39, avg_loss=0.0034, train_err=0.0813
Eval: 128_h1=0.0068, 128_l2=0.0033
[460] time=245.32, avg_loss=0.0030, train_err=0.0717
[394] time=146.39, avg_loss=0.0034, train_err=0.0809
Eval: 128_h1=0.0055, 128_l2=0.0029
Eval: 128_h1=0.0068, 128_l2=0.0033
[248] time=451.61, avg_loss=0.0042, train_err=0.1006
Eval: 128_h1=0.0073, 128_l2=0.0037
[395] time=146.39, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0068, 128_l2=0.0034
[461] time=248.42, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0055, 128_l2=0.0029
[396] time=146.39, avg_loss=0.0033, train_err=0.0802
Eval: 128_h1=0.0068, 128_l2=0.0034
[397] time=146.39, avg_loss=0.0033, train_err=0.0800
Eval: 128_h1=0.0068, 128_l2=0.0034
[462] time=244.91, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0055, 128_l2=0.0029
[249] time=455.48, avg_loss=0.0042, train_err=0.0997
Eval: 128_h1=0.0073, 128_l2=0.0037
[398] time=146.39, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0068, 128_l2=0.0034
[463] time=243.37, avg_loss=0.0030, train_err=0.0714
[399] time=146.40, avg_loss=0.0033, train_err=0.0797
Eval: 128_h1=0.0055, 128_l2=0.0029
Eval: 128_h1=0.0068, 128_l2=0.0034
[400] time=146.44, avg_loss=0.0037, train_err=0.0885
Eval: 128_h1=0.0069, 128_l2=0.0033
[250] time=452.60, avg_loss=0.0041, train_err=0.0991
[464] time=246.40, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0072, 128_l2=0.0036
Eval: 128_h1=0.0055, 128_l2=0.0028
[401] time=146.39, avg_loss=0.0037, train_err=0.0888
Eval: 128_h1=0.0069, 128_l2=0.0032
[402] time=146.39, avg_loss=0.0037, train_err=0.0883
Eval: 128_h1=0.0069, 128_l2=0.0032
[465] time=248.17, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0055, 128_l2=0.0028
[403] time=146.38, avg_loss=0.0037, train_err=0.0877
Eval: 128_h1=0.0069, 128_l2=0.0032
[251] time=445.65, avg_loss=0.0041, train_err=0.0987
Eval: 128_h1=0.0072, 128_l2=0.0036
[466] time=233.38, avg_loss=0.0030, train_err=0.0712
Eval: 128_h1=0.0054, 128_l2=0.0028
[404] time=146.41, avg_loss=0.0036, train_err=0.0871
Eval: 128_h1=0.0069, 128_l2=0.0032
[405] time=146.39, avg_loss=0.0036, train_err=0.0865
Eval: 128_h1=0.0068, 128_l2=0.0032
[467] time=248.62, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0054, 128_l2=0.0028
[406] time=146.43, avg_loss=0.0036, train_err=0.0861
Eval: 128_h1=0.0068, 128_l2=0.0032
[252] time=461.88, avg_loss=0.0041, train_err=0.0985
Eval: 128_h1=0.0072, 128_l2=0.0036
[407] time=146.40, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0068, 128_l2=0.0032
[468] time=248.89, avg_loss=0.0030, train_err=0.0710
Eval: 128_h1=0.0054, 128_l2=0.0028
[408] time=146.39, avg_loss=0.0036, train_err=0.0853
Eval: 128_h1=0.0068, 128_l2=0.0032
[469] time=234.62, avg_loss=0.0030, train_err=0.0710
Eval: 128_h1=0.0054, 128_l2=0.0028
[409] time=146.40, avg_loss=0.0035, train_err=0.0849
Eval: 128_h1=0.0068, 128_l2=0.0032
[253] time=429.39, avg_loss=0.0042, train_err=0.1004
Eval: 128_h1=0.0074, 128_l2=0.0039
[410] time=146.39, avg_loss=0.0035, train_err=0.0846
Eval: 128_h1=0.0068, 128_l2=0.0032
[470] time=234.31, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0054, 128_l2=0.0028
[411] time=146.38, avg_loss=0.0035, train_err=0.0844
Eval: 128_h1=0.0068, 128_l2=0.0032
[412] time=146.39, avg_loss=0.0035, train_err=0.0841
Eval: 128_h1=0.0068, 128_l2=0.0032
[471] time=242.12, avg_loss=0.0030, train_err=0.0708
Eval: 128_h1=0.0054, 128_l2=0.0028
[254] time=442.55, avg_loss=0.0043, train_err=0.1027
Eval: 128_h1=0.0073, 128_l2=0.0037
[413] time=146.39, avg_loss=0.0035, train_err=0.0838
Eval: 128_h1=0.0068, 128_l2=0.0032
[472] time=252.19, avg_loss=0.0030, train_err=0.0707
Eval: 128_h1=0.0054, 128_l2=0.0028
[414] time=146.37, avg_loss=0.0035, train_err=0.0836
Eval: 128_h1=0.0068, 128_l2=0.0032
[415] time=146.40, avg_loss=0.0035, train_err=0.0834
Eval: 128_h1=0.0068, 128_l2=0.0032
[473] time=234.26, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0054, 128_l2=0.0028
[255] time=441.43, avg_loss=0.0043, train_err=0.1023
Eval: 128_h1=0.0073, 128_l2=0.0037
[416] time=146.51, avg_loss=0.0035, train_err=0.0832
Eval: 128_h1=0.0068, 128_l2=0.0032
[474] time=235.05, avg_loss=0.0029, train_err=0.0706
[417] time=146.43, avg_loss=0.0035, train_err=0.0830
Eval: 128_h1=0.0054, 128_l2=0.0028
Eval: 128_h1=0.0068, 128_l2=0.0032
[418] time=146.48, avg_loss=0.0035, train_err=0.0828
Eval: 128_h1=0.0067, 128_l2=0.0032
[256] time=433.98, avg_loss=0.0043, train_err=0.1034
[475] time=240.74, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0074, 128_l2=0.0038
Eval: 128_h1=0.0054, 128_l2=0.0028
[419] time=146.46, avg_loss=0.0034, train_err=0.0826
Eval: 128_h1=0.0067, 128_l2=0.0032
[420] time=146.38, avg_loss=0.0034, train_err=0.0824
Eval: 128_h1=0.0067, 128_l2=0.0032
[476] time=254.28, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0054, 128_l2=0.0028
[421] time=146.39, avg_loss=0.0034, train_err=0.0822
Eval: 128_h1=0.0067, 128_l2=0.0032
[257] time=455.49, avg_loss=0.0043, train_err=0.1036
Eval: 128_h1=0.0075, 128_l2=0.0039
[477] time=234.64, avg_loss=0.0029, train_err=0.0704
[422] time=146.37, avg_loss=0.0034, train_err=0.0821
Eval: 128_h1=0.0054, 128_l2=0.0028
Eval: 128_h1=0.0067, 128_l2=0.0032
[423] time=146.42, avg_loss=0.0034, train_err=0.0819
Eval: 128_h1=0.0067, 128_l2=0.0032
[478] time=234.04, avg_loss=0.0029, train_err=0.0704
Eval: 128_h1=0.0054, 128_l2=0.0028
[424] time=146.39, avg_loss=0.0034, train_err=0.0817
Eval: 128_h1=0.0067, 128_l2=0.0032
[258] time=424.16, avg_loss=0.0043, train_err=0.1033
Eval: 128_h1=0.0075, 128_l2=0.0040
[425] time=146.39, avg_loss=0.0034, train_err=0.0816
Eval: 128_h1=0.0067, 128_l2=0.0032
[479] time=236.37, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0054, 128_l2=0.0028
[426] time=146.40, avg_loss=0.0034, train_err=0.0814
Eval: 128_h1=0.0067, 128_l2=0.0032
[480] time=253.14, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0054, 128_l2=0.0028
[427] time=146.39, avg_loss=0.0034, train_err=0.0813
Eval: 128_h1=0.0067, 128_l2=0.0032
[259] time=461.34, avg_loss=0.0043, train_err=0.1024
Eval: 128_h1=0.0074, 128_l2=0.0039
[428] time=146.45, avg_loss=0.0034, train_err=0.0812
Eval: 128_h1=0.0067, 128_l2=0.0032
[481] time=239.14, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0054, 128_l2=0.0028
[429] time=146.50, avg_loss=0.0034, train_err=0.0810
Eval: 128_h1=0.0067, 128_l2=0.0032
[430] time=146.37, avg_loss=0.0034, train_err=0.0809
[482] time=235.23, avg_loss=0.0029, train_err=0.0701
Eval: 128_h1=0.0067, 128_l2=0.0032
Eval: 128_h1=0.0054, 128_l2=0.0028
[260] time=428.88, avg_loss=0.0042, train_err=0.1017
Eval: 128_h1=0.0073, 128_l2=0.0038
[431] time=146.39, avg_loss=0.0034, train_err=0.0807
Eval: 128_h1=0.0067, 128_l2=0.0032
[483] time=236.98, avg_loss=0.0029, train_err=0.0701
Eval: 128_h1=0.0054, 128_l2=0.0028
[432] time=146.39, avg_loss=0.0034, train_err=0.0806
Eval: 128_h1=0.0067, 128_l2=0.0032
[433] time=146.38, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0067, 128_l2=0.0032
[484] time=255.42, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0054, 128_l2=0.0028
[261] time=460.07, avg_loss=0.0042, train_err=0.1013
Eval: 128_h1=0.0072, 128_l2=0.0037
[434] time=146.38, avg_loss=0.0034, train_err=0.0804
Eval: 128_h1=0.0067, 128_l2=0.0032
[485] time=236.07, avg_loss=0.0029, train_err=0.0700
[435] time=146.39, avg_loss=0.0033, train_err=0.0802
Eval: 128_h1=0.0067, 128_l2=0.0032
Eval: 128_h1=0.0054, 128_l2=0.0028
[436] time=146.41, avg_loss=0.0033, train_err=0.0801
Eval: 128_h1=0.0067, 128_l2=0.0032
[262] time=427.02, avg_loss=0.0042, train_err=0.1008
Eval: 128_h1=0.0072, 128_l2=0.0038
[486] time=234.23, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0054, 128_l2=0.0028
[437] time=146.38, avg_loss=0.0033, train_err=0.0800
Eval: 128_h1=0.0067, 128_l2=0.0032
[438] time=146.39, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0067, 128_l2=0.0031
[487] time=234.19, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0054, 128_l2=0.0028
[439] time=146.39, avg_loss=0.0033, train_err=0.0798
Eval: 128_h1=0.0067, 128_l2=0.0031
[263] time=440.13, avg_loss=0.0041, train_err=0.0995
Eval: 128_h1=0.0073, 128_l2=0.0038
[488] time=250.84, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0054, 128_l2=0.0028
[440] time=146.36, avg_loss=0.0033, train_err=0.0796
Eval: 128_h1=0.0067, 128_l2=0.0031
[441] time=146.38, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0067, 128_l2=0.0031
[489] time=241.66, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0054, 128_l2=0.0028
[442] time=146.41, avg_loss=0.0033, train_err=0.0794
Eval: 128_h1=0.0067, 128_l2=0.0031
[264] time=443.13, avg_loss=0.0041, train_err=0.0990
Eval: 128_h1=0.0072, 128_l2=0.0037
[443] time=146.41, avg_loss=0.0033, train_err=0.0793
Eval: 128_h1=0.0067, 128_l2=0.0031
[490] time=235.16, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0054, 128_l2=0.0028
[444] time=146.39, avg_loss=0.0033, train_err=0.0792
Eval: 128_h1=0.0067, 128_l2=0.0031
[491] time=235.35, avg_loss=0.0029, train_err=0.0697
Eval: 128_h1=0.0054, 128_l2=0.0028
[445] time=146.48, avg_loss=0.0033, train_err=0.0791
Eval: 128_h1=0.0067, 128_l2=0.0031
[265] time=434.14, avg_loss=0.0041, train_err=0.0981
Eval: 128_h1=0.0071, 128_l2=0.0037
[446] time=146.42, avg_loss=0.0033, train_err=0.0790
Eval: 128_h1=0.0067, 128_l2=0.0031
[492] time=251.64, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0054, 128_l2=0.0028
[447] time=146.43, avg_loss=0.0033, train_err=0.0789
Eval: 128_h1=0.0067, 128_l2=0.0031
[448] time=146.50, avg_loss=0.0033, train_err=0.0788
[493] time=244.30, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0066, 128_l2=0.0031
Eval: 128_h1=0.0054, 128_l2=0.0028
[266] time=457.44, avg_loss=0.0040, train_err=0.0969
Eval: 128_h1=0.0071, 128_l2=0.0036
[449] time=146.44, avg_loss=0.0033, train_err=0.0787
Eval: 128_h1=0.0066, 128_l2=0.0031
[494] time=235.70, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0054, 128_l2=0.0028
[450] time=146.39, avg_loss=0.0033, train_err=0.0786
Eval: 128_h1=0.0066, 128_l2=0.0031
[451] time=146.42, avg_loss=0.0033, train_err=0.0785
Eval: 128_h1=0.0066, 128_l2=0.0031
[495] time=237.13, avg_loss=0.0029, train_err=0.0702
[267] time=432.20, avg_loss=0.0040, train_err=0.0958
Eval: 128_h1=0.0054, 128_l2=0.0027
Eval: 128_h1=0.0071, 128_l2=0.0036
[452] time=146.44, avg_loss=0.0033, train_err=0.0784
Eval: 128_h1=0.0066, 128_l2=0.0031
[496] time=254.40, avg_loss=0.0029, train_err=0.0707
[453] time=146.37, avg_loss=0.0033, train_err=0.0783
Eval: 128_h1=0.0066, 128_l2=0.0031
Eval: 128_h1=0.0054, 128_l2=0.0027
[454] time=146.37, avg_loss=0.0033, train_err=0.0782
Eval: 128_h1=0.0066, 128_l2=0.0031
[268] time=461.09, avg_loss=0.0040, train_err=0.0950
Eval: 128_h1=0.0071, 128_l2=0.0036
[497] time=239.96, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0054, 128_l2=0.0028
[455] time=146.38, avg_loss=0.0033, train_err=0.0781
Eval: 128_h1=0.0066, 128_l2=0.0031
[456] time=146.44, avg_loss=0.0033, train_err=0.0780
Eval: 128_h1=0.0066, 128_l2=0.0031
[498] time=238.84, avg_loss=0.0030, train_err=0.0708
Eval: 128_h1=0.0054, 128_l2=0.0028
[457] time=146.42, avg_loss=0.0032, train_err=0.0779
Eval: 128_h1=0.0066, 128_l2=0.0031
[269] time=437.34, avg_loss=0.0039, train_err=0.0942
Eval: 128_h1=0.0071, 128_l2=0.0036
[499] time=239.03, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0054, 128_l2=0.0028
[458] time=146.44, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0066, 128_l2=0.0031
[459] time=146.39, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0066, 128_l2=0.0031
[500] time=254.47, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0053, 128_l2=0.0027
[460] time=146.38, avg_loss=0.0032, train_err=0.0777
Eval: 128_h1=0.0066, 128_l2=0.0031
[270] time=460.53, avg_loss=0.0039, train_err=0.0944
Eval: 128_h1=0.0072, 128_l2=0.0037
[461] time=146.39, avg_loss=0.0032, train_err=0.0776
Eval: 128_h1=0.0066, 128_l2=0.0031
[501] time=236.27, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0053, 128_l2=0.0027
[462] time=146.39, avg_loss=0.0032, train_err=0.0775
Eval: 128_h1=0.0066, 128_l2=0.0031
[502] time=236.42, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0053, 128_l2=0.0027
[463] time=146.41, avg_loss=0.0032, train_err=0.0774
Eval: 128_h1=0.0066, 128_l2=0.0031
[271] time=430.87, avg_loss=0.0039, train_err=0.0943
Eval: 128_h1=0.0071, 128_l2=0.0035
[464] time=146.42, avg_loss=0.0032, train_err=0.0773
Eval: 128_h1=0.0066, 128_l2=0.0031
[503] time=244.38, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0053, 128_l2=0.0027
[465] time=146.39, avg_loss=0.0032, train_err=0.0772
Eval: 128_h1=0.0066, 128_l2=0.0031
[466] time=146.37, avg_loss=0.0032, train_err=0.0771
Eval: 128_h1=0.0066, 128_l2=0.0031
[504] time=255.92, avg_loss=0.0030, train_err=0.0707
Eval: 128_h1=0.0053, 128_l2=0.0027
[272] time=467.01, avg_loss=0.0041, train_err=0.0982
Eval: 128_h1=0.0072, 128_l2=0.0036
[467] time=146.42, avg_loss=0.0032, train_err=0.0771
Eval: 128_h1=0.0066, 128_l2=0.0031
[505] time=232.68, avg_loss=0.0029, train_err=0.0706
Eval: 128_h1=0.0053, 128_l2=0.0027
[468] time=146.39, avg_loss=0.0032, train_err=0.0770
Eval: 128_h1=0.0066, 128_l2=0.0031
[469] time=146.39, avg_loss=0.0032, train_err=0.0769
Eval: 128_h1=0.0066, 128_l2=0.0031
[506] time=235.29, avg_loss=0.0029, train_err=0.0705
[273] time=424.40, avg_loss=0.0041, train_err=0.0974
Eval: 128_h1=0.0053, 128_l2=0.0027
Eval: 128_h1=0.0072, 128_l2=0.0038
[470] time=146.40, avg_loss=0.0032, train_err=0.0768
Eval: 128_h1=0.0066, 128_l2=0.0031
[471] time=146.39, avg_loss=0.0032, train_err=0.0767
[507] time=247.18, avg_loss=0.0029, train_err=0.0704
Eval: 128_h1=0.0066, 128_l2=0.0031
Eval: 128_h1=0.0053, 128_l2=0.0027
[472] time=146.43, avg_loss=0.0032, train_err=0.0766
Eval: 128_h1=0.0066, 128_l2=0.0031
[274] time=467.30, avg_loss=0.0040, train_err=0.0960
Eval: 128_h1=0.0071, 128_l2=0.0036
[508] time=251.60, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0053, 128_l2=0.0027
[473] time=146.49, avg_loss=0.0032, train_err=0.0766
Eval: 128_h1=0.0066, 128_l2=0.0031
[474] time=146.40, avg_loss=0.0032, train_err=0.0765
Eval: 128_h1=0.0066, 128_l2=0.0031
[509] time=232.06, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0053, 128_l2=0.0027
[475] time=146.41, avg_loss=0.0032, train_err=0.0764
Eval: 128_h1=0.0066, 128_l2=0.0031
[275] time=423.94, avg_loss=0.0040, train_err=0.0965
Eval: 128_h1=0.0071, 128_l2=0.0035
[510] time=234.63, avg_loss=0.0029, train_err=0.0701
[476] time=146.41, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0053, 128_l2=0.0027
Eval: 128_h1=0.0066, 128_l2=0.0031
[477] time=146.45, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0066, 128_l2=0.0031
[511] time=247.65, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0053, 128_l2=0.0027
[478] time=146.39, avg_loss=0.0032, train_err=0.0762
Eval: 128_h1=0.0066, 128_l2=0.0031
[276] time=463.44, avg_loss=0.0041, train_err=0.0976
Eval: 128_h1=0.0071, 128_l2=0.0035
[479] time=146.44, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0066, 128_l2=0.0031
[512] time=249.24, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0053, 128_l2=0.0027
[480] time=146.47, avg_loss=0.0032, train_err=0.0760
Eval: 128_h1=0.0066, 128_l2=0.0031
[513] time=232.90, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0053, 128_l2=0.0027
[481] time=146.47, avg_loss=0.0032, train_err=0.0759
Eval: 128_h1=0.0066, 128_l2=0.0031
[277] time=426.95, avg_loss=0.0041, train_err=0.0974
Eval: 128_h1=0.0071, 128_l2=0.0035
[482] time=146.42, avg_loss=0.0032, train_err=0.0759
Eval: 128_h1=0.0066, 128_l2=0.0031
[514] time=238.67, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0053, 128_l2=0.0027
[483] time=146.39, avg_loss=0.0032, train_err=0.0758
Eval: 128_h1=0.0066, 128_l2=0.0031
[484] time=146.46, avg_loss=0.0032, train_err=0.0757
Eval: 128_h1=0.0066, 128_l2=0.0031
[515] time=240.42, avg_loss=0.0029, train_err=0.0697
Eval: 128_h1=0.0053, 128_l2=0.0027
[278] time=441.43, avg_loss=0.0040, train_err=0.0964
Eval: 128_h1=0.0071, 128_l2=0.0035
[485] time=146.51, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0065, 128_l2=0.0031
[516] time=248.42, avg_loss=0.0029, train_err=0.0696
Eval: 128_h1=0.0053, 128_l2=0.0027
[486] time=146.46, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0065, 128_l2=0.0031
[487] time=146.40, avg_loss=0.0031, train_err=0.0755
Eval: 128_h1=0.0065, 128_l2=0.0031
[517] time=245.37, avg_loss=0.0029, train_err=0.0695
[279] time=457.38, avg_loss=0.0040, train_err=0.0954
Eval: 128_h1=0.0053, 128_l2=0.0027
Eval: 128_h1=0.0070, 128_l2=0.0035
[488] time=146.39, avg_loss=0.0031, train_err=0.0754
Eval: 128_h1=0.0065, 128_l2=0.0031
[489] time=146.42, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0065, 128_l2=0.0031
[518] time=240.86, avg_loss=0.0029, train_err=0.0695
Eval: 128_h1=0.0053, 128_l2=0.0027
[490] time=146.51, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0065, 128_l2=0.0031
[280] time=444.94, avg_loss=0.0039, train_err=0.0947
Eval: 128_h1=0.0070, 128_l2=0.0035
[519] time=242.87, avg_loss=0.0029, train_err=0.0694
Eval: 128_h1=0.0053, 128_l2=0.0027
[491] time=146.39, avg_loss=0.0031, train_err=0.0752
Eval: 128_h1=0.0065, 128_l2=0.0031
[492] time=146.39, avg_loss=0.0031, train_err=0.0751
Eval: 128_h1=0.0065, 128_l2=0.0031
[520] time=243.41, avg_loss=0.0029, train_err=0.0694
Eval: 128_h1=0.0052, 128_l2=0.0027
[493] time=146.45, avg_loss=0.0031, train_err=0.0750
Eval: 128_h1=0.0065, 128_l2=0.0031
[281] time=448.92, avg_loss=0.0039, train_err=0.0942
Eval: 128_h1=0.0070, 128_l2=0.0035
[494] time=146.39, avg_loss=0.0031, train_err=0.0750
[521] time=242.98, avg_loss=0.0029, train_err=0.0693
Eval: 128_h1=0.0065, 128_l2=0.0031
Eval: 128_h1=0.0052, 128_l2=0.0027
[495] time=146.39, avg_loss=0.0031, train_err=0.0749
Eval: 128_h1=0.0065, 128_l2=0.0030
[522] time=241.83, avg_loss=0.0029, train_err=0.0692
Eval: 128_h1=0.0052, 128_l2=0.0027
[496] time=146.41, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0065, 128_l2=0.0030
[282] time=445.14, avg_loss=0.0039, train_err=0.0939
Eval: 128_h1=0.0070, 128_l2=0.0036
[497] time=146.42, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0065, 128_l2=0.0030
[523] time=247.71, avg_loss=0.0029, train_err=0.0692
Eval: 128_h1=0.0052, 128_l2=0.0027
[498] time=146.41, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0065, 128_l2=0.0030
[499] time=146.39, avg_loss=0.0031, train_err=0.0746
[524] time=249.86, avg_loss=0.0029, train_err=0.0691
Eval: 128_h1=0.0065, 128_l2=0.0030
Eval: 128_h1=0.0052, 128_l2=0.0027
[283] time=456.95, avg_loss=0.0040, train_err=0.0949
Eval: 128_h1=0.0071, 128_l2=0.0036
[500] time=146.37, avg_loss=0.0032, train_err=0.0775
Eval: 128_h1=0.0065, 128_l2=0.0031
[525] time=233.36, avg_loss=0.0029, train_err=0.0691
Eval: 128_h1=0.0052, 128_l2=0.0027
[501] time=146.47, avg_loss=0.0032, train_err=0.0777
Eval: 128_h1=0.0065, 128_l2=0.0031
[502] time=146.46, avg_loss=0.0032, train_err=0.0775
Eval: 128_h1=0.0065, 128_l2=0.0031
[526] time=238.75, avg_loss=0.0029, train_err=0.0690
Eval: 128_h1=0.0052, 128_l2=0.0027
[284] time=433.75, avg_loss=0.0040, train_err=0.0961
Eval: 128_h1=0.0070, 128_l2=0.0038
[503] time=146.51, avg_loss=0.0032, train_err=0.0773
Eval: 128_h1=0.0065, 128_l2=0.0031
[527] time=242.41, avg_loss=0.0029, train_err=0.0690
Eval: 128_h1=0.0052, 128_l2=0.0027
[504] time=146.50, avg_loss=0.0032, train_err=0.0772
Eval: 128_h1=0.0065, 128_l2=0.0030
[505] time=146.41, avg_loss=0.0032, train_err=0.0770
Eval: 128_h1=0.0065, 128_l2=0.0030
[528] time=239.31, avg_loss=0.0029, train_err=0.0689
[285] time=442.27, avg_loss=0.0040, train_err=0.0967
Eval: 128_h1=0.0052, 128_l2=0.0027
Eval: 128_h1=0.0070, 128_l2=0.0037
[506] time=146.46, avg_loss=0.0032, train_err=0.0768
Eval: 128_h1=0.0065, 128_l2=0.0030
[507] time=146.39, avg_loss=0.0032, train_err=0.0766
Eval: 128_h1=0.0065, 128_l2=0.0030
[529] time=242.40, avg_loss=0.0029, train_err=0.0689
Eval: 128_h1=0.0052, 128_l2=0.0027
[508] time=146.48, avg_loss=0.0032, train_err=0.0765
Eval: 128_h1=0.0065, 128_l2=0.0030
[286] time=447.46, avg_loss=0.0041, train_err=0.0983
Eval: 128_h1=0.0073, 128_l2=0.0041
[530] time=243.02, avg_loss=0.0029, train_err=0.0688
Eval: 128_h1=0.0052, 128_l2=0.0027
[509] time=146.39, avg_loss=0.0032, train_err=0.0764
Eval: 128_h1=0.0065, 128_l2=0.0030
[510] time=146.39, avg_loss=0.0032, train_err=0.0762
Eval: 128_h1=0.0065, 128_l2=0.0030
[531] time=253.81, avg_loss=0.0029, train_err=0.0688
Eval: 128_h1=0.0052, 128_l2=0.0027
[511] time=146.45, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0065, 128_l2=0.0030
[287] time=457.90, avg_loss=0.0042, train_err=0.0997
Eval: 128_h1=0.0072, 128_l2=0.0038
[512] time=146.43, avg_loss=0.0032, train_err=0.0760
Eval: 128_h1=0.0065, 128_l2=0.0030
[532] time=236.11, avg_loss=0.0029, train_err=0.0687
Eval: 128_h1=0.0052, 128_l2=0.0027
[513] time=146.47, avg_loss=0.0032, train_err=0.0758
Eval: 128_h1=0.0065, 128_l2=0.0030
[533] time=235.79, avg_loss=0.0029, train_err=0.0687
Eval: 128_h1=0.0052, 128_l2=0.0027
[514] time=146.40, avg_loss=0.0032, train_err=0.0757
Eval: 128_h1=0.0065, 128_l2=0.0030
[288] time=432.83, avg_loss=0.0044, train_err=0.1047
Eval: 128_h1=0.0079, 128_l2=0.0048
[515] time=146.46, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0065, 128_l2=0.0030
[534] time=245.34, avg_loss=0.0029, train_err=0.0686
Eval: 128_h1=0.0052, 128_l2=0.0027
[516] time=146.51, avg_loss=0.0031, train_err=0.0755
Eval: 128_h1=0.0065, 128_l2=0.0030
[517] time=146.46, avg_loss=0.0031, train_err=0.0754
Eval: 128_h1=0.0065, 128_l2=0.0030
[535] time=255.57, avg_loss=0.0029, train_err=0.0686
Eval: 128_h1=0.0052, 128_l2=0.0027
[289] time=466.72, avg_loss=0.0046, train_err=0.1101
Eval: 128_h1=0.0079, 128_l2=0.0043
[518] time=146.45, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0065, 128_l2=0.0030
[536] time=235.86, avg_loss=0.0029, train_err=0.0685
Eval: 128_h1=0.0052, 128_l2=0.0027
[519] time=146.42, avg_loss=0.0031, train_err=0.0752
Eval: 128_h1=0.0065, 128_l2=0.0030
[520] time=146.44, avg_loss=0.0031, train_err=0.0752
Eval: 128_h1=0.0065, 128_l2=0.0030
[537] time=236.43, avg_loss=0.0029, train_err=0.0685
Eval: 128_h1=0.0052, 128_l2=0.0027
[290] time=429.79, avg_loss=0.0047, train_err=0.1126
Eval: 128_h1=0.0077, 128_l2=0.0042
[521] time=146.47, avg_loss=0.0031, train_err=0.0751
Eval: 128_h1=0.0064, 128_l2=0.0030
[538] time=244.45, avg_loss=0.0029, train_err=0.0685
[522] time=146.49, avg_loss=0.0031, train_err=0.0750
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0052, 128_l2=0.0027
[523] time=146.42, avg_loss=0.0031, train_err=0.0749
Eval: 128_h1=0.0064, 128_l2=0.0030
[539] time=253.65, avg_loss=0.0029, train_err=0.0684
Eval: 128_h1=0.0052, 128_l2=0.0027
[291] time=464.43, avg_loss=0.0047, train_err=0.1138
Eval: 128_h1=0.0077, 128_l2=0.0042
[524] time=146.39, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0064, 128_l2=0.0030
[525] time=146.50, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0064, 128_l2=0.0030
[540] time=232.09, avg_loss=0.0029, train_err=0.0684
Eval: 128_h1=0.0052, 128_l2=0.0027
[526] time=146.39, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0064, 128_l2=0.0030
[292] time=424.21, avg_loss=0.0047, train_err=0.1130
Eval: 128_h1=0.0076, 128_l2=0.0041
[541] time=235.04, avg_loss=0.0028, train_err=0.0683
Eval: 128_h1=0.0052, 128_l2=0.0027
[527] time=146.42, avg_loss=0.0031, train_err=0.0746
Eval: 128_h1=0.0064, 128_l2=0.0030
[528] time=146.38, avg_loss=0.0031, train_err=0.0745
Eval: 128_h1=0.0064, 128_l2=0.0030
[542] time=243.23, avg_loss=0.0028, train_err=0.0683
Eval: 128_h1=0.0052, 128_l2=0.0027
[529] time=146.40, avg_loss=0.0031, train_err=0.0745
Eval: 128_h1=0.0064, 128_l2=0.0030
[293] time=461.01, avg_loss=0.0047, train_err=0.1118
Eval: 128_h1=0.0076, 128_l2=0.0040
[530] time=146.41, avg_loss=0.0031, train_err=0.0744
Eval: 128_h1=0.0064, 128_l2=0.0030
[543] time=251.88, avg_loss=0.0028, train_err=0.0683
Eval: 128_h1=0.0052, 128_l2=0.0027
[531] time=146.45, avg_loss=0.0031, train_err=0.0743
Eval: 128_h1=0.0064, 128_l2=0.0030
[544] time=232.10, avg_loss=0.0028, train_err=0.0682
Eval: 128_h1=0.0052, 128_l2=0.0027
[532] time=146.41, avg_loss=0.0031, train_err=0.0743
Eval: 128_h1=0.0064, 128_l2=0.0030
[294] time=424.15, avg_loss=0.0046, train_err=0.1100
Eval: 128_h1=0.0075, 128_l2=0.0039
[533] time=146.42, avg_loss=0.0031, train_err=0.0742
Eval: 128_h1=0.0064, 128_l2=0.0030
[545] time=234.43, avg_loss=0.0028, train_err=0.0682
Eval: 128_h1=0.0052, 128_l2=0.0027
[534] time=146.41, avg_loss=0.0031, train_err=0.0742
Eval: 128_h1=0.0064, 128_l2=0.0030
[535] time=146.49, avg_loss=0.0031, train_err=0.0741
[546] time=243.97, avg_loss=0.0028, train_err=0.0681
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0052, 128_l2=0.0027
[295] time=450.41, avg_loss=0.0045, train_err=0.1083
Eval: 128_h1=0.0075, 128_l2=0.0038
[536] time=146.48, avg_loss=0.0031, train_err=0.0740
Eval: 128_h1=0.0064, 128_l2=0.0030
[547] time=252.43, avg_loss=0.0028, train_err=0.0681
Eval: 128_h1=0.0052, 128_l2=0.0027
[537] time=146.39, avg_loss=0.0031, train_err=0.0740
Eval: 128_h1=0.0064, 128_l2=0.0030
[538] time=146.50, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0064, 128_l2=0.0030
[548] time=234.89, avg_loss=0.0028, train_err=0.0681
Eval: 128_h1=0.0052, 128_l2=0.0027
[296] time=437.67, avg_loss=0.0044, train_err=0.1063
Eval: 128_h1=0.0075, 128_l2=0.0038
[539] time=146.47, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0064, 128_l2=0.0030
[549] time=236.09, avg_loss=0.0028, train_err=0.0680
[540] time=146.41, avg_loss=0.0031, train_err=0.0738
Eval: 128_h1=0.0052, 128_l2=0.0027
Eval: 128_h1=0.0064, 128_l2=0.0030
[541] time=146.43, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0064, 128_l2=0.0030
[550] time=245.77, avg_loss=0.0028, train_err=0.0680
[297] time=443.73, avg_loss=0.0043, train_err=0.1039
Eval: 128_h1=0.0052, 128_l2=0.0027
Eval: 128_h1=0.0075, 128_l2=0.0038
[542] time=146.40, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0064, 128_l2=0.0030
[543] time=146.41, avg_loss=0.0031, train_err=0.0736
Eval: 128_h1=0.0064, 128_l2=0.0030
[551] time=250.60, avg_loss=0.0028, train_err=0.0680
Eval: 128_h1=0.0052, 128_l2=0.0027
[544] time=146.40, avg_loss=0.0031, train_err=0.0736
Eval: 128_h1=0.0064, 128_l2=0.0030
[298] time=446.76, avg_loss=0.0042, train_err=0.1016
Eval: 128_h1=0.0074, 128_l2=0.0037
[552] time=235.39, avg_loss=0.0028, train_err=0.0679
[545] time=146.45, avg_loss=0.0031, train_err=0.0735
Eval: 128_h1=0.0052, 128_l2=0.0027
Eval: 128_h1=0.0064, 128_l2=0.0030
[546] time=146.48, avg_loss=0.0031, train_err=0.0735
Eval: 128_h1=0.0064, 128_l2=0.0030
[553] time=236.32, avg_loss=0.0028, train_err=0.0679
Eval: 128_h1=0.0052, 128_l2=0.0027
[547] time=146.39, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0064, 128_l2=0.0030
[299] time=433.51, avg_loss=0.0042, train_err=0.1001
Eval: 128_h1=0.0073, 128_l2=0.0036
[548] time=146.39, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0064, 128_l2=0.0030
[554] time=243.20, avg_loss=0.0028, train_err=0.0679
Eval: 128_h1=0.0052, 128_l2=0.0027
[549] time=146.41, avg_loss=0.0031, train_err=0.0733
Eval: 128_h1=0.0064, 128_l2=0.0030
[555] time=250.25, avg_loss=0.0028, train_err=0.0678
Eval: 128_h1=0.0052, 128_l2=0.0026
[550] time=146.41, avg_loss=0.0031, train_err=0.0733
Eval: 128_h1=0.0064, 128_l2=0.0030
[300] time=452.71, avg_loss=0.0046, train_err=0.1106
Eval: 128_h1=0.0072, 128_l2=0.0036
[551] time=146.49, avg_loss=0.0031, train_err=0.0732
Eval: 128_h1=0.0064, 128_l2=0.0030
[556] time=234.07, avg_loss=0.0028, train_err=0.0678
Eval: 128_h1=0.0052, 128_l2=0.0026
[552] time=146.43, avg_loss=0.0031, train_err=0.0732
Eval: 128_h1=0.0064, 128_l2=0.0030
[553] time=146.41, avg_loss=0.0030, train_err=0.0731
Eval: 128_h1=0.0064, 128_l2=0.0030
[557] time=239.36, avg_loss=0.0028, train_err=0.0677
Eval: 128_h1=0.0052, 128_l2=0.0026
[301] time=435.66, avg_loss=0.0045, train_err=0.1068
Eval: 128_h1=0.0071, 128_l2=0.0036
[554] time=146.40, avg_loss=0.0030, train_err=0.0731
Eval: 128_h1=0.0064, 128_l2=0.0030
[558] time=245.31, avg_loss=0.0028, train_err=0.0677
Eval: 128_h1=0.0052, 128_l2=0.0026
[555] time=146.41, avg_loss=0.0030, train_err=0.0730
Eval: 128_h1=0.0064, 128_l2=0.0030
[556] time=146.41, avg_loss=0.0030, train_err=0.0730
Eval: 128_h1=0.0064, 128_l2=0.0030
[559] time=247.50, avg_loss=0.0028, train_err=0.0677
Eval: 128_h1=0.0052, 128_l2=0.0026
[302] time=456.74, avg_loss=0.0043, train_err=0.1043
Eval: 128_h1=0.0070, 128_l2=0.0036
[557] time=146.39, avg_loss=0.0030, train_err=0.0729
Eval: 128_h1=0.0064, 128_l2=0.0030
[558] time=146.40, avg_loss=0.0030, train_err=0.0729
[560] time=234.85, avg_loss=0.0028, train_err=0.0676
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0052, 128_l2=0.0026
[559] time=146.50, avg_loss=0.0030, train_err=0.0728
Eval: 128_h1=0.0064, 128_l2=0.0030
[561] time=247.49, avg_loss=0.0028, train_err=0.0676
[303] time=445.71, avg_loss=0.0043, train_err=0.1026
Eval: 128_h1=0.0052, 128_l2=0.0026
Eval: 128_h1=0.0070, 128_l2=0.0036
[560] time=146.40, avg_loss=0.0030, train_err=0.0728
Eval: 128_h1=0.0064, 128_l2=0.0030
[561] time=146.39, avg_loss=0.0030, train_err=0.0728
Eval: 128_h1=0.0064, 128_l2=0.0030
[562] time=253.76, avg_loss=0.0028, train_err=0.0676
Eval: 128_h1=0.0052, 128_l2=0.0026
[562] time=146.42, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0064, 128_l2=0.0030
[304] time=466.10, avg_loss=0.0042, train_err=0.1013
[563] time=146.50, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0070, 128_l2=0.0036
Eval: 128_h1=0.0064, 128_l2=0.0030
[563] time=244.44, avg_loss=0.0028, train_err=0.0675
Eval: 128_h1=0.0052, 128_l2=0.0026
[564] time=146.42, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0064, 128_l2=0.0030
[564] time=233.51, avg_loss=0.0028, train_err=0.0675
Eval: 128_h1=0.0052, 128_l2=0.0026
[565] time=146.40, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0064, 128_l2=0.0030
[305] time=429.93, avg_loss=0.0042, train_err=0.1002
Eval: 128_h1=0.0070, 128_l2=0.0036
[566] time=146.42, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0064, 128_l2=0.0030
[565] time=239.47, avg_loss=0.0028, train_err=0.0675
Eval: 128_h1=0.0052, 128_l2=0.0026
[567] time=146.40, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0064, 128_l2=0.0030
[566] time=245.45, avg_loss=0.0028, train_err=0.0674
[568] time=146.39, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0052, 128_l2=0.0026
Eval: 128_h1=0.0064, 128_l2=0.0030
[306] time=449.92, avg_loss=0.0041, train_err=0.0992
Eval: 128_h1=0.0070, 128_l2=0.0036
[569] time=146.40, avg_loss=0.0030, train_err=0.0724
Eval: 128_h1=0.0064, 128_l2=0.0030
[567] time=247.19, avg_loss=0.0028, train_err=0.0674
Eval: 128_h1=0.0052, 128_l2=0.0026
[570] time=146.48, avg_loss=0.0030, train_err=0.0724
Eval: 128_h1=0.0064, 128_l2=0.0030
[571] time=146.40, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0064, 128_l2=0.0030
[568] time=250.59, avg_loss=0.0028, train_err=0.0674
Eval: 128_h1=0.0052, 128_l2=0.0026
[307] time=457.24, avg_loss=0.0041, train_err=0.0984
[572] time=146.39, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0070, 128_l2=0.0036
Eval: 128_h1=0.0064, 128_l2=0.0030
[569] time=232.56, avg_loss=0.0028, train_err=0.0673
Eval: 128_h1=0.0052, 128_l2=0.0026
[573] time=146.44, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0064, 128_l2=0.0030
[574] time=146.54, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0064, 128_l2=0.0030
[570] time=240.36, avg_loss=0.0028, train_err=0.0673
Eval: 128_h1=0.0052, 128_l2=0.0026
[308] time=436.37, avg_loss=0.0041, train_err=0.0976
[575] time=146.51, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0070, 128_l2=0.0036
Eval: 128_h1=0.0064, 128_l2=0.0030
[576] time=146.40, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0064, 128_l2=0.0030
[571] time=254.39, avg_loss=0.0028, train_err=0.0673
Eval: 128_h1=0.0052, 128_l2=0.0026
[577] time=146.50, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0064, 128_l2=0.0030
[572] time=246.28, avg_loss=0.0028, train_err=0.0673
[309] time=466.08, avg_loss=0.0040, train_err=0.0970
[578] time=146.46, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0052, 128_l2=0.0026
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0070, 128_l2=0.0036
[579] time=146.41, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0064, 128_l2=0.0030
[573] time=233.04, avg_loss=0.0028, train_err=0.0672
Eval: 128_h1=0.0052, 128_l2=0.0026
[580] time=146.39, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0064, 128_l2=0.0030
[310] time=428.90, avg_loss=0.0040, train_err=0.0963
[581] time=146.39, avg_loss=0.0030, train_err=0.0719
Eval: 128_h1=0.0070, 128_l2=0.0036
Eval: 128_h1=0.0064, 128_l2=0.0030
[574] time=237.46, avg_loss=0.0028, train_err=0.0672
Eval: 128_h1=0.0052, 128_l2=0.0026
[582] time=146.40, avg_loss=0.0030, train_err=0.0719
Eval: 128_h1=0.0064, 128_l2=0.0030
[575] time=253.92, avg_loss=0.0028, train_err=0.0672
Eval: 128_h1=0.0052, 128_l2=0.0026
[583] time=146.44, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0064, 128_l2=0.0030
[584] time=146.48, avg_loss=0.0030, train_err=0.0718
[311] time=466.58, avg_loss=0.0040, train_err=0.0957
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0070, 128_l2=0.0036
[576] time=242.88, avg_loss=0.0028, train_err=0.0671
Eval: 128_h1=0.0052, 128_l2=0.0026
[585] time=146.43, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0064, 128_l2=0.0030
[586] time=146.39, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0064, 128_l2=0.0030
[577] time=234.47, avg_loss=0.0028, train_err=0.0671
Eval: 128_h1=0.0052, 128_l2=0.0026
[312] time=428.98, avg_loss=0.0040, train_err=0.0952
[587] time=146.41, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0070, 128_l2=0.0036
[578] time=238.54, avg_loss=0.0028, train_err=0.0671
Eval: 128_h1=0.0052, 128_l2=0.0026
[588] time=146.39, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0064, 128_l2=0.0030
[589] time=146.40, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0064, 128_l2=0.0030
[579] time=252.55, avg_loss=0.0028, train_err=0.0670
Eval: 128_h1=0.0052, 128_l2=0.0026
[590] time=146.40, avg_loss=0.0030, train_err=0.0716
[313] time=464.14, avg_loss=0.0039, train_err=0.0947
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0070, 128_l2=0.0036
[591] time=146.50, avg_loss=0.0030, train_err=0.0715
[580] time=244.74, avg_loss=0.0028, train_err=0.0670
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0052, 128_l2=0.0026
[592] time=146.46, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0064, 128_l2=0.0030
[581] time=233.49, avg_loss=0.0028, train_err=0.0670
Eval: 128_h1=0.0052, 128_l2=0.0026
[314] time=428.94, avg_loss=0.0039, train_err=0.0942
[593] time=146.53, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0070, 128_l2=0.0036
[594] time=146.52, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0064, 128_l2=0.0030
[582] time=237.63, avg_loss=0.0028, train_err=0.0670
Eval: 128_h1=0.0052, 128_l2=0.0026
[595] time=146.50, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0064, 128_l2=0.0030
[583] time=238.96, avg_loss=0.0028, train_err=0.0669
[315] time=436.76, avg_loss=0.0039, train_err=0.0937
Eval: 128_h1=0.0052, 128_l2=0.0026
[596] time=146.80, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0069, 128_l2=0.0036
[597] time=157.50, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0064, 128_l2=0.0030
[584] time=239.66, avg_loss=0.0028, train_err=0.0669
Eval: 128_h1=0.0052, 128_l2=0.0026
[598] time=156.05, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0064, 128_l2=0.0030
[316] time=451.73, avg_loss=0.0039, train_err=0.0933
Eval: 128_h1=0.0069, 128_l2=0.0036
[599] time=155.12, avg_loss=0.0030, train_err=0.0713
[585] time=253.44, avg_loss=0.0028, train_err=0.0669
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0052, 128_l2=0.0026
[586] time=266.49, avg_loss=0.0028, train_err=0.0668
Eval: 128_h1=0.0052, 128_l2=0.0026
[317] time=524.32, avg_loss=0.0039, train_err=0.0929
Eval: 128_h1=0.0069, 128_l2=0.0036
[587] time=283.83, avg_loss=0.0028, train_err=0.0668
Eval: 128_h1=0.0052, 128_l2=0.0026
[588] time=301.78, avg_loss=0.0028, train_err=0.0668
Eval: 128_h1=0.0052, 128_l2=0.0026
[318] time=560.69, avg_loss=0.0039, train_err=0.0925
Eval: 128_h1=0.0069, 128_l2=0.0036
[589] time=267.26, avg_loss=0.0028, train_err=0.0667
Eval: 128_h1=0.0052, 128_l2=0.0026
logfile: /home/leeshu/wmm/neuraloperator-main/logs/darcy/20260130_083733__L8HC2_decay_421.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'arch': 'fno', 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_small2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [32, 32], 'hidden_channels': 32, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 2, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'_config_name': 'darcyoptconfig', 'n_epochs': 300, 'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.005, 'weight_decay': 0.0001, 'hc_weight_decay': 0.0, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 60, 'gamma': 0.5}, 'data': {'_config_name': 'darcydatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/Darcy_pt', 'batch_size': 8, 'n_train': 1000, 'train_resolution': 421, 'n_tests': [224], 'test_resolutions': [421], 'test_batch_sizes': [8], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'darcy32_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 421 with 224 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 32, 17]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 32, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(32, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0001

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.005
    lr: 0.005
    weight_decay: 0.0
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f09b0152850>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f09b01528b0>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f09b01528b0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f09b0152880>}

### Beginning Training...


n_params: 8937329
Training on 800 samples
Testing on [224] samples         on resolutions [421].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([8, 1, 421, 421])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[0] time=132.08, avg_loss=0.3356, train_err=2.6847
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 421_h1=0.1835, 421_l2=0.0941
[590] time=250.35, avg_loss=0.0028, train_err=0.0667
Eval: 128_h1=0.0052, 128_l2=0.0026
[1] time=130.30, avg_loss=0.1654, train_err=1.3236
Eval: 421_h1=0.1638, 421_l2=0.0861
[319] time=488.16, avg_loss=0.0038, train_err=0.0921
Eval: 128_h1=0.0069, 128_l2=0.0036
[2] time=130.24, avg_loss=0.1355, train_err=1.0840
Eval: 421_h1=0.1293, 421_l2=0.0782
[591] time=259.85, avg_loss=0.0028, train_err=0.0667
Eval: 128_h1=0.0052, 128_l2=0.0026
logfile: /home/leeshu/wmm/neuraloperator-main/logs/navier_stokes/20260130_084615__L8HC2_decay_NS.log
##### CONFIG #####

{'_config_name': 'default', 'n_params_baseline': None, 'verbose': True, 'distributed': {'use_distributed': False, 'model_parallel_size': 1, 'seed': None}, 'model': {'_config_name': 'fno_medium2d', 'arch': None, 'data_channels': 1, 'out_channels': 1, 'model_arch': 'fno', 'n_modes': [64, 64], 'hidden_channels': 64, 'lifting_channel_ratio': 2, 'projection_channel_ratio': 4, 'n_layers': 8, 'domain_padding': 0.0, 'norm': None, 'fno_skip': 'linear', 'implementation': 'factorized', 'use_channel_mlp': True, 'channel_mlp_expansion': 0.5, 'channel_mlp_dropout': 0, 'separable': False, 'factorization': None, 'rank': 1.0, 'fixed_rank_modes': False, 'stabilizer': None, 'hc_rate': 2, 'hc_dynamic': True}, 'opt': {'_config_name': 'navierstokesoptconfig', 'n_epochs': 600, 'training_loss': 'h1', 'testing_loss': 'l2', 'learning_rate': 0.0003, 'weight_decay': 0.0001, 'hc_weight_decay': 0.0, 'eval_interval': 1, 'mixed_precision': False, 'scheduler': 'StepLR', 'scheduler_T_max': 500, 'scheduler_patience': 50, 'step_size': 100, 'gamma': 0.5}, 'data': {'_config_name': 'navierstokesdatasetconfig', 'folder': '/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/data/V1e-3_N5000_T50', 'batch_size': 24, 'n_train': 10000, 'train_resolution': 128, 'n_tests': [2000], 'test_resolutions': [128], 'test_batch_sizes': [24], 'encode_input': True, 'encode_output': True, 'download': False}, 'patching': {'levels': 0, 'padding': 0, 'stitching': False}, 'wandb': {'_config_name': 'wandbconfig', 'log': False, 'entity': None, 'project': 'your_project', 'name': 'ns128_hc_run', 'group': None, 'sweep': False, 'log_output': True}}
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(
Loading test db for resolution 128 with 2000 samples 
/home/leeshu/wmm/neuraloperator-main/neuralop/data/datasets/pt_dataset.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(Path(root_dir).joinpath(f"{dataset_name}_test_{res}.pt").as_posix())

### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-7): 8 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([64, 64, 64, 33]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-7): 8 x Flattened1dConv(
        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-7): 8 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-7): 8 x SoftGating()
    )
  )
  (hc_layers): ModuleList(
    (0-7): 8 x HyperConnection(
      (layer_norm): GroupNorm(1, 64, eps=1e-05, affine=True)
      (dynamic_alpha_fn): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (dynamic_beta_fn): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0001

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0.0
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.StepLR object at 0x7f1c484213d0>

### LOSSES ###

 * Train: <neuralop.losses.data_losses.H1Loss object at 0x7f1c48421040>

 * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x7f1c48421040>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x7f1c48421400>}

### Beginning Training...


n_params: 138510225
Training on 10000 samples
Testing on [2000] samples         on resolutions [128].
/home/leeshu/anaconda3/envs/FNO1/lib/python3.9/site-packages/torch/nn/modules/module.py:1747: UserWarning: FNO.forward() received unexpected keyword arguments: ['y']. These arguments will be ignored.
  return forward_call(*args, **kwargs)
Raw outputs of shape torch.Size([24, 1, 128, 128])
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:536: UserWarning: H1Loss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  loss += training_loss(out, **sample)
[3] time=130.24, avg_loss=0.1213, train_err=0.9707
Eval: 421_h1=0.1137, 421_l2=0.0680
[4] time=130.25, avg_loss=0.1093, train_err=0.8746
[0] time=181.20, avg_loss=0.1221, train_err=2.9284
/home/leeshu/wmm/neuraloperator-main/neuralop/training/trainer.py:581: UserWarning: LpLoss.__call__() received unexpected keyword arguments: ['x']. These arguments will be ignored.
  val_loss = loss(out, **sample)
Eval: 128_h1=0.0785, 128_l2=0.0558
Eval: 421_h1=0.1138, 421_l2=0.0692
[592] time=262.83, avg_loss=0.0028, train_err=0.0667
Eval: 128_h1=0.0052, 128_l2=0.0026
[5] time=130.24, avg_loss=0.1110, train_err=0.8879
Eval: 421_h1=0.1004, 421_l2=0.0603
[320] time=489.91, avg_loss=0.0038, train_err=0.0917
[1] time=180.44, avg_loss=0.0693, train_err=1.6622
Eval: 128_h1=0.0069, 128_l2=0.0036
Eval: 128_h1=0.0629, 128_l2=0.0534
[6] time=130.25, avg_loss=0.0961, train_err=0.7688
Eval: 421_h1=0.1086, 421_l2=0.0668
[593] time=257.30, avg_loss=0.0028, train_err=0.0666
Eval: 128_h1=0.0052, 128_l2=0.0026
[2] time=176.12, avg_loss=0.0572, train_err=1.3715
Eval: 128_h1=0.0553, 128_l2=0.0517
[7] time=130.26, avg_loss=0.0957, train_err=0.7660
Eval: 421_h1=0.1035, 421_l2=0.0610
[3] time=175.78, avg_loss=0.0504, train_err=1.2084
[8] time=130.25, avg_loss=0.0886, train_err=0.7087
Eval: 128_h1=0.0503, 128_l2=0.0498
Eval: 421_h1=0.0916, 421_l2=0.0508
[594] time=261.45, avg_loss=0.0028, train_err=0.0666
Eval: 128_h1=0.0052, 128_l2=0.0026
[321] time=487.19, avg_loss=0.0038, train_err=0.0913
Eval: 128_h1=0.0069, 128_l2=0.0036
[9] time=130.26, avg_loss=0.0829, train_err=0.6630
Eval: 421_h1=0.0886, 421_l2=0.0457
[4] time=173.24, avg_loss=0.0459, train_err=1.1003
Eval: 128_h1=0.0468, 128_l2=0.0477
[10] time=130.23, avg_loss=0.0789, train_err=0.6309
[595] time=250.75, avg_loss=0.0028, train_err=0.0666
Eval: 421_h1=0.0825, 421_l2=0.0403
Eval: 128_h1=0.0052, 128_l2=0.0026
[5] time=176.73, avg_loss=0.0424, train_err=1.0165
Eval: 128_h1=0.0441, 128_l2=0.0457
[11] time=130.26, avg_loss=0.0835, train_err=0.6679
Eval: 421_h1=0.0962, 421_l2=0.0537
[6] time=179.28, avg_loss=0.0396, train_err=0.9501
[596] time=250.12, avg_loss=0.0028, train_err=0.0666
Eval: 128_h1=0.0419, 128_l2=0.0438
[12] time=130.25, avg_loss=0.0778, train_err=0.6223
Eval: 128_h1=0.0052, 128_l2=0.0026
Eval: 421_h1=0.0903, 421_l2=0.0433
[322] time=460.32, avg_loss=0.0038, train_err=0.0910
Eval: 128_h1=0.0069, 128_l2=0.0035
[13] time=130.27, avg_loss=0.0716, train_err=0.5726
Eval: 421_h1=0.0785, 421_l2=0.0366
[7] time=180.07, avg_loss=0.0373, train_err=0.8950
Eval: 128_h1=0.0400, 128_l2=0.0419
[597] time=246.93, avg_loss=0.0028, train_err=0.0665
Eval: 128_h1=0.0052, 128_l2=0.0026
[14] time=130.25, avg_loss=0.0690, train_err=0.5517
Eval: 421_h1=0.0828, 421_l2=0.0379
[8] time=173.25, avg_loss=0.0354, train_err=0.8484
Eval: 128_h1=0.0382, 128_l2=0.0401
[15] time=130.24, avg_loss=0.0694, train_err=0.5550
Eval: 421_h1=0.0771, 421_l2=0.0322
[598] time=260.64, avg_loss=0.0028, train_err=0.0665
[323] time=475.51, avg_loss=0.0038, train_err=0.0906
[9] time=174.73, avg_loss=0.0337, train_err=0.8083
Eval: 128_h1=0.0052, 128_l2=0.0026
Eval: 128_h1=0.0366, 128_l2=0.0384
Eval: 128_h1=0.0069, 128_l2=0.0035
[16] time=130.24, avg_loss=0.0680, train_err=0.5443
Eval: 421_h1=0.0838, 421_l2=0.0404
[17] time=130.23, avg_loss=0.0667, train_err=0.5334
[10] time=173.66, avg_loss=0.0322, train_err=0.7732
Eval: 128_h1=0.0350, 128_l2=0.0366
Eval: 421_h1=0.0792, 421_l2=0.0357
[599] time=239.71, avg_loss=0.0028, train_err=0.0665
Eval: 128_h1=0.0052, 128_l2=0.0026
NS.sh: 57: exit: Illegal number: 0FILE 2>/dev/null || echo 1)
[18] time=130.22, avg_loss=0.0624, train_err=0.4995
Eval: 421_h1=0.0748, 421_l2=0.0288
[324] time=326.71, avg_loss=0.0038, train_err=0.0903
[11] time=167.20, avg_loss=0.0309, train_err=0.7421
Eval: 128_h1=0.0069, 128_l2=0.0035
Eval: 128_h1=0.0336, 128_l2=0.0350
[19] time=130.22, avg_loss=0.0613, train_err=0.4900
Eval: 421_h1=0.0783, 421_l2=0.0358
[12] time=166.44, avg_loss=0.0298, train_err=0.7140
Eval: 128_h1=0.0322, 128_l2=0.0334
[325] time=202.40, avg_loss=0.0038, train_err=0.0900
Eval: 128_h1=0.0069, 128_l2=0.0035
[20] time=130.22, avg_loss=0.0641, train_err=0.5124
Eval: 421_h1=0.0847, 421_l2=0.0326
[13] time=166.46, avg_loss=0.0287, train_err=0.6884
Eval: 128_h1=0.0310, 128_l2=0.0318
[21] time=130.24, avg_loss=0.0653, train_err=0.5227
Eval: 421_h1=0.0772, 421_l2=0.0280
[326] time=205.08, avg_loss=0.0037, train_err=0.0897
Eval: 128_h1=0.0069, 128_l2=0.0035
[14] time=166.46, avg_loss=0.0278, train_err=0.6661
[22] time=130.22, avg_loss=0.0599, train_err=0.4792
Eval: 128_h1=0.0309, 128_l2=0.0307
Eval: 421_h1=0.0742, 421_l2=0.0296
[327] time=220.09, avg_loss=0.0037, train_err=0.0894
Eval: 128_h1=0.0068, 128_l2=0.0035
[23] time=130.23, avg_loss=0.0622, train_err=0.4976
Eval: 421_h1=0.0891, 421_l2=0.0438
[15] time=174.68, avg_loss=0.0272, train_err=0.6511
Eval: 128_h1=0.0295, 128_l2=0.0290
[24] time=130.27, avg_loss=0.0600, train_err=0.4802
Eval: 421_h1=0.0735, 421_l2=0.0285
[328] time=204.69, avg_loss=0.0037, train_err=0.0891
Eval: 128_h1=0.0068, 128_l2=0.0035
[16] time=174.40, avg_loss=0.0263, train_err=0.6316
Eval: 128_h1=0.0290, 128_l2=0.0282
[25] time=130.22, avg_loss=0.0606, train_err=0.4850
Eval: 421_h1=0.0716, 421_l2=0.0251
[329] time=199.91, avg_loss=0.0037, train_err=0.0888
[17] time=176.54, avg_loss=0.0251, train_err=0.6018
Eval: 128_h1=0.0277, 128_l2=0.0267
Eval: 128_h1=0.0068, 128_l2=0.0035
[26] time=130.24, avg_loss=0.0579, train_err=0.4636
Eval: 421_h1=0.0728, 421_l2=0.0257
[27] time=130.23, avg_loss=0.0536, train_err=0.4286
Eval: 421_h1=0.0721, 421_l2=0.0263
[18] time=178.33, avg_loss=0.0244, train_err=0.5844
Eval: 128_h1=0.0272, 128_l2=0.0257
[330] time=214.05, avg_loss=0.0037, train_err=0.0885
Eval: 128_h1=0.0068, 128_l2=0.0035
[28] time=130.25, avg_loss=0.0560, train_err=0.4477
Eval: 421_h1=0.0752, 421_l2=0.0258
[19] time=178.52, avg_loss=0.0238, train_err=0.5709
Eval: 128_h1=0.0262, 128_l2=0.0245
[331] time=213.69, avg_loss=0.0037, train_err=0.0882
[29] time=130.25, avg_loss=0.0580, train_err=0.4639
Eval: 128_h1=0.0068, 128_l2=0.0035
Eval: 421_h1=0.0731, 421_l2=0.0244
[20] time=178.25, avg_loss=0.0232, train_err=0.5573
Eval: 128_h1=0.0252, 128_l2=0.0234
[30] time=130.24, avg_loss=0.0573, train_err=0.4584
Eval: 421_h1=0.0730, 421_l2=0.0234
[332] time=206.45, avg_loss=0.0037, train_err=0.0879
Eval: 128_h1=0.0068, 128_l2=0.0035
[31] time=130.23, avg_loss=0.0572, train_err=0.4573
Eval: 421_h1=0.0722, 421_l2=0.0253
[21] time=179.12, avg_loss=0.0227, train_err=0.5443
Eval: 128_h1=0.0251, 128_l2=0.0226
[32] time=130.22, avg_loss=0.0574, train_err=0.4589
[333] time=209.09, avg_loss=0.0037, train_err=0.0877
Eval: 421_h1=0.0704, 421_l2=0.0203
Eval: 128_h1=0.0068, 128_l2=0.0035
[22] time=179.59, avg_loss=0.0221, train_err=0.5296
Eval: 128_h1=0.0248, 128_l2=0.0219
[33] time=130.22, avg_loss=0.0533, train_err=0.4268
Eval: 421_h1=0.0713, 421_l2=0.0225
[334] time=225.43, avg_loss=0.0036, train_err=0.0874
[23] time=178.61, avg_loss=0.0234, train_err=0.5603
Eval: 128_h1=0.0068, 128_l2=0.0035
Eval: 128_h1=0.0255, 128_l2=0.0233
[34] time=130.23, avg_loss=0.0532, train_err=0.4252
Eval: 421_h1=0.0743, 421_l2=0.0249
[35] time=130.22, avg_loss=0.0551, train_err=0.4411
[24] time=178.81, avg_loss=0.0225, train_err=0.5404
Eval: 421_h1=0.0780, 421_l2=0.0274
Eval: 128_h1=0.0247, 128_l2=0.0208
[335] time=209.89, avg_loss=0.0036, train_err=0.0871
Eval: 128_h1=0.0068, 128_l2=0.0035
[36] time=130.23, avg_loss=0.0527, train_err=0.4217
Eval: 421_h1=0.0705, 421_l2=0.0215
[25] time=178.87, avg_loss=0.0229, train_err=0.5481
Eval: 128_h1=0.0261, 128_l2=0.0200
[336] time=200.97, avg_loss=0.0036, train_err=0.0868
Eval: 128_h1=0.0068, 128_l2=0.0035
[37] time=130.22, avg_loss=0.0530, train_err=0.4243
Eval: 421_h1=0.0702, 421_l2=0.0200
[26] time=179.30, avg_loss=0.0217, train_err=0.5209
Eval: 128_h1=0.0248, 128_l2=0.0192
[38] time=130.23, avg_loss=0.0509, train_err=0.4072
Eval: 421_h1=0.0696, 421_l2=0.0203
[337] time=204.41, avg_loss=0.0036, train_err=0.0866
Eval: 128_h1=0.0068, 128_l2=0.0035
[39] time=130.26, avg_loss=0.0501, train_err=0.4007
[27] time=178.47, avg_loss=0.0211, train_err=0.5069
Eval: 421_h1=0.0740, 421_l2=0.0271
Eval: 128_h1=0.0234, 128_l2=0.0181
[338] time=215.00, avg_loss=0.0036, train_err=0.0863
Eval: 128_h1=0.0067, 128_l2=0.0034
[40] time=130.23, avg_loss=0.0528, train_err=0.4225
Eval: 421_h1=0.0729, 421_l2=0.0231
[28] time=179.02, avg_loss=0.0209, train_err=0.5008
Eval: 128_h1=0.0226, 128_l2=0.0173
[41] time=130.24, avg_loss=0.0522, train_err=0.4178
Eval: 421_h1=0.0695, 421_l2=0.0197
[339] time=224.14, avg_loss=0.0036, train_err=0.0860
Eval: 128_h1=0.0067, 128_l2=0.0034
[29] time=179.07, avg_loss=0.0200, train_err=0.4793
Eval: 128_h1=0.0222, 128_l2=0.0168
[42] time=130.23, avg_loss=0.0499, train_err=0.3995
Eval: 421_h1=0.0699, 421_l2=0.0197
[30] time=178.97, avg_loss=0.0195, train_err=0.4678
[43] time=130.22, avg_loss=0.0539, train_err=0.4312
[340] time=203.13, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0207, 128_l2=0.0163
Eval: 421_h1=0.0697, 421_l2=0.0181
Eval: 128_h1=0.0067, 128_l2=0.0034
[44] time=130.24, avg_loss=0.0509, train_err=0.4069
Eval: 421_h1=0.0692, 421_l2=0.0197
[31] time=178.62, avg_loss=0.0190, train_err=0.4563
Eval: 128_h1=0.0203, 128_l2=0.0160
[341] time=206.59, avg_loss=0.0036, train_err=0.0855
Eval: 128_h1=0.0067, 128_l2=0.0034
[45] time=130.23, avg_loss=0.0492, train_err=0.3932
Eval: 421_h1=0.0694, 421_l2=0.0218
[32] time=178.46, avg_loss=0.0188, train_err=0.4515
Eval: 128_h1=0.0200, 128_l2=0.0158
[46] time=130.24, avg_loss=0.0479, train_err=0.3833
Eval: 421_h1=0.0878, 421_l2=0.0402
[342] time=210.09, avg_loss=0.0036, train_err=0.0852
Eval: 128_h1=0.0067, 128_l2=0.0033
[33] time=179.22, avg_loss=0.0184, train_err=0.4419
[47] time=130.23, avg_loss=0.0513, train_err=0.4100
Eval: 128_h1=0.0196, 128_l2=0.0152
Eval: 421_h1=0.0690, 421_l2=0.0168
[343] time=218.46, avg_loss=0.0035, train_err=0.0850
Eval: 128_h1=0.0067, 128_l2=0.0033
[48] time=130.24, avg_loss=0.0462, train_err=0.3700
Eval: 421_h1=0.0693, 421_l2=0.0169
[34] time=178.95, avg_loss=0.0188, train_err=0.4503
Eval: 128_h1=0.0218, 128_l2=0.0150
[49] time=130.26, avg_loss=0.0473, train_err=0.3787
Eval: 421_h1=0.0686, 421_l2=0.0199
[344] time=219.84, avg_loss=0.0035, train_err=0.0848
Eval: 128_h1=0.0066, 128_l2=0.0033
[35] time=179.98, avg_loss=0.0194, train_err=0.4661
Eval: 128_h1=0.0199, 128_l2=0.0138
[50] time=130.26, avg_loss=0.0567, train_err=0.4534
Eval: 421_h1=0.0723, 421_l2=0.0206
[345] time=200.75, avg_loss=0.0035, train_err=0.0846
Eval: 128_h1=0.0066, 128_l2=0.0033
[36] time=180.05, avg_loss=0.0180, train_err=0.4317
Eval: 128_h1=0.0188, 128_l2=0.0134
[51] time=130.25, avg_loss=0.0498, train_err=0.3986
Eval: 421_h1=0.0809, 421_l2=0.0375
[52] time=130.27, avg_loss=0.0471, train_err=0.3764
Eval: 421_h1=0.0685, 421_l2=0.0169
[37] time=178.74, avg_loss=0.0170, train_err=0.4086
Eval: 128_h1=0.0187, 128_l2=0.0133
[346] time=205.47, avg_loss=0.0035, train_err=0.0845
Eval: 128_h1=0.0066, 128_l2=0.0033
[53] time=130.24, avg_loss=0.0445, train_err=0.3563
Eval: 421_h1=0.0703, 421_l2=0.0200
[38] time=179.75, avg_loss=0.0170, train_err=0.4077
Eval: 128_h1=0.0183, 128_l2=0.0133
[347] time=214.65, avg_loss=0.0035, train_err=0.0843
[54] time=130.25, avg_loss=0.0479, train_err=0.3833
Eval: 128_h1=0.0066, 128_l2=0.0033
Eval: 421_h1=0.0691, 421_l2=0.0186
[39] time=179.19, avg_loss=0.0169, train_err=0.4056
Eval: 128_h1=0.0180, 128_l2=0.0130
[55] time=130.29, avg_loss=0.0460, train_err=0.3678
Eval: 421_h1=0.0686, 421_l2=0.0170
[348] time=224.45, avg_loss=0.0035, train_err=0.0842
Eval: 128_h1=0.0066, 128_l2=0.0033
[56] time=130.25, avg_loss=0.0487, train_err=0.3894
Eval: 421_h1=0.0693, 421_l2=0.0194
[40] time=179.59, avg_loss=0.0172, train_err=0.4133
Eval: 128_h1=0.0178, 128_l2=0.0129
[57] time=130.26, avg_loss=0.0478, train_err=0.3826
Eval: 421_h1=0.0702, 421_l2=0.0176
[349] time=206.34, avg_loss=0.0035, train_err=0.0841
Eval: 128_h1=0.0067, 128_l2=0.0034
[41] time=179.11, avg_loss=0.0173, train_err=0.4150
Eval: 128_h1=0.0179, 128_l2=0.0124
[58] time=130.27, avg_loss=0.0475, train_err=0.3801
Eval: 421_h1=0.0771, 421_l2=0.0299
[350] time=201.72, avg_loss=0.0035, train_err=0.0842
Eval: 128_h1=0.0067, 128_l2=0.0035
[42] time=180.02, avg_loss=0.0168, train_err=0.4036
Eval: 128_h1=0.0175, 128_l2=0.0130
[59] time=130.28, avg_loss=0.0474, train_err=0.3789
Eval: 421_h1=0.0679, 421_l2=0.0168
[60] time=130.27, avg_loss=0.0388, train_err=0.3106
Eval: 421_h1=0.0658, 421_l2=0.0142
[351] time=205.75, avg_loss=0.0035, train_err=0.0847
[43] time=179.16, avg_loss=0.0174, train_err=0.4179
Eval: 128_h1=0.0069, 128_l2=0.0036
Eval: 128_h1=0.0176, 128_l2=0.0124
[61] time=130.27, avg_loss=0.0358, train_err=0.2862
Eval: 421_h1=0.0659, 421_l2=0.0140
[44] time=179.67, avg_loss=0.0158, train_err=0.3781
Eval: 128_h1=0.0172, 128_l2=0.0123
[352] time=218.00, avg_loss=0.0036, train_err=0.0863
Eval: 128_h1=0.0067, 128_l2=0.0034
[62] time=130.29, avg_loss=0.0351, train_err=0.2812
Eval: 421_h1=0.0662, 421_l2=0.0139
[45] time=177.20, avg_loss=0.0152, train_err=0.3646
Eval: 128_h1=0.0168, 128_l2=0.0119
[63] time=130.25, avg_loss=0.0350, train_err=0.2797
Eval: 421_h1=0.0667, 421_l2=0.0143
[353] time=217.22, avg_loss=0.0036, train_err=0.0866
Eval: 128_h1=0.0067, 128_l2=0.0034
[64] time=130.27, avg_loss=0.0350, train_err=0.2803
Eval: 421_h1=0.0664, 421_l2=0.0136
[46] time=176.90, avg_loss=0.0149, train_err=0.3566
Eval: 128_h1=0.0166, 128_l2=0.0118
[354] time=198.17, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0067, 128_l2=0.0033
[65] time=130.25, avg_loss=0.0346, train_err=0.2764
Eval: 421_h1=0.0667, 421_l2=0.0136
[47] time=179.99, avg_loss=0.0144, train_err=0.3464
Eval: 128_h1=0.0165, 128_l2=0.0115
[66] time=130.27, avg_loss=0.0349, train_err=0.2793
Eval: 421_h1=0.0665, 421_l2=0.0131
[355] time=205.41, avg_loss=0.0035, train_err=0.0851
Eval: 128_h1=0.0067, 128_l2=0.0033
[48] time=180.97, avg_loss=0.0142, train_err=0.3407
Eval: 128_h1=0.0164, 128_l2=0.0113
[67] time=130.30, avg_loss=0.0348, train_err=0.2782
Eval: 421_h1=0.0664, 421_l2=0.0130
[356] time=207.63, avg_loss=0.0035, train_err=0.0845
Eval: 128_h1=0.0067, 128_l2=0.0033
[68] time=130.27, avg_loss=0.0353, train_err=0.2821
Eval: 421_h1=0.0670, 421_l2=0.0148
[49] time=182.50, avg_loss=0.0150, train_err=0.3589
Eval: 128_h1=0.0175, 128_l2=0.0115
[69] time=130.25, avg_loss=0.0355, train_err=0.2839
Eval: 421_h1=0.0684, 421_l2=0.0169
[357] time=209.36, avg_loss=0.0035, train_err=0.0839
[50] time=181.09, avg_loss=0.0160, train_err=0.3830
Eval: 128_h1=0.0067, 128_l2=0.0034
Eval: 128_h1=0.0167, 128_l2=0.0113
[70] time=130.29, avg_loss=0.0362, train_err=0.2895
Eval: 421_h1=0.0667, 421_l2=0.0129
[51] time=181.70, avg_loss=0.0159, train_err=0.3804
Eval: 128_h1=0.0174, 128_l2=0.0118
[358] time=212.66, avg_loss=0.0035, train_err=0.0832
[71] time=130.24, avg_loss=0.0346, train_err=0.2767
Eval: 128_h1=0.0067, 128_l2=0.0034
Eval: 421_h1=0.0668, 421_l2=0.0128
[72] time=130.27, avg_loss=0.0348, train_err=0.2780
Eval: 421_h1=0.0677, 421_l2=0.0147
[52] time=182.38, avg_loss=0.0162, train_err=0.3882
Eval: 128_h1=0.0166, 128_l2=0.0103
[359] time=222.88, avg_loss=0.0034, train_err=0.0824
Eval: 128_h1=0.0066, 128_l2=0.0033
[73] time=130.26, avg_loss=0.0347, train_err=0.2775
Eval: 421_h1=0.0675, 421_l2=0.0135
[53] time=182.40, avg_loss=0.0151, train_err=0.3616
Eval: 128_h1=0.0164, 128_l2=0.0106
[74] time=130.25, avg_loss=0.0354, train_err=0.2835
Eval: 421_h1=0.0675, 421_l2=0.0132
[360] time=223.97, avg_loss=0.0034, train_err=0.0818
Eval: 128_h1=0.0065, 128_l2=0.0032
[54] time=180.94, avg_loss=0.0143, train_err=0.3440
Eval: 128_h1=0.0173, 128_l2=0.0120
[75] time=130.28, avg_loss=0.0352, train_err=0.2819
Eval: 421_h1=0.0675, 421_l2=0.0133
[361] time=217.22, avg_loss=0.0034, train_err=0.0815
Eval: 128_h1=0.0065, 128_l2=0.0032
[76] time=130.27, avg_loss=0.0350, train_err=0.2796
Eval: 421_h1=0.0685, 421_l2=0.0148
[55] time=181.21, avg_loss=0.0144, train_err=0.3463
Eval: 128_h1=0.0162, 128_l2=0.0101
[77] time=130.26, avg_loss=0.0358, train_err=0.2866
Eval: 421_h1=0.0689, 421_l2=0.0165
[362] time=217.72, avg_loss=0.0034, train_err=0.0813
[56] time=181.09, avg_loss=0.0140, train_err=0.3352
Eval: 128_h1=0.0160, 128_l2=0.0102
Eval: 128_h1=0.0065, 128_l2=0.0032
[78] time=130.29, avg_loss=0.0356, train_err=0.2844
Eval: 421_h1=0.0677, 421_l2=0.0131
[57] time=183.41, avg_loss=0.0132, train_err=0.3156
Eval: 128_h1=0.0159, 128_l2=0.0107
[79] time=130.27, avg_loss=0.0374, train_err=0.2991
Eval: 421_h1=0.0699, 421_l2=0.0165
[363] time=217.02, avg_loss=0.0034, train_err=0.0809
Eval: 128_h1=0.0065, 128_l2=0.0031
[80] time=130.31, avg_loss=0.0352, train_err=0.2818
Eval: 421_h1=0.0680, 421_l2=0.0156
[58] time=183.04, avg_loss=0.0133, train_err=0.3180
Eval: 128_h1=0.0155, 128_l2=0.0103
[364] time=218.73, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0065, 128_l2=0.0031
[81] time=130.28, avg_loss=0.0340, train_err=0.2720
Eval: 421_h1=0.0676, 421_l2=0.0129
[59] time=182.02, avg_loss=0.0135, train_err=0.3238
Eval: 128_h1=0.0181, 128_l2=0.0119
[82] time=130.27, avg_loss=0.0336, train_err=0.2691
Eval: 421_h1=0.0676, 421_l2=0.0144
[365] time=217.34, avg_loss=0.0033, train_err=0.0801
Eval: 128_h1=0.0064, 128_l2=0.0031
[60] time=183.61, avg_loss=0.0142, train_err=0.3408
Eval: 128_h1=0.0166, 128_l2=0.0112
[83] time=130.24, avg_loss=0.0343, train_err=0.2746
Eval: 421_h1=0.0679, 421_l2=0.0133
[366] time=217.35, avg_loss=0.0033, train_err=0.0798
[84] time=130.28, avg_loss=0.0343, train_err=0.2746
Eval: 128_h1=0.0065, 128_l2=0.0031
Eval: 421_h1=0.0677, 421_l2=0.0133
[61] time=182.13, avg_loss=0.0139, train_err=0.3324
Eval: 128_h1=0.0157, 128_l2=0.0097
[85] time=130.25, avg_loss=0.0359, train_err=0.2873
Eval: 421_h1=0.0684, 421_l2=0.0136
[367] time=217.81, avg_loss=0.0033, train_err=0.0796
[62] time=182.97, avg_loss=0.0138, train_err=0.3309
Eval: 128_h1=0.0064, 128_l2=0.0031
Eval: 128_h1=0.0156, 128_l2=0.0096
[86] time=130.25, avg_loss=0.0359, train_err=0.2872
Eval: 421_h1=0.0684, 421_l2=0.0150
[63] time=182.12, avg_loss=0.0140, train_err=0.3348
[87] time=130.25, avg_loss=0.0343, train_err=0.2743
Eval: 128_h1=0.0158, 128_l2=0.0094
Eval: 421_h1=0.0681, 421_l2=0.0142
[368] time=217.22, avg_loss=0.0033, train_err=0.0794
Eval: 128_h1=0.0064, 128_l2=0.0031
[88] time=130.25, avg_loss=0.0335, train_err=0.2678
Eval: 421_h1=0.0677, 421_l2=0.0130
[64] time=183.37, avg_loss=0.0143, train_err=0.3440
Eval: 128_h1=0.0182, 128_l2=0.0113
[369] time=220.39, avg_loss=0.0033, train_err=0.0791
Eval: 128_h1=0.0064, 128_l2=0.0031
[89] time=130.26, avg_loss=0.0335, train_err=0.2683
Eval: 421_h1=0.0683, 421_l2=0.0152
[65] time=181.04, avg_loss=0.0130, train_err=0.3119
Eval: 128_h1=0.0147, 128_l2=0.0090
[90] time=130.26, avg_loss=0.0332, train_err=0.2656
Eval: 421_h1=0.0679, 421_l2=0.0147
[370] time=220.70, avg_loss=0.0033, train_err=0.0789
Eval: 128_h1=0.0064, 128_l2=0.0031
[91] time=130.28, avg_loss=0.0349, train_err=0.2794
[66] time=182.53, avg_loss=0.0121, train_err=0.2892
Eval: 128_h1=0.0144, 128_l2=0.0087
Eval: 421_h1=0.0687, 421_l2=0.0145
[92] time=130.25, avg_loss=0.0340, train_err=0.2719
[371] time=220.85, avg_loss=0.0033, train_err=0.0787
Eval: 421_h1=0.0692, 421_l2=0.0148
Eval: 128_h1=0.0064, 128_l2=0.0031
[67] time=183.77, avg_loss=0.0123, train_err=0.2948
Eval: 128_h1=0.0146, 128_l2=0.0084
[93] time=130.26, avg_loss=0.0353, train_err=0.2826
Eval: 421_h1=0.0694, 421_l2=0.0157
[372] time=219.45, avg_loss=0.0033, train_err=0.0786
[68] time=181.17, avg_loss=0.0122, train_err=0.2926
Eval: 128_h1=0.0143, 128_l2=0.0086
Eval: 128_h1=0.0064, 128_l2=0.0031
[94] time=130.25, avg_loss=0.0338, train_err=0.2703
Eval: 421_h1=0.0686, 421_l2=0.0157
[95] time=130.27, avg_loss=0.0330, train_err=0.2643
[69] time=181.41, avg_loss=0.0122, train_err=0.2915
Eval: 421_h1=0.0674, 421_l2=0.0128
Eval: 128_h1=0.0149, 128_l2=0.0093
[373] time=219.66, avg_loss=0.0033, train_err=0.0784
Eval: 128_h1=0.0064, 128_l2=0.0031
[96] time=130.24, avg_loss=0.0325, train_err=0.2602
Eval: 421_h1=0.0678, 421_l2=0.0130
[70] time=182.03, avg_loss=0.0123, train_err=0.2949
Eval: 128_h1=0.0143, 128_l2=0.0086
[374] time=225.14, avg_loss=0.0033, train_err=0.0782
[97] time=130.25, avg_loss=0.0342, train_err=0.2734
Eval: 128_h1=0.0064, 128_l2=0.0031
Eval: 421_h1=0.0705, 421_l2=0.0182
[71] time=181.84, avg_loss=0.0122, train_err=0.2927
Eval: 128_h1=0.0144, 128_l2=0.0089
[98] time=130.24, avg_loss=0.0331, train_err=0.2645
Eval: 421_h1=0.0683, 421_l2=0.0131
[375] time=221.74, avg_loss=0.0033, train_err=0.0780
Eval: 128_h1=0.0064, 128_l2=0.0031
[99] time=130.26, avg_loss=0.0323, train_err=0.2585
[72] time=181.91, avg_loss=0.0124, train_err=0.2977
Eval: 421_h1=0.0679, 421_l2=0.0136
Eval: 128_h1=0.0154, 128_l2=0.0090
[100] time=130.24, avg_loss=0.0324, train_err=0.2589
Eval: 421_h1=0.0681, 421_l2=0.0127
[376] time=220.57, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0064, 128_l2=0.0031
[73] time=182.85, avg_loss=0.0131, train_err=0.3131
Eval: 128_h1=0.0188, 128_l2=0.0125
[101] time=130.26, avg_loss=0.0328, train_err=0.2625
Eval: 421_h1=0.0685, 421_l2=0.0144
[74] time=181.71, avg_loss=0.0137, train_err=0.3291
Eval: 128_h1=0.0158, 128_l2=0.0092
[377] time=220.28, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0064, 128_l2=0.0031
[102] time=130.25, avg_loss=0.0375, train_err=0.2997
Eval: 421_h1=0.0697, 421_l2=0.0144
[103] time=130.26, avg_loss=0.0337, train_err=0.2699
Eval: 421_h1=0.0700, 421_l2=0.0151
[75] time=180.77, avg_loss=0.0124, train_err=0.2967
Eval: 128_h1=0.0158, 128_l2=0.0092
[378] time=221.70, avg_loss=0.0032, train_err=0.0779
Eval: 128_h1=0.0064, 128_l2=0.0031
[104] time=130.27, avg_loss=0.0347, train_err=0.2778
Eval: 421_h1=0.0697, 421_l2=0.0148
[76] time=182.32, avg_loss=0.0126, train_err=0.3029
Eval: 128_h1=0.0157, 128_l2=0.0091
[105] time=130.25, avg_loss=0.0339, train_err=0.2714
Eval: 421_h1=0.0693, 421_l2=0.0149
[379] time=225.69, avg_loss=0.0033, train_err=0.0783
Eval: 128_h1=0.0064, 128_l2=0.0030
[77] time=183.40, avg_loss=0.0122, train_err=0.2915
Eval: 128_h1=0.0152, 128_l2=0.0086
[106] time=130.33, avg_loss=0.0331, train_err=0.2648
Eval: 421_h1=0.0685, 421_l2=0.0139
[380] time=219.01, avg_loss=0.0033, train_err=0.0788
Eval: 128_h1=0.0064, 128_l2=0.0030
[107] time=130.27, avg_loss=0.0312, train_err=0.2499
Eval: 421_h1=0.0680, 421_l2=0.0126
[78] time=180.27, avg_loss=0.0120, train_err=0.2872
Eval: 128_h1=0.0148, 128_l2=0.0083
[108] time=130.29, avg_loss=0.0309, train_err=0.2470
Eval: 421_h1=0.0684, 421_l2=0.0127
[381] time=219.87, avg_loss=0.0033, train_err=0.0786
[79] time=182.63, avg_loss=0.0125, train_err=0.2997
Eval: 128_h1=0.0064, 128_l2=0.0030
Eval: 128_h1=0.0146, 128_l2=0.0092
[109] time=130.27, avg_loss=0.0316, train_err=0.2531
Eval: 421_h1=0.0682, 421_l2=0.0123
[80] time=182.24, avg_loss=0.0114, train_err=0.2741
Eval: 128_h1=0.0145, 128_l2=0.0083
[110] time=130.25, avg_loss=0.0316, train_err=0.2528
[382] time=219.75, avg_loss=0.0033, train_err=0.0787
Eval: 421_h1=0.0679, 421_l2=0.0130
Eval: 128_h1=0.0064, 128_l2=0.0030
[111] time=130.25, avg_loss=0.0316, train_err=0.2526
[81] time=166.36, avg_loss=0.0122, train_err=0.2927
Eval: 421_h1=0.0702, 421_l2=0.0156
Eval: 128_h1=0.0150, 128_l2=0.0090
[383] time=216.79, avg_loss=0.0033, train_err=0.0791
Eval: 128_h1=0.0064, 128_l2=0.0031
[112] time=130.25, avg_loss=0.0341, train_err=0.2725
Eval: 421_h1=0.0687, 421_l2=0.0131
[82] time=166.37, avg_loss=0.0111, train_err=0.2658
Eval: 128_h1=0.0138, 128_l2=0.0079
[113] time=130.25, avg_loss=0.0311, train_err=0.2488
Eval: 421_h1=0.0686, 421_l2=0.0124
[384] time=218.89, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0064, 128_l2=0.0030
[83] time=166.41, avg_loss=0.0106, train_err=0.2541
Eval: 128_h1=0.0134, 128_l2=0.0077
[114] time=130.25, avg_loss=0.0323, train_err=0.2586
Eval: 421_h1=0.0690, 421_l2=0.0143
[84] time=166.42, avg_loss=0.0105, train_err=0.2521
Eval: 128_h1=0.0134, 128_l2=0.0076
[385] time=214.11, avg_loss=0.0033, train_err=0.0800
Eval: 128_h1=0.0064, 128_l2=0.0031
[115] time=130.27, avg_loss=0.0321, train_err=0.2567
Eval: 421_h1=0.0685, 421_l2=0.0132
[85] time=166.38, avg_loss=0.0107, train_err=0.2576
[116] time=130.25, avg_loss=0.0315, train_err=0.2518
Eval: 128_h1=0.0135, 128_l2=0.0078
Eval: 421_h1=0.0708, 421_l2=0.0180
[386] time=212.31, avg_loss=0.0034, train_err=0.0806
Eval: 128_h1=0.0065, 128_l2=0.0031
[117] time=130.24, avg_loss=0.0311, train_err=0.2490
Eval: 421_h1=0.0690, 421_l2=0.0136
[86] time=166.40, avg_loss=0.0105, train_err=0.2509
Eval: 128_h1=0.0132, 128_l2=0.0075
[387] time=202.44, avg_loss=0.0034, train_err=0.0809
[118] time=130.29, avg_loss=0.0338, train_err=0.2705
Eval: 128_h1=0.0065, 128_l2=0.0032
Eval: 421_h1=0.0685, 421_l2=0.0128
[87] time=166.44, avg_loss=0.0106, train_err=0.2545
Eval: 128_h1=0.0130, 128_l2=0.0072
[119] time=130.27, avg_loss=0.0312, train_err=0.2499
Eval: 421_h1=0.0688, 421_l2=0.0148
[388] time=203.32, avg_loss=0.0034, train_err=0.0807
Eval: 128_h1=0.0065, 128_l2=0.0032
[88] time=166.43, avg_loss=0.0111, train_err=0.2663
Eval: 128_h1=0.0143, 128_l2=0.0083
[120] time=130.26, avg_loss=0.0289, train_err=0.2310
Eval: 421_h1=0.0679, 421_l2=0.0120
[89] time=166.35, avg_loss=0.0120, train_err=0.2882
Eval: 128_h1=0.0142, 128_l2=0.0081
[121] time=130.25, avg_loss=0.0271, train_err=0.2171
[389] time=220.54, avg_loss=0.0034, train_err=0.0805
Eval: 421_h1=0.0677, 421_l2=0.0117
Eval: 128_h1=0.0065, 128_l2=0.0032
[122] time=130.26, avg_loss=0.0265, train_err=0.2124
Eval: 421_h1=0.0682, 421_l2=0.0117
[90] time=166.44, avg_loss=0.0121, train_err=0.2899
Eval: 128_h1=0.0151, 128_l2=0.0081
[390] time=200.71, avg_loss=0.0033, train_err=0.0803
Eval: 128_h1=0.0065, 128_l2=0.0032
[123] time=130.27, avg_loss=0.0264, train_err=0.2111
Eval: 421_h1=0.0684, 421_l2=0.0116
[91] time=181.93, avg_loss=0.0134, train_err=0.3208
Eval: 128_h1=0.0150, 128_l2=0.0080
[124] time=130.25, avg_loss=0.0263, train_err=0.2100
[391] time=198.35, avg_loss=0.0033, train_err=0.0801
Eval: 421_h1=0.0684, 421_l2=0.0115
Eval: 128_h1=0.0065, 128_l2=0.0032
[92] time=168.24, avg_loss=0.0122, train_err=0.2931
Eval: 128_h1=0.0148, 128_l2=0.0079
[125] time=130.25, avg_loss=0.0261, train_err=0.2089
Eval: 421_h1=0.0685, 421_l2=0.0117
[392] time=204.20, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0065, 128_l2=0.0032
[93] time=166.38, avg_loss=0.0117, train_err=0.2813
Eval: 128_h1=0.0142, 128_l2=0.0084
[126] time=130.29, avg_loss=0.0262, train_err=0.2092
Eval: 421_h1=0.0685, 421_l2=0.0115
[127] time=130.27, avg_loss=0.0264, train_err=0.2109
[393] time=211.27, avg_loss=0.0033, train_err=0.0798
Eval: 421_h1=0.0686, 421_l2=0.0116
[94] time=166.40, avg_loss=0.0109, train_err=0.2614
Eval: 128_h1=0.0065, 128_l2=0.0032
Eval: 128_h1=0.0160, 128_l2=0.0105
[128] time=130.24, avg_loss=0.0266, train_err=0.2131
Eval: 421_h1=0.0688, 421_l2=0.0117
[95] time=166.41, avg_loss=0.0105, train_err=0.2522
Eval: 128_h1=0.0149, 128_l2=0.0094
[394] time=217.95, avg_loss=0.0033, train_err=0.0796
Eval: 128_h1=0.0065, 128_l2=0.0032
[129] time=130.26, avg_loss=0.0264, train_err=0.2113
Eval: 421_h1=0.0689, 421_l2=0.0119
[96] time=176.01, avg_loss=0.0110, train_err=0.2642
Eval: 128_h1=0.0137, 128_l2=0.0077
[130] time=130.26, avg_loss=0.0265, train_err=0.2117
Eval: 421_h1=0.0688, 421_l2=0.0115
[395] time=201.46, avg_loss=0.0033, train_err=0.0796
Eval: 128_h1=0.0065, 128_l2=0.0032
[97] time=176.00, avg_loss=0.0110, train_err=0.2638
[131] time=130.28, avg_loss=0.0266, train_err=0.2125
Eval: 128_h1=0.0142, 128_l2=0.0090
Eval: 421_h1=0.0692, 421_l2=0.0119
[396] time=203.87, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0065, 128_l2=0.0033
[132] time=130.32, avg_loss=0.0265, train_err=0.2118
Eval: 421_h1=0.0689, 421_l2=0.0116
[98] time=174.68, avg_loss=0.0099, train_err=0.2376
Eval: 128_h1=0.0156, 128_l2=0.0104
[133] time=130.39, avg_loss=0.0265, train_err=0.2116
Eval: 421_h1=0.0693, 421_l2=0.0117
[397] time=204.34, avg_loss=0.0033, train_err=0.0797
Eval: 128_h1=0.0066, 128_l2=0.0034
[99] time=178.81, avg_loss=0.0105, train_err=0.2514
Eval: 128_h1=0.0150, 128_l2=0.0094
[134] time=130.51, avg_loss=0.0268, train_err=0.2141
Eval: 421_h1=0.0695, 421_l2=0.0123
[398] time=219.50, avg_loss=0.0034, train_err=0.0810
[100] time=177.83, avg_loss=0.0103, train_err=0.2464
Eval: 128_h1=0.0067, 128_l2=0.0035
Eval: 128_h1=0.0119, 128_l2=0.0063
[135] time=130.30, avg_loss=0.0266, train_err=0.2131
Eval: 421_h1=0.0690, 421_l2=0.0117
[136] time=130.28, avg_loss=0.0266, train_err=0.2126
Eval: 421_h1=0.0692, 421_l2=0.0115
[101] time=176.01, avg_loss=0.0098, train_err=0.2353
Eval: 128_h1=0.0118, 128_l2=0.0063
[399] time=212.03, avg_loss=0.0034, train_err=0.0826
Eval: 128_h1=0.0066, 128_l2=0.0033
[137] time=130.29, avg_loss=0.0267, train_err=0.2138
Eval: 421_h1=0.0692, 421_l2=0.0122
[102] time=175.81, avg_loss=0.0095, train_err=0.2287
Eval: 128_h1=0.0117, 128_l2=0.0063
[400] time=197.74, avg_loss=0.0036, train_err=0.0853
Eval: 128_h1=0.0065, 128_l2=0.0031
[138] time=130.29, avg_loss=0.0265, train_err=0.2122
Eval: 421_h1=0.0694, 421_l2=0.0118
[103] time=177.41, avg_loss=0.0093, train_err=0.2239
Eval: 128_h1=0.0116, 128_l2=0.0062
[139] time=130.33, avg_loss=0.0269, train_err=0.2149
Eval: 421_h1=0.0699, 421_l2=0.0129
[401] time=205.22, avg_loss=0.0035, train_err=0.0850
Eval: 128_h1=0.0065, 128_l2=0.0031
[140] time=130.28, avg_loss=0.0269, train_err=0.2152
Eval: 421_h1=0.0693, 421_l2=0.0119
[104] time=177.26, avg_loss=0.0092, train_err=0.2196
Eval: 128_h1=0.0115, 128_l2=0.0062
[402] time=208.33, avg_loss=0.0035, train_err=0.0843
Eval: 128_h1=0.0065, 128_l2=0.0031
[141] time=130.28, avg_loss=0.0268, train_err=0.2147
Eval: 421_h1=0.0694, 421_l2=0.0122
[105] time=180.92, avg_loss=0.0090, train_err=0.2152
Eval: 128_h1=0.0116, 128_l2=0.0063
[142] time=130.32, avg_loss=0.0263, train_err=0.2103
Eval: 421_h1=0.0690, 421_l2=0.0119
[403] time=208.70, avg_loss=0.0035, train_err=0.0838
Eval: 128_h1=0.0065, 128_l2=0.0031
[106] time=179.64, avg_loss=0.0089, train_err=0.2134
Eval: 128_h1=0.0116, 128_l2=0.0063
[143] time=130.28, avg_loss=0.0266, train_err=0.2130
Eval: 421_h1=0.0696, 421_l2=0.0119
[404] time=208.47, avg_loss=0.0035, train_err=0.0832
[144] time=130.29, avg_loss=0.0263, train_err=0.2103
Eval: 128_h1=0.0064, 128_l2=0.0031
[107] time=180.40, avg_loss=0.0088, train_err=0.2116
Eval: 421_h1=0.0694, 421_l2=0.0117
Eval: 128_h1=0.0115, 128_l2=0.0062
[145] time=130.31, avg_loss=0.0263, train_err=0.2107
Eval: 421_h1=0.0696, 421_l2=0.0116
[108] time=178.64, avg_loss=0.0088, train_err=0.2099
Eval: 128_h1=0.0114, 128_l2=0.0061
[405] time=221.60, avg_loss=0.0035, train_err=0.0827
Eval: 128_h1=0.0064, 128_l2=0.0031
[146] time=130.28, avg_loss=0.0269, train_err=0.2148
Eval: 421_h1=0.0691, 421_l2=0.0116
[109] time=179.32, avg_loss=0.0087, train_err=0.2083
Eval: 128_h1=0.0113, 128_l2=0.0060
[147] time=130.28, avg_loss=0.0263, train_err=0.2101
Eval: 421_h1=0.0700, 421_l2=0.0116
[406] time=213.93, avg_loss=0.0034, train_err=0.0823
Eval: 128_h1=0.0064, 128_l2=0.0031
[148] time=130.28, avg_loss=0.0264, train_err=0.2110
[110] time=179.62, avg_loss=0.0086, train_err=0.2064
Eval: 421_h1=0.0696, 421_l2=0.0117
Eval: 128_h1=0.0112, 128_l2=0.0060
[407] time=199.62, avg_loss=0.0034, train_err=0.0819
Eval: 128_h1=0.0064, 128_l2=0.0031
[149] time=130.31, avg_loss=0.0260, train_err=0.2080
Eval: 421_h1=0.0698, 421_l2=0.0117
[111] time=178.91, avg_loss=0.0085, train_err=0.2043
Eval: 128_h1=0.0111, 128_l2=0.0059
[150] time=130.27, avg_loss=0.0259, train_err=0.2071
Eval: 421_h1=0.0698, 421_l2=0.0118
[408] time=206.15, avg_loss=0.0034, train_err=0.0816
Eval: 128_h1=0.0064, 128_l2=0.0031
[112] time=173.88, avg_loss=0.0084, train_err=0.2021
Eval: 128_h1=0.0111, 128_l2=0.0059
[151] time=130.32, avg_loss=0.0259, train_err=0.2074
Eval: 421_h1=0.0699, 421_l2=0.0113
[409] time=212.84, avg_loss=0.0034, train_err=0.0812
Eval: 128_h1=0.0064, 128_l2=0.0031
[113] time=166.38, avg_loss=0.0083, train_err=0.2000
Eval: 128_h1=0.0110, 128_l2=0.0058
[152] time=130.27, avg_loss=0.0258, train_err=0.2061
Eval: 421_h1=0.0696, 421_l2=0.0121
[153] time=130.37, avg_loss=0.0258, train_err=0.2067
Eval: 421_h1=0.0700, 421_l2=0.0122
[114] time=166.36, avg_loss=0.0083, train_err=0.1986
Eval: 128_h1=0.0110, 128_l2=0.0058
[410] time=220.10, avg_loss=0.0034, train_err=0.0809
Eval: 128_h1=0.0064, 128_l2=0.0030
[154] time=130.28, avg_loss=0.0260, train_err=0.2076
Eval: 421_h1=0.0698, 421_l2=0.0118
[115] time=166.38, avg_loss=0.0083, train_err=0.1983
Eval: 128_h1=0.0110, 128_l2=0.0058
[411] time=198.70, avg_loss=0.0034, train_err=0.0807
Eval: 128_h1=0.0064, 128_l2=0.0030
[155] time=130.29, avg_loss=0.0258, train_err=0.2065
Eval: 421_h1=0.0697, 421_l2=0.0113
[116] time=166.42, avg_loss=0.0088, train_err=0.2100
Eval: 128_h1=0.0108, 128_l2=0.0055
[156] time=130.27, avg_loss=0.0257, train_err=0.2059
Eval: 421_h1=0.0697, 421_l2=0.0116
[412] time=198.16, avg_loss=0.0034, train_err=0.0804
Eval: 128_h1=0.0064, 128_l2=0.0030
[117] time=166.46, avg_loss=0.0086, train_err=0.2070
Eval: 128_h1=0.0108, 128_l2=0.0055
[157] time=130.29, avg_loss=0.0259, train_err=0.2076
Eval: 421_h1=0.0699, 421_l2=0.0118
[413] time=199.41, avg_loss=0.0033, train_err=0.0802
Eval: 128_h1=0.0063, 128_l2=0.0030
[158] time=130.30, avg_loss=0.0254, train_err=0.2030
[118] time=166.45, avg_loss=0.0084, train_err=0.2007
Eval: 421_h1=0.0702, 421_l2=0.0120
Eval: 128_h1=0.0107, 128_l2=0.0055
[159] time=130.30, avg_loss=0.0254, train_err=0.2035
Eval: 421_h1=0.0696, 421_l2=0.0119
[119] time=166.45, avg_loss=0.0081, train_err=0.1943
Eval: 128_h1=0.0107, 128_l2=0.0055
[414] time=214.06, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0063, 128_l2=0.0030
[160] time=130.32, avg_loss=0.0255, train_err=0.2044
Eval: 421_h1=0.0698, 421_l2=0.0117
[120] time=166.45, avg_loss=0.0078, train_err=0.1870
Eval: 128_h1=0.0106, 128_l2=0.0056
[415] time=216.14, avg_loss=0.0033, train_err=0.0797
[161] time=130.29, avg_loss=0.0253, train_err=0.2026
Eval: 128_h1=0.0063, 128_l2=0.0030
Eval: 421_h1=0.0704, 421_l2=0.0130
[121] time=166.41, avg_loss=0.0077, train_err=0.1836
Eval: 128_h1=0.0105, 128_l2=0.0057
[162] time=130.29, avg_loss=0.0262, train_err=0.2094
Eval: 421_h1=0.0702, 421_l2=0.0119
[416] time=199.07, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0063, 128_l2=0.0030
[122] time=166.45, avg_loss=0.0076, train_err=0.1823
[163] time=130.30, avg_loss=0.0255, train_err=0.2042
Eval: 128_h1=0.0104, 128_l2=0.0056
Eval: 421_h1=0.0700, 421_l2=0.0117
[417] time=201.34, avg_loss=0.0033, train_err=0.0793
[164] time=130.34, avg_loss=0.0254, train_err=0.2036
Eval: 128_h1=0.0063, 128_l2=0.0030
Eval: 421_h1=0.0706, 421_l2=0.0119
[123] time=166.41, avg_loss=0.0075, train_err=0.1810
Eval: 128_h1=0.0104, 128_l2=0.0056
[165] time=130.30, avg_loss=0.0260, train_err=0.2080
Eval: 421_h1=0.0699, 421_l2=0.0114
[124] time=166.43, avg_loss=0.0075, train_err=0.1802
Eval: 128_h1=0.0104, 128_l2=0.0056
[418] time=204.71, avg_loss=0.0033, train_err=0.0791
Eval: 128_h1=0.0063, 128_l2=0.0030
[166] time=130.32, avg_loss=0.0252, train_err=0.2014
Eval: 421_h1=0.0701, 421_l2=0.0116
[125] time=166.44, avg_loss=0.0075, train_err=0.1797
Eval: 128_h1=0.0103, 128_l2=0.0056
[167] time=130.31, avg_loss=0.0252, train_err=0.2017
Eval: 421_h1=0.0703, 421_l2=0.0129
[419] time=220.76, avg_loss=0.0033, train_err=0.0789
Eval: 128_h1=0.0063, 128_l2=0.0030
[126] time=169.28, avg_loss=0.0075, train_err=0.1789
Eval: 128_h1=0.0103, 128_l2=0.0055
[168] time=130.30, avg_loss=0.0261, train_err=0.2085
Eval: 421_h1=0.0704, 421_l2=0.0119
[420] time=204.41, avg_loss=0.0033, train_err=0.0788
Eval: 128_h1=0.0063, 128_l2=0.0030
[169] time=130.31, avg_loss=0.0257, train_err=0.2055
Eval: 421_h1=0.0706, 421_l2=0.0116
[127] time=177.67, avg_loss=0.0075, train_err=0.1792
Eval: 128_h1=0.0103, 128_l2=0.0055
[170] time=130.31, avg_loss=0.0252, train_err=0.2014
Eval: 421_h1=0.0701, 421_l2=0.0116
[421] time=203.05, avg_loss=0.0033, train_err=0.0786
Eval: 128_h1=0.0063, 128_l2=0.0030
[128] time=179.43, avg_loss=0.0081, train_err=0.1933
Eval: 128_h1=0.0102, 128_l2=0.0055
[171] time=130.32, avg_loss=0.0250, train_err=0.2000
Eval: 421_h1=0.0702, 421_l2=0.0115
[422] time=206.50, avg_loss=0.0033, train_err=0.0784
Eval: 128_h1=0.0063, 128_l2=0.0030
[129] time=178.11, avg_loss=0.0079, train_err=0.1901
Eval: 128_h1=0.0103, 128_l2=0.0055
[172] time=130.33, avg_loss=0.0249, train_err=0.1995
Eval: 421_h1=0.0701, 421_l2=0.0114
[173] time=130.31, avg_loss=0.0250, train_err=0.1996
Eval: 421_h1=0.0706, 421_l2=0.0131
[130] time=175.61, avg_loss=0.0077, train_err=0.1852
Eval: 128_h1=0.0104, 128_l2=0.0053
[423] time=221.89, avg_loss=0.0033, train_err=0.0783
Eval: 128_h1=0.0063, 128_l2=0.0030
[174] time=130.31, avg_loss=0.0254, train_err=0.2036
Eval: 421_h1=0.0703, 421_l2=0.0116
[131] time=175.96, avg_loss=0.0075, train_err=0.1799
Eval: 128_h1=0.0103, 128_l2=0.0053
[424] time=216.11, avg_loss=0.0033, train_err=0.0781
Eval: 128_h1=0.0063, 128_l2=0.0030
[175] time=130.31, avg_loss=0.0247, train_err=0.1978
Eval: 421_h1=0.0703, 421_l2=0.0114
[132] time=167.53, avg_loss=0.0074, train_err=0.1769
Eval: 128_h1=0.0103, 128_l2=0.0053
[176] time=130.31, avg_loss=0.0248, train_err=0.1986
Eval: 421_h1=0.0707, 421_l2=0.0119
[425] time=196.88, avg_loss=0.0033, train_err=0.0780
Eval: 128_h1=0.0063, 128_l2=0.0030
[133] time=166.43, avg_loss=0.0075, train_err=0.1796
Eval: 128_h1=0.0102, 128_l2=0.0052
[177] time=130.30, avg_loss=0.0249, train_err=0.1991
Eval: 421_h1=0.0702, 421_l2=0.0119
[426] time=204.02, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0063, 128_l2=0.0030
[178] time=130.31, avg_loss=0.0250, train_err=0.1996
Eval: 421_h1=0.0708, 421_l2=0.0129
[134] time=166.41, avg_loss=0.0080, train_err=0.1907
Eval: 128_h1=0.0105, 128_l2=0.0053
[179] time=130.31, avg_loss=0.0257, train_err=0.2053
Eval: 421_h1=0.0704, 421_l2=0.0118
[135] time=166.43, avg_loss=0.0081, train_err=0.1952
[427] time=207.85, avg_loss=0.0032, train_err=0.0777
Eval: 128_h1=0.0113, 128_l2=0.0062
Eval: 128_h1=0.0063, 128_l2=0.0030
[180] time=130.32, avg_loss=0.0239, train_err=0.1911
Eval: 421_h1=0.0703, 421_l2=0.0113
[136] time=166.44, avg_loss=0.0082, train_err=0.1955
Eval: 128_h1=0.0114, 128_l2=0.0063
[428] time=208.66, avg_loss=0.0032, train_err=0.0775
[181] time=130.32, avg_loss=0.0229, train_err=0.1829
Eval: 128_h1=0.0063, 128_l2=0.0030
Eval: 421_h1=0.0705, 421_l2=0.0112
[137] time=166.43, avg_loss=0.0081, train_err=0.1944
Eval: 128_h1=0.0113, 128_l2=0.0064
[182] time=130.30, avg_loss=0.0226, train_err=0.1812
Eval: 421_h1=0.0706, 421_l2=0.0114
[429] time=209.33, avg_loss=0.0032, train_err=0.0774
Eval: 128_h1=0.0063, 128_l2=0.0030
[183] time=130.29, avg_loss=0.0225, train_err=0.1799
[138] time=166.50, avg_loss=0.0079, train_err=0.1891
Eval: 421_h1=0.0707, 421_l2=0.0112
Eval: 128_h1=0.0109, 128_l2=0.0060
[184] time=130.35, avg_loss=0.0224, train_err=0.1791
[430] time=211.13, avg_loss=0.0032, train_err=0.0773
Eval: 421_h1=0.0709, 421_l2=0.0112
Eval: 128_h1=0.0063, 128_l2=0.0030
[139] time=166.42, avg_loss=0.0076, train_err=0.1812
Eval: 128_h1=0.0103, 128_l2=0.0054
[185] time=130.30, avg_loss=0.0224, train_err=0.1789
Eval: 421_h1=0.0709, 421_l2=0.0113
[140] time=166.46, avg_loss=0.0072, train_err=0.1719
Eval: 128_h1=0.0099, 128_l2=0.0049
[431] time=214.04, avg_loss=0.0032, train_err=0.0771
Eval: 128_h1=0.0063, 128_l2=0.0030
[186] time=130.31, avg_loss=0.0223, train_err=0.1786
Eval: 421_h1=0.0710, 421_l2=0.0112
[141] time=166.47, avg_loss=0.0069, train_err=0.1647
Eval: 128_h1=0.0099, 128_l2=0.0052
[187] time=130.30, avg_loss=0.0223, train_err=0.1784
Eval: 421_h1=0.0711, 421_l2=0.0113
[432] time=214.88, avg_loss=0.0032, train_err=0.0770
Eval: 128_h1=0.0063, 128_l2=0.0030
[142] time=166.44, avg_loss=0.0067, train_err=0.1618
[188] time=130.29, avg_loss=0.0223, train_err=0.1784
Eval: 128_h1=0.0097, 128_l2=0.0050
Eval: 421_h1=0.0712, 421_l2=0.0113
[433] time=212.05, avg_loss=0.0032, train_err=0.0769
Eval: 128_h1=0.0062, 128_l2=0.0030
[189] time=130.30, avg_loss=0.0224, train_err=0.1793
Eval: 421_h1=0.0714, 421_l2=0.0112
[143] time=166.44, avg_loss=0.0067, train_err=0.1610
Eval: 128_h1=0.0096, 128_l2=0.0050
[190] time=130.29, avg_loss=0.0225, train_err=0.1799
Eval: 421_h1=0.0712, 421_l2=0.0114
[434] time=213.31, avg_loss=0.0032, train_err=0.0768
[144] time=166.46, avg_loss=0.0066, train_err=0.1586
Eval: 128_h1=0.0062, 128_l2=0.0030
Eval: 128_h1=0.0096, 128_l2=0.0051
[191] time=130.30, avg_loss=0.0225, train_err=0.1796
Eval: 421_h1=0.0714, 421_l2=0.0113
[145] time=166.44, avg_loss=0.0066, train_err=0.1584
Eval: 128_h1=0.0095, 128_l2=0.0049
[435] time=213.42, avg_loss=0.0032, train_err=0.0766
[192] time=130.30, avg_loss=0.0225, train_err=0.1800
Eval: 128_h1=0.0062, 128_l2=0.0030
Eval: 421_h1=0.0713, 421_l2=0.0112
[146] time=166.46, avg_loss=0.0064, train_err=0.1533
Eval: 128_h1=0.0093, 128_l2=0.0049
[193] time=130.29, avg_loss=0.0226, train_err=0.1809
Eval: 421_h1=0.0715, 421_l2=0.0116
[436] time=215.14, avg_loss=0.0032, train_err=0.0765
Eval: 128_h1=0.0062, 128_l2=0.0030
[194] time=130.28, avg_loss=0.0227, train_err=0.1813
[147] time=166.45, avg_loss=0.0063, train_err=0.1503
Eval: 421_h1=0.0716, 421_l2=0.0113
Eval: 128_h1=0.0092, 128_l2=0.0047
[195] time=130.30, avg_loss=0.0228, train_err=0.1821
Eval: 421_h1=0.0715, 421_l2=0.0115
[437] time=218.62, avg_loss=0.0032, train_err=0.0764
Eval: 128_h1=0.0062, 128_l2=0.0030
[148] time=166.46, avg_loss=0.0064, train_err=0.1544
Eval: 128_h1=0.0092, 128_l2=0.0048
[196] time=130.31, avg_loss=0.0227, train_err=0.1817
Eval: 421_h1=0.0716, 421_l2=0.0113
[149] time=166.38, avg_loss=0.0067, train_err=0.1599
Eval: 128_h1=0.0095, 128_l2=0.0052
[438] time=214.87, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0062, 128_l2=0.0030
[197] time=130.29, avg_loss=0.0226, train_err=0.1806
Eval: 421_h1=0.0715, 421_l2=0.0113
[150] time=166.45, avg_loss=0.0069, train_err=0.1651
Eval: 128_h1=0.0094, 128_l2=0.0046
[198] time=130.30, avg_loss=0.0226, train_err=0.1804
Eval: 421_h1=0.0715, 421_l2=0.0114
[439] time=212.72, avg_loss=0.0032, train_err=0.0762
Eval: 128_h1=0.0062, 128_l2=0.0030
[151] time=166.47, avg_loss=0.0068, train_err=0.1620
[199] time=130.29, avg_loss=0.0226, train_err=0.1807
Eval: 128_h1=0.0099, 128_l2=0.0049
Eval: 421_h1=0.0718, 421_l2=0.0116
[440] time=213.92, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0062, 128_l2=0.0029
[200] time=130.30, avg_loss=0.0225, train_err=0.1798
Eval: 421_h1=0.0716, 421_l2=0.0113
[152] time=166.49, avg_loss=0.0069, train_err=0.1663
Eval: 128_h1=0.0104, 128_l2=0.0058
[201] time=130.30, avg_loss=0.0224, train_err=0.1789
Eval: 421_h1=0.0716, 421_l2=0.0113
[441] time=214.05, avg_loss=0.0032, train_err=0.0760
[153] time=166.45, avg_loss=0.0071, train_err=0.1700
Eval: 128_h1=0.0106, 128_l2=0.0062
Eval: 128_h1=0.0062, 128_l2=0.0029
[202] time=130.30, avg_loss=0.0224, train_err=0.1794
Eval: 421_h1=0.0717, 421_l2=0.0114
[154] time=166.42, avg_loss=0.0069, train_err=0.1660
Eval: 128_h1=0.0104, 128_l2=0.0060
[203] time=130.29, avg_loss=0.0225, train_err=0.1797
[442] time=214.32, avg_loss=0.0032, train_err=0.0759
Eval: 421_h1=0.0718, 421_l2=0.0113
Eval: 128_h1=0.0062, 128_l2=0.0029
[155] time=166.50, avg_loss=0.0070, train_err=0.1687
Eval: 128_h1=0.0106, 128_l2=0.0062
[204] time=130.29, avg_loss=0.0224, train_err=0.1791
Eval: 421_h1=0.0717, 421_l2=0.0113
[443] time=214.64, avg_loss=0.0032, train_err=0.0758
Eval: 128_h1=0.0062, 128_l2=0.0029
[205] time=130.30, avg_loss=0.0223, train_err=0.1783
Eval: 421_h1=0.0718, 421_l2=0.0112
[156] time=166.43, avg_loss=0.0076, train_err=0.1814
Eval: 128_h1=0.0107, 128_l2=0.0058
[206] time=130.30, avg_loss=0.0223, train_err=0.1781
Eval: 421_h1=0.0718, 421_l2=0.0115
[444] time=214.80, avg_loss=0.0032, train_err=0.0757
Eval: 128_h1=0.0062, 128_l2=0.0029
[157] time=166.42, avg_loss=0.0083, train_err=0.1985
Eval: 128_h1=0.0108, 128_l2=0.0062
[207] time=130.30, avg_loss=0.0222, train_err=0.1779
Eval: 421_h1=0.0720, 421_l2=0.0113
[158] time=166.49, avg_loss=0.0080, train_err=0.1925
Eval: 128_h1=0.0106, 128_l2=0.0062
[445] time=215.12, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0062, 128_l2=0.0029
[208] time=130.31, avg_loss=0.0223, train_err=0.1786
Eval: 421_h1=0.0720, 421_l2=0.0117
[159] time=166.43, avg_loss=0.0076, train_err=0.1824
Eval: 128_h1=0.0106, 128_l2=0.0064
[209] time=130.30, avg_loss=0.0229, train_err=0.1834
Eval: 421_h1=0.0718, 421_l2=0.0119
[446] time=215.21, avg_loss=0.0031, train_err=0.0755
Eval: 128_h1=0.0062, 128_l2=0.0029
[210] time=130.29, avg_loss=0.0222, train_err=0.1777
[160] time=166.43, avg_loss=0.0073, train_err=0.1745
Eval: 421_h1=0.0722, 421_l2=0.0117
Eval: 128_h1=0.0102, 128_l2=0.0060
[447] time=215.78, avg_loss=0.0031, train_err=0.0754
[211] time=130.29, avg_loss=0.0223, train_err=0.1781
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0720, 421_l2=0.0114
[161] time=166.42, avg_loss=0.0068, train_err=0.1640
Eval: 128_h1=0.0099, 128_l2=0.0059
[212] time=130.29, avg_loss=0.0221, train_err=0.1770
Eval: 421_h1=0.0722, 421_l2=0.0113
[162] time=166.43, avg_loss=0.0065, train_err=0.1563
[448] time=215.94, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0093, 128_l2=0.0050
Eval: 128_h1=0.0062, 128_l2=0.0029
[213] time=130.29, avg_loss=0.0223, train_err=0.1780
Eval: 421_h1=0.0722, 421_l2=0.0119
[163] time=166.44, avg_loss=0.0063, train_err=0.1511
Eval: 128_h1=0.0093, 128_l2=0.0052
[214] time=130.28, avg_loss=0.0222, train_err=0.1772
Eval: 421_h1=0.0720, 421_l2=0.0114
[449] time=215.27, avg_loss=0.0031, train_err=0.0752
Eval: 128_h1=0.0062, 128_l2=0.0029
[164] time=166.45, avg_loss=0.0061, train_err=0.1469
[215] time=130.28, avg_loss=0.0220, train_err=0.1757
Eval: 128_h1=0.0091, 128_l2=0.0048
Eval: 421_h1=0.0721, 421_l2=0.0114
[450] time=215.53, avg_loss=0.0031, train_err=0.0751
Eval: 128_h1=0.0062, 128_l2=0.0029
[216] time=130.29, avg_loss=0.0221, train_err=0.1768
Eval: 421_h1=0.0724, 421_l2=0.0114
[165] time=166.44, avg_loss=0.0061, train_err=0.1451
Eval: 128_h1=0.0090, 128_l2=0.0047
[217] time=130.29, avg_loss=0.0220, train_err=0.1757
Eval: 421_h1=0.0721, 421_l2=0.0114
[451] time=215.53, avg_loss=0.0031, train_err=0.0750
[166] time=166.44, avg_loss=0.0060, train_err=0.1433
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 128_h1=0.0089, 128_l2=0.0046
[218] time=130.29, avg_loss=0.0219, train_err=0.1753
Eval: 421_h1=0.0724, 421_l2=0.0113
[167] time=166.44, avg_loss=0.0059, train_err=0.1417
Eval: 128_h1=0.0089, 128_l2=0.0045
[452] time=215.77, avg_loss=0.0031, train_err=0.0749
[219] time=130.28, avg_loss=0.0219, train_err=0.1751
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0723, 421_l2=0.0113
[168] time=166.44, avg_loss=0.0059, train_err=0.1416
Eval: 128_h1=0.0088, 128_l2=0.0045
[220] time=130.31, avg_loss=0.0219, train_err=0.1751
Eval: 421_h1=0.0720, 421_l2=0.0115
[453] time=215.69, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0062, 128_l2=0.0029
[221] time=130.53, avg_loss=0.0218, train_err=0.1745
Eval: 421_h1=0.0724, 421_l2=0.0113
[169] time=167.02, avg_loss=0.0060, train_err=0.1439
Eval: 128_h1=0.0089, 128_l2=0.0045
[222] time=130.76, avg_loss=0.0218, train_err=0.1746
Eval: 421_h1=0.0723, 421_l2=0.0113
[454] time=213.41, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0062, 128_l2=0.0029
[170] time=167.51, avg_loss=0.0063, train_err=0.1508
Eval: 128_h1=0.0092, 128_l2=0.0046
[223] time=130.88, avg_loss=0.0218, train_err=0.1746
Eval: 421_h1=0.0726, 421_l2=0.0115
[171] time=167.43, avg_loss=0.0064, train_err=0.1543
Eval: 128_h1=0.0089, 128_l2=0.0045
[455] time=213.46, avg_loss=0.0031, train_err=0.0746
Eval: 128_h1=0.0062, 128_l2=0.0029
[224] time=130.75, avg_loss=0.0220, train_err=0.1759
Eval: 421_h1=0.0725, 421_l2=0.0117
[172] time=167.47, avg_loss=0.0061, train_err=0.1465
Eval: 128_h1=0.0088, 128_l2=0.0045
[225] time=130.88, avg_loss=0.0220, train_err=0.1757
Eval: 421_h1=0.0724, 421_l2=0.0116
[456] time=233.22, avg_loss=0.0031, train_err=0.0745
Eval: 128_h1=0.0062, 128_l2=0.0029
[226] time=130.81, avg_loss=0.0218, train_err=0.1744
[173] time=167.79, avg_loss=0.0060, train_err=0.1435
Eval: 421_h1=0.0725, 421_l2=0.0115
Eval: 128_h1=0.0089, 128_l2=0.0046
[457] time=215.46, avg_loss=0.0031, train_err=0.0744
[227] time=130.80, avg_loss=0.0218, train_err=0.1746
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0727, 421_l2=0.0113
[174] time=167.69, avg_loss=0.0067, train_err=0.1608
Eval: 128_h1=0.0091, 128_l2=0.0048
[228] time=130.74, avg_loss=0.0218, train_err=0.1743
Eval: 421_h1=0.0725, 421_l2=0.0114
[175] time=167.61, avg_loss=0.0063, train_err=0.1502
[458] time=208.17, avg_loss=0.0031, train_err=0.0743
Eval: 128_h1=0.0089, 128_l2=0.0046
Eval: 128_h1=0.0062, 128_l2=0.0029
[229] time=130.81, avg_loss=0.0217, train_err=0.1736
Eval: 421_h1=0.0724, 421_l2=0.0114
[176] time=167.43, avg_loss=0.0061, train_err=0.1472
Eval: 128_h1=0.0088, 128_l2=0.0044
[230] time=130.80, avg_loss=0.0217, train_err=0.1737
[459] time=212.52, avg_loss=0.0031, train_err=0.0743
Eval: 421_h1=0.0727, 421_l2=0.0118
Eval: 128_h1=0.0062, 128_l2=0.0029
[177] time=167.55, avg_loss=0.0060, train_err=0.1432
[231] time=130.77, avg_loss=0.0217, train_err=0.1736
Eval: 128_h1=0.0087, 128_l2=0.0043
Eval: 421_h1=0.0725, 421_l2=0.0114
[460] time=228.49, avg_loss=0.0031, train_err=0.0742
Eval: 128_h1=0.0062, 128_l2=0.0029
[232] time=130.81, avg_loss=0.0218, train_err=0.1746
Eval: 421_h1=0.0728, 421_l2=0.0115
[178] time=167.64, avg_loss=0.0058, train_err=0.1392
Eval: 128_h1=0.0086, 128_l2=0.0043
[233] time=130.82, avg_loss=0.0217, train_err=0.1737
Eval: 421_h1=0.0726, 421_l2=0.0117
[179] time=167.56, avg_loss=0.0058, train_err=0.1396
[461] time=227.07, avg_loss=0.0031, train_err=0.0741
Eval: 128_h1=0.0086, 128_l2=0.0043
Eval: 128_h1=0.0062, 128_l2=0.0029
[234] time=130.91, avg_loss=0.0216, train_err=0.1727
Eval: 421_h1=0.0728, 421_l2=0.0114
[180] time=167.60, avg_loss=0.0062, train_err=0.1496
Eval: 128_h1=0.0090, 128_l2=0.0046
[462] time=206.40, avg_loss=0.0031, train_err=0.0740
[235] time=130.79, avg_loss=0.0215, train_err=0.1720
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0728, 421_l2=0.0117
[181] time=167.73, avg_loss=0.0064, train_err=0.1543
Eval: 128_h1=0.0089, 128_l2=0.0047
[236] time=130.76, avg_loss=0.0215, train_err=0.1717
Eval: 421_h1=0.0725, 421_l2=0.0115
[463] time=213.34, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0062, 128_l2=0.0029
[237] time=130.76, avg_loss=0.0216, train_err=0.1725
Eval: 421_h1=0.0727, 421_l2=0.0115
[182] time=167.80, avg_loss=0.0068, train_err=0.1631
Eval: 128_h1=0.0107, 128_l2=0.0067
[238] time=130.71, avg_loss=0.0216, train_err=0.1727
Eval: 421_h1=0.0733, 421_l2=0.0119
[464] time=221.21, avg_loss=0.0031, train_err=0.0738
Eval: 128_h1=0.0062, 128_l2=0.0029
[183] time=167.65, avg_loss=0.0073, train_err=0.1760
Eval: 128_h1=0.0111, 128_l2=0.0075
[239] time=130.81, avg_loss=0.0216, train_err=0.1727
Eval: 421_h1=0.0732, 421_l2=0.0115
[184] time=167.55, avg_loss=0.0073, train_err=0.1760
Eval: 128_h1=0.0109, 128_l2=0.0074
[465] time=232.50, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0062, 128_l2=0.0029
[240] time=130.77, avg_loss=0.0211, train_err=0.1690
Eval: 421_h1=0.0729, 421_l2=0.0113
[185] time=167.64, avg_loss=0.0073, train_err=0.1761
Eval: 128_h1=0.0106, 128_l2=0.0070
[241] time=130.79, avg_loss=0.0206, train_err=0.1649
Eval: 421_h1=0.0730, 421_l2=0.0113
[466] time=208.77, avg_loss=0.0031, train_err=0.0736
Eval: 128_h1=0.0062, 128_l2=0.0029
[242] time=130.74, avg_loss=0.0205, train_err=0.1640
[186] time=167.66, avg_loss=0.0075, train_err=0.1800
Eval: 421_h1=0.0732, 421_l2=0.0113
Eval: 128_h1=0.0119, 128_l2=0.0079
[467] time=211.88, avg_loss=0.0031, train_err=0.0736
[243] time=130.78, avg_loss=0.0205, train_err=0.1637
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0732, 421_l2=0.0113
[187] time=167.71, avg_loss=0.0075, train_err=0.1802
Eval: 128_h1=0.0110, 128_l2=0.0067
[244] time=130.78, avg_loss=0.0204, train_err=0.1634
Eval: 421_h1=0.0733, 421_l2=0.0113
[188] time=167.54, avg_loss=0.0072, train_err=0.1717
[468] time=214.68, avg_loss=0.0031, train_err=0.0735
Eval: 128_h1=0.0108, 128_l2=0.0065
Eval: 128_h1=0.0062, 128_l2=0.0029
[245] time=130.82, avg_loss=0.0204, train_err=0.1632
Eval: 421_h1=0.0734, 421_l2=0.0113
[189] time=167.45, avg_loss=0.0069, train_err=0.1646
Eval: 128_h1=0.0104, 128_l2=0.0061
[246] time=130.77, avg_loss=0.0204, train_err=0.1630
Eval: 421_h1=0.0734, 421_l2=0.0113
[469] time=210.57, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0062, 128_l2=0.0029
[190] time=167.40, avg_loss=0.0067, train_err=0.1605
[247] time=130.80, avg_loss=0.0204, train_err=0.1629
Eval: 128_h1=0.0098, 128_l2=0.0056
Eval: 421_h1=0.0735, 421_l2=0.0113
[470] time=231.08, avg_loss=0.0031, train_err=0.0733
Eval: 128_h1=0.0062, 128_l2=0.0029
[248] time=130.79, avg_loss=0.0203, train_err=0.1628
Eval: 421_h1=0.0736, 421_l2=0.0113
[191] time=167.78, avg_loss=0.0064, train_err=0.1528
Eval: 128_h1=0.0100, 128_l2=0.0061
[249] time=130.81, avg_loss=0.0203, train_err=0.1627
Eval: 421_h1=0.0737, 421_l2=0.0113
[471] time=217.14, avg_loss=0.0031, train_err=0.0732
[192] time=167.65, avg_loss=0.0060, train_err=0.1443
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 128_h1=0.0098, 128_l2=0.0061
[250] time=130.66, avg_loss=0.0203, train_err=0.1627
Eval: 421_h1=0.0737, 421_l2=0.0113
[193] time=167.44, avg_loss=0.0058, train_err=0.1391
Eval: 128_h1=0.0089, 128_l2=0.0053
[472] time=206.96, avg_loss=0.0031, train_err=0.0732
[251] time=130.79, avg_loss=0.0203, train_err=0.1626
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0738, 421_l2=0.0113
[194] time=167.57, avg_loss=0.0057, train_err=0.1361
Eval: 128_h1=0.0087, 128_l2=0.0051
[252] time=130.80, avg_loss=0.0203, train_err=0.1626
Eval: 421_h1=0.0738, 421_l2=0.0113
[473] time=214.20, avg_loss=0.0030, train_err=0.0731
Eval: 128_h1=0.0062, 128_l2=0.0029
[253] time=130.79, avg_loss=0.0203, train_err=0.1628
Eval: 421_h1=0.0738, 421_l2=0.0113
[195] time=167.62, avg_loss=0.0058, train_err=0.1390
Eval: 128_h1=0.0098, 128_l2=0.0062
[254] time=130.75, avg_loss=0.0204, train_err=0.1629
Eval: 421_h1=0.0739, 421_l2=0.0114
[474] time=218.33, avg_loss=0.0030, train_err=0.0730
Eval: 128_h1=0.0062, 128_l2=0.0029
[196] time=167.45, avg_loss=0.0061, train_err=0.1466
Eval: 128_h1=0.0098, 128_l2=0.0063
[255] time=130.79, avg_loss=0.0204, train_err=0.1634
Eval: 421_h1=0.0739, 421_l2=0.0114
[197] time=167.60, avg_loss=0.0057, train_err=0.1365
Eval: 128_h1=0.0090, 128_l2=0.0053
[475] time=224.27, avg_loss=0.0030, train_err=0.0729
Eval: 128_h1=0.0062, 128_l2=0.0029
[256] time=130.81, avg_loss=0.0205, train_err=0.1637
Eval: 421_h1=0.0738, 421_l2=0.0113
[198] time=167.58, avg_loss=0.0056, train_err=0.1346
Eval: 128_h1=0.0089, 128_l2=0.0050
[257] time=130.75, avg_loss=0.0205, train_err=0.1637
Eval: 421_h1=0.0741, 421_l2=0.0114
[476] time=225.98, avg_loss=0.0030, train_err=0.0728
Eval: 128_h1=0.0062, 128_l2=0.0029
[258] time=130.82, avg_loss=0.0205, train_err=0.1641
[199] time=167.45, avg_loss=0.0057, train_err=0.1376
Eval: 421_h1=0.0740, 421_l2=0.0114
Eval: 128_h1=0.0087, 128_l2=0.0049
[259] time=130.82, avg_loss=0.0205, train_err=0.1641
[477] time=219.54, avg_loss=0.0030, train_err=0.0728
Eval: 421_h1=0.0739, 421_l2=0.0112
Eval: 128_h1=0.0062, 128_l2=0.0029
[200] time=167.36, avg_loss=0.0065, train_err=0.1554
Eval: 128_h1=0.0086, 128_l2=0.0047
[260] time=130.75, avg_loss=0.0204, train_err=0.1632
Eval: 421_h1=0.0740, 421_l2=0.0114
[201] time=167.80, avg_loss=0.0062, train_err=0.1483
Eval: 128_h1=0.0085, 128_l2=0.0046
[478] time=220.83, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0062, 128_l2=0.0029
[261] time=130.67, avg_loss=0.0204, train_err=0.1631
Eval: 421_h1=0.0741, 421_l2=0.0114
[202] time=167.56, avg_loss=0.0060, train_err=0.1433
Eval: 128_h1=0.0084, 128_l2=0.0045
[262] time=130.86, avg_loss=0.0204, train_err=0.1630
Eval: 421_h1=0.0742, 421_l2=0.0113
[479] time=220.68, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0062, 128_l2=0.0029
[203] time=167.63, avg_loss=0.0058, train_err=0.1399
[263] time=130.71, avg_loss=0.0203, train_err=0.1625
Eval: 128_h1=0.0084, 128_l2=0.0045
Eval: 421_h1=0.0742, 421_l2=0.0113
[480] time=226.23, avg_loss=0.0030, train_err=0.0725
[264] time=130.74, avg_loss=0.0203, train_err=0.1621
Eval: 128_h1=0.0062, 128_l2=0.0029
Eval: 421_h1=0.0741, 421_l2=0.0113
[204] time=167.52, avg_loss=0.0057, train_err=0.1373
Eval: 128_h1=0.0083, 128_l2=0.0044
[265] time=130.75, avg_loss=0.0203, train_err=0.1621
Eval: 421_h1=0.0740, 421_l2=0.0113
[205] time=167.48, avg_loss=0.0056, train_err=0.1350
Eval: 128_h1=0.0082, 128_l2=0.0043
[481] time=224.81, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0062, 128_l2=0.0029
[266] time=130.75, avg_loss=0.0203, train_err=0.1622
Eval: 421_h1=0.0742, 421_l2=0.0114
[206] time=167.48, avg_loss=0.0055, train_err=0.1330
Eval: 128_h1=0.0081, 128_l2=0.0041
[267] time=130.75, avg_loss=0.0203, train_err=0.1622
Eval: 421_h1=0.0743, 421_l2=0.0113
[482] time=222.58, avg_loss=0.0030, train_err=0.0724
Eval: 128_h1=0.0062, 128_l2=0.0029
[207] time=167.56, avg_loss=0.0055, train_err=0.1313
Eval: 128_h1=0.0080, 128_l2=0.0040
[268] time=130.77, avg_loss=0.0202, train_err=0.1617
Eval: 421_h1=0.0743, 421_l2=0.0113
[483] time=223.37, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0062, 128_l2=0.0029
[269] time=130.81, avg_loss=0.0202, train_err=0.1615
Eval: 421_h1=0.0741, 421_l2=0.0113
[208] time=167.77, avg_loss=0.0054, train_err=0.1298
Eval: 128_h1=0.0080, 128_l2=0.0039
[270] time=130.79, avg_loss=0.0202, train_err=0.1613
Eval: 421_h1=0.0745, 421_l2=0.0113
[209] time=167.77, avg_loss=0.0054, train_err=0.1284
Eval: 128_h1=0.0080, 128_l2=0.0039
[484] time=223.96, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0062, 128_l2=0.0029
[271] time=130.79, avg_loss=0.0201, train_err=0.1611
Eval: 421_h1=0.0744, 421_l2=0.0113
[210] time=167.54, avg_loss=0.0053, train_err=0.1272
Eval: 128_h1=0.0080, 128_l2=0.0039
[272] time=130.80, avg_loss=0.0201, train_err=0.1610
Eval: 421_h1=0.0746, 421_l2=0.0114
[485] time=229.17, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0062, 128_l2=0.0029
[211] time=167.42, avg_loss=0.0053, train_err=0.1261
Eval: 128_h1=0.0080, 128_l2=0.0039
[273] time=130.72, avg_loss=0.0202, train_err=0.1616
Eval: 421_h1=0.0745, 421_l2=0.0113
[486] time=228.23, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0062, 128_l2=0.0029
[274] time=130.80, avg_loss=0.0201, train_err=0.1610
[212] time=167.43, avg_loss=0.0052, train_err=0.1251
Eval: 421_h1=0.0746, 421_l2=0.0113
Eval: 128_h1=0.0080, 128_l2=0.0039
[275] time=130.80, avg_loss=0.0201, train_err=0.1609
Eval: 421_h1=0.0745, 421_l2=0.0113
[213] time=167.42, avg_loss=0.0052, train_err=0.1241
Eval: 128_h1=0.0080, 128_l2=0.0039
[487] time=223.87, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0062, 128_l2=0.0029
[276] time=130.88, avg_loss=0.0201, train_err=0.1608
Eval: 421_h1=0.0745, 421_l2=0.0114
[214] time=167.49, avg_loss=0.0051, train_err=0.1232
Eval: 128_h1=0.0080, 128_l2=0.0039
[277] time=130.83, avg_loss=0.0201, train_err=0.1609
Eval: 421_h1=0.0744, 421_l2=0.0114
[488] time=224.23, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0062, 128_l2=0.0029
[215] time=167.60, avg_loss=0.0051, train_err=0.1223
Eval: 128_h1=0.0080, 128_l2=0.0040
[278] time=130.72, avg_loss=0.0201, train_err=0.1605
Eval: 421_h1=0.0745, 421_l2=0.0113
[489] time=224.03, avg_loss=0.0030, train_err=0.0719
Eval: 128_h1=0.0062, 128_l2=0.0029
[279] time=130.79, avg_loss=0.0201, train_err=0.1606
[216] time=167.48, avg_loss=0.0051, train_err=0.1215
Eval: 128_h1=0.0080, 128_l2=0.0040
Eval: 421_h1=0.0745, 421_l2=0.0113
[280] time=130.79, avg_loss=0.0201, train_err=0.1607
Eval: 421_h1=0.0744, 421_l2=0.0114
[217] time=167.57, avg_loss=0.0050, train_err=0.1207
Eval: 128_h1=0.0080, 128_l2=0.0040
[490] time=224.13, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0062, 128_l2=0.0029
[281] time=130.73, avg_loss=0.0200, train_err=0.1599
Eval: 421_h1=0.0747, 421_l2=0.0113
[218] time=167.63, avg_loss=0.0050, train_err=0.1199
Eval: 128_h1=0.0080, 128_l2=0.0040
[282] time=130.74, avg_loss=0.0201, train_err=0.1605
Eval: 421_h1=0.0747, 421_l2=0.0115
[491] time=224.05, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0062, 128_l2=0.0029
[219] time=167.53, avg_loss=0.0050, train_err=0.1191
Eval: 128_h1=0.0080, 128_l2=0.0041
[283] time=130.80, avg_loss=0.0200, train_err=0.1599
Eval: 421_h1=0.0748, 421_l2=0.0113
[492] time=223.94, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0062, 128_l2=0.0029
[220] time=167.69, avg_loss=0.0049, train_err=0.1183
[284] time=130.78, avg_loss=0.0199, train_err=0.1595
Eval: 128_h1=0.0080, 128_l2=0.0041
Eval: 421_h1=0.0749, 421_l2=0.0113
[285] time=130.78, avg_loss=0.0199, train_err=0.1595
Eval: 421_h1=0.0749, 421_l2=0.0114
[221] time=167.59, avg_loss=0.0049, train_err=0.1176
Eval: 128_h1=0.0080, 128_l2=0.0041
[493] time=224.05, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0062, 128_l2=0.0029
[286] time=130.82, avg_loss=0.0199, train_err=0.1593
Eval: 421_h1=0.0751, 421_l2=0.0113
[222] time=167.72, avg_loss=0.0049, train_err=0.1169
Eval: 128_h1=0.0080, 128_l2=0.0042
[287] time=130.75, avg_loss=0.0199, train_err=0.1591
Eval: 421_h1=0.0748, 421_l2=0.0113
[494] time=224.85, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0062, 128_l2=0.0029
[223] time=167.58, avg_loss=0.0048, train_err=0.1163
Eval: 128_h1=0.0080, 128_l2=0.0042
[288] time=130.75, avg_loss=0.0199, train_err=0.1590
Eval: 421_h1=0.0750, 421_l2=0.0113
[495] time=224.67, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0062, 128_l2=0.0029
[224] time=167.37, avg_loss=0.0048, train_err=0.1156
Eval: 128_h1=0.0080, 128_l2=0.0042
[289] time=130.83, avg_loss=0.0199, train_err=0.1589
Eval: 421_h1=0.0750, 421_l2=0.0113
[290] time=130.77, avg_loss=0.0198, train_err=0.1587
Eval: 421_h1=0.0749, 421_l2=0.0113
[225] time=167.79, avg_loss=0.0048, train_err=0.1151
Eval: 128_h1=0.0080, 128_l2=0.0042
[496] time=224.46, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0061, 128_l2=0.0029
[291] time=130.84, avg_loss=0.0199, train_err=0.1592
Eval: 421_h1=0.0752, 421_l2=0.0114
[226] time=167.63, avg_loss=0.0048, train_err=0.1145
Eval: 128_h1=0.0080, 128_l2=0.0042
[292] time=130.70, avg_loss=0.0198, train_err=0.1586
[497] time=224.78, avg_loss=0.0030, train_err=0.0714
Eval: 421_h1=0.0750, 421_l2=0.0113
Eval: 128_h1=0.0061, 128_l2=0.0029
[227] time=167.56, avg_loss=0.0048, train_err=0.1141
Eval: 128_h1=0.0080, 128_l2=0.0042
[293] time=130.88, avg_loss=0.0198, train_err=0.1584
Eval: 421_h1=0.0751, 421_l2=0.0113
[498] time=224.92, avg_loss=0.0030, train_err=0.0713
[228] time=167.38, avg_loss=0.0047, train_err=0.1137
Eval: 128_h1=0.0061, 128_l2=0.0029
Eval: 128_h1=0.0080, 128_l2=0.0042
[294] time=130.73, avg_loss=0.0198, train_err=0.1584
Eval: 421_h1=0.0754, 421_l2=0.0116
[295] time=130.84, avg_loss=0.0198, train_err=0.1587
[229] time=167.59, avg_loss=0.0047, train_err=0.1135
Eval: 421_h1=0.0750, 421_l2=0.0114
Eval: 128_h1=0.0080, 128_l2=0.0043
[499] time=225.23, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0061, 128_l2=0.0029
[296] time=130.81, avg_loss=0.0198, train_err=0.1585
Eval: 421_h1=0.0753, 421_l2=0.0113
[230] time=167.45, avg_loss=0.0047, train_err=0.1134
Eval: 128_h1=0.0080, 128_l2=0.0043
[297] time=130.85, avg_loss=0.0198, train_err=0.1585
[500] time=225.14, avg_loss=0.0031, train_err=0.0744
Eval: 421_h1=0.0751, 421_l2=0.0114
Eval: 128_h1=0.0062, 128_l2=0.0029
[231] time=167.38, avg_loss=0.0047, train_err=0.1131
Eval: 128_h1=0.0080, 128_l2=0.0042
[298] time=130.75, avg_loss=0.0198, train_err=0.1581
Eval: 421_h1=0.0753, 421_l2=0.0114
[501] time=224.93, avg_loss=0.0031, train_err=0.0743
[232] time=167.30, avg_loss=0.0047, train_err=0.1124
Eval: 128_h1=0.0080, 128_l2=0.0042
Eval: 128_h1=0.0061, 128_l2=0.0029
[299] time=130.76, avg_loss=0.0197, train_err=0.1579
Eval: 421_h1=0.0750, 421_l2=0.0114
[233] time=167.59, avg_loss=0.0046, train_err=0.1114
Eval: 128_h1=0.0080, 128_l2=0.0042
[502] time=227.93, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0061, 128_l2=0.0029
[234] time=167.60, avg_loss=0.0046, train_err=0.1105
Eval: 128_h1=0.0079, 128_l2=0.0041
[503] time=232.12, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0061, 128_l2=0.0029
[235] time=167.57, avg_loss=0.0046, train_err=0.1096
Eval: 128_h1=0.0079, 128_l2=0.0041
[236] time=167.55, avg_loss=0.0045, train_err=0.1089
[504] time=214.43, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0078, 128_l2=0.0040
Eval: 128_h1=0.0061, 128_l2=0.0029
[237] time=167.52, avg_loss=0.0045, train_err=0.1082
Eval: 128_h1=0.0078, 128_l2=0.0040
[505] time=226.20, avg_loss=0.0031, train_err=0.0732
Eval: 128_h1=0.0061, 128_l2=0.0029
[238] time=167.32, avg_loss=0.0045, train_err=0.1077
Eval: 128_h1=0.0078, 128_l2=0.0040
[506] time=220.49, avg_loss=0.0030, train_err=0.0730
Eval: 128_h1=0.0061, 128_l2=0.0029
[239] time=167.40, avg_loss=0.0045, train_err=0.1072
Eval: 128_h1=0.0077, 128_l2=0.0039
[507] time=209.46, avg_loss=0.0030, train_err=0.0728
[240] time=167.63, avg_loss=0.0045, train_err=0.1067
Eval: 128_h1=0.0061, 128_l2=0.0029
Eval: 128_h1=0.0077, 128_l2=0.0039
[241] time=167.41, avg_loss=0.0044, train_err=0.1064
Eval: 128_h1=0.0077, 128_l2=0.0039
[508] time=219.03, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0060, 128_l2=0.0029
[242] time=167.49, avg_loss=0.0044, train_err=0.1062
Eval: 128_h1=0.0077, 128_l2=0.0040
[509] time=225.65, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0060, 128_l2=0.0028
[243] time=167.55, avg_loss=0.0044, train_err=0.1065
Eval: 128_h1=0.0078, 128_l2=0.0041
[510] time=230.59, avg_loss=0.0030, train_err=0.0724
[244] time=167.52, avg_loss=0.0045, train_err=0.1081
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0079, 128_l2=0.0041
[245] time=167.48, avg_loss=0.0046, train_err=0.1109
Eval: 128_h1=0.0079, 128_l2=0.0041
[511] time=206.43, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0060, 128_l2=0.0028
[246] time=167.46, avg_loss=0.0046, train_err=0.1111
Eval: 128_h1=0.0079, 128_l2=0.0040
[512] time=212.40, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0060, 128_l2=0.0028
[247] time=167.59, avg_loss=0.0048, train_err=0.1147
Eval: 128_h1=0.0080, 128_l2=0.0042
[513] time=216.32, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0060, 128_l2=0.0028
[248] time=167.57, avg_loss=0.0049, train_err=0.1182
Eval: 128_h1=0.0081, 128_l2=0.0044
[249] time=167.59, avg_loss=0.0049, train_err=0.1184
Eval: 128_h1=0.0080, 128_l2=0.0043
[514] time=215.96, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0060, 128_l2=0.0028
[250] time=167.46, avg_loss=0.0049, train_err=0.1186
Eval: 128_h1=0.0079, 128_l2=0.0042
[515] time=215.31, avg_loss=0.0030, train_err=0.0719
Eval: 128_h1=0.0060, 128_l2=0.0028
[251] time=167.62, avg_loss=0.0050, train_err=0.1191
Eval: 128_h1=0.0079, 128_l2=0.0042
[516] time=220.56, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0060, 128_l2=0.0028
[252] time=167.61, avg_loss=0.0050, train_err=0.1208
Eval: 128_h1=0.0080, 128_l2=0.0043
[517] time=217.96, avg_loss=0.0030, train_err=0.0717
[253] time=167.63, avg_loss=0.0051, train_err=0.1224
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0081, 128_l2=0.0043
[254] time=167.69, avg_loss=0.0051, train_err=0.1223
Eval: 128_h1=0.0080, 128_l2=0.0041
[518] time=217.70, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0060, 128_l2=0.0028
[255] time=167.47, avg_loss=0.0050, train_err=0.1206
Eval: 128_h1=0.0079, 128_l2=0.0039
[519] time=220.16, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0060, 128_l2=0.0028
[256] time=167.55, avg_loss=0.0049, train_err=0.1177
Eval: 128_h1=0.0079, 128_l2=0.0037
[520] time=221.52, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0060, 128_l2=0.0028
[257] time=167.63, avg_loss=0.0048, train_err=0.1154
Eval: 128_h1=0.0078, 128_l2=0.0037
[258] time=167.58, avg_loss=0.0047, train_err=0.1131
Eval: 128_h1=0.0078, 128_l2=0.0037
[521] time=227.46, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0060, 128_l2=0.0028
[259] time=167.42, avg_loss=0.0046, train_err=0.1105
Eval: 128_h1=0.0078, 128_l2=0.0038
[522] time=220.42, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0060, 128_l2=0.0028
[260] time=167.53, avg_loss=0.0045, train_err=0.1080
Eval: 128_h1=0.0076, 128_l2=0.0037
[523] time=220.38, avg_loss=0.0030, train_err=0.0712
Eval: 128_h1=0.0060, 128_l2=0.0028
[261] time=167.52, avg_loss=0.0044, train_err=0.1056
Eval: 128_h1=0.0075, 128_l2=0.0037
[262] time=167.54, avg_loss=0.0043, train_err=0.1038
Eval: 128_h1=0.0078, 128_l2=0.0041
[524] time=219.30, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0060, 128_l2=0.0028
[263] time=167.67, avg_loss=0.0043, train_err=0.1029
Eval: 128_h1=0.0077, 128_l2=0.0041
[525] time=222.60, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0060, 128_l2=0.0028
[264] time=167.63, avg_loss=0.0043, train_err=0.1022
Eval: 128_h1=0.0075, 128_l2=0.0039
[526] time=230.80, avg_loss=0.0030, train_err=0.0710
Eval: 128_h1=0.0060, 128_l2=0.0028
[265] time=167.67, avg_loss=0.0043, train_err=0.1038
Eval: 128_h1=0.0074, 128_l2=0.0036
[266] time=167.37, avg_loss=0.0042, train_err=0.1012
Eval: 128_h1=0.0076, 128_l2=0.0040
[527] time=232.83, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0060, 128_l2=0.0028
[267] time=167.43, avg_loss=0.0041, train_err=0.0995
Eval: 128_h1=0.0076, 128_l2=0.0039
[528] time=224.12, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0060, 128_l2=0.0028
[268] time=167.55, avg_loss=0.0041, train_err=0.0988
Eval: 128_h1=0.0073, 128_l2=0.0036
[529] time=222.22, avg_loss=0.0030, train_err=0.0708
[269] time=167.55, avg_loss=0.0041, train_err=0.0984
Eval: 128_h1=0.0073, 128_l2=0.0035
Eval: 128_h1=0.0060, 128_l2=0.0028
[270] time=167.45, avg_loss=0.0041, train_err=0.0978
Eval: 128_h1=0.0072, 128_l2=0.0035
[530] time=223.39, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0060, 128_l2=0.0028
[271] time=167.43, avg_loss=0.0040, train_err=0.0970
Eval: 128_h1=0.0072, 128_l2=0.0034
[531] time=228.46, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0060, 128_l2=0.0028
[272] time=167.55, avg_loss=0.0040, train_err=0.0966
Eval: 128_h1=0.0072, 128_l2=0.0034
[273] time=167.45, avg_loss=0.0040, train_err=0.0964
[532] time=224.82, avg_loss=0.0029, train_err=0.0706
Eval: 128_h1=0.0072, 128_l2=0.0034
Eval: 128_h1=0.0060, 128_l2=0.0028
[274] time=167.40, avg_loss=0.0040, train_err=0.0965
Eval: 128_h1=0.0072, 128_l2=0.0035
[533] time=222.52, avg_loss=0.0029, train_err=0.0706
Eval: 128_h1=0.0060, 128_l2=0.0028
[275] time=167.39, avg_loss=0.0041, train_err=0.0981
Eval: 128_h1=0.0072, 128_l2=0.0035
[534] time=221.72, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0060, 128_l2=0.0028
[276] time=167.37, avg_loss=0.0043, train_err=0.1026
Eval: 128_h1=0.0078, 128_l2=0.0043
[277] time=167.63, avg_loss=0.0043, train_err=0.1029
[535] time=221.45, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0073, 128_l2=0.0036
Eval: 128_h1=0.0060, 128_l2=0.0028
[278] time=167.77, avg_loss=0.0044, train_err=0.1048
Eval: 128_h1=0.0073, 128_l2=0.0036
[536] time=224.49, avg_loss=0.0029, train_err=0.0704
Eval: 128_h1=0.0060, 128_l2=0.0028
[279] time=167.49, avg_loss=0.0045, train_err=0.1088
Eval: 128_h1=0.0076, 128_l2=0.0039
[537] time=224.36, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0060, 128_l2=0.0028
[280] time=167.60, avg_loss=0.0045, train_err=0.1081
Eval: 128_h1=0.0076, 128_l2=0.0038
[281] time=167.55, avg_loss=0.0045, train_err=0.1068
[538] time=220.12, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0075, 128_l2=0.0037
Eval: 128_h1=0.0060, 128_l2=0.0028
[282] time=167.59, avg_loss=0.0045, train_err=0.1067
Eval: 128_h1=0.0075, 128_l2=0.0037
[539] time=219.14, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0060, 128_l2=0.0028
[283] time=167.59, avg_loss=0.0044, train_err=0.1061
Eval: 128_h1=0.0075, 128_l2=0.0037
[540] time=219.02, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0060, 128_l2=0.0028
[284] time=167.50, avg_loss=0.0044, train_err=0.1052
Eval: 128_h1=0.0075, 128_l2=0.0036
[541] time=222.96, avg_loss=0.0029, train_err=0.0701
[285] time=167.56, avg_loss=0.0043, train_err=0.1041
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0075, 128_l2=0.0037
[286] time=167.62, avg_loss=0.0043, train_err=0.1029
Eval: 128_h1=0.0075, 128_l2=0.0037
[542] time=223.55, avg_loss=0.0029, train_err=0.0701
Eval: 128_h1=0.0060, 128_l2=0.0028
[287] time=167.55, avg_loss=0.0042, train_err=0.1016
Eval: 128_h1=0.0074, 128_l2=0.0037
[543] time=220.00, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0060, 128_l2=0.0028
[288] time=167.72, avg_loss=0.0042, train_err=0.1003
Eval: 128_h1=0.0074, 128_l2=0.0036
[544] time=219.61, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0060, 128_l2=0.0028
[289] time=167.54, avg_loss=0.0041, train_err=0.0987
Eval: 128_h1=0.0073, 128_l2=0.0036
[290] time=167.46, avg_loss=0.0041, train_err=0.0972
Eval: 128_h1=0.0073, 128_l2=0.0036
[545] time=219.07, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0060, 128_l2=0.0028
[291] time=167.41, avg_loss=0.0040, train_err=0.0960
Eval: 128_h1=0.0075, 128_l2=0.0040
[546] time=211.24, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0060, 128_l2=0.0028
[292] time=167.48, avg_loss=0.0040, train_err=0.0948
Eval: 128_h1=0.0073, 128_l2=0.0037
[547] time=212.23, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0060, 128_l2=0.0028
[293] time=167.34, avg_loss=0.0039, train_err=0.0943
Eval: 128_h1=0.0071, 128_l2=0.0035
[294] time=167.41, avg_loss=0.0039, train_err=0.0940
Eval: 128_h1=0.0071, 128_l2=0.0034
[548] time=230.64, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0060, 128_l2=0.0028
[295] time=167.45, avg_loss=0.0039, train_err=0.0935
Eval: 128_h1=0.0071, 128_l2=0.0034
[549] time=219.49, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0060, 128_l2=0.0028
[296] time=167.37, avg_loss=0.0039, train_err=0.0933
Eval: 128_h1=0.0071, 128_l2=0.0034
[550] time=203.69, avg_loss=0.0029, train_err=0.0697
Eval: 128_h1=0.0060, 128_l2=0.0028
[297] time=167.53, avg_loss=0.0039, train_err=0.0934
Eval: 128_h1=0.0071, 128_l2=0.0035
[551] time=211.95, avg_loss=0.0029, train_err=0.0697
[298] time=167.44, avg_loss=0.0039, train_err=0.0945
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0071, 128_l2=0.0036
[299] time=167.63, avg_loss=0.0041, train_err=0.0995
Eval: 128_h1=0.0075, 128_l2=0.0039
[552] time=213.03, avg_loss=0.0029, train_err=0.0696
Eval: 128_h1=0.0060, 128_l2=0.0028
[300] time=167.60, avg_loss=0.0046, train_err=0.1101
Eval: 128_h1=0.0074, 128_l2=0.0038
[553] time=212.96, avg_loss=0.0029, train_err=0.0696
Eval: 128_h1=0.0060, 128_l2=0.0028
[301] time=167.57, avg_loss=0.0045, train_err=0.1084
Eval: 128_h1=0.0074, 128_l2=0.0037
[554] time=214.22, avg_loss=0.0029, train_err=0.0696
Eval: 128_h1=0.0060, 128_l2=0.0028
[302] time=167.55, avg_loss=0.0044, train_err=0.1059
Eval: 128_h1=0.0073, 128_l2=0.0037
[303] time=167.63, avg_loss=0.0043, train_err=0.1042
Eval: 128_h1=0.0073, 128_l2=0.0037
[555] time=214.84, avg_loss=0.0029, train_err=0.0695
Eval: 128_h1=0.0060, 128_l2=0.0028
[304] time=167.52, avg_loss=0.0043, train_err=0.1030
Eval: 128_h1=0.0073, 128_l2=0.0037
[556] time=216.49, avg_loss=0.0029, train_err=0.0695
Eval: 128_h1=0.0060, 128_l2=0.0028
[305] time=167.45, avg_loss=0.0043, train_err=0.1020
Eval: 128_h1=0.0073, 128_l2=0.0037
[557] time=220.11, avg_loss=0.0029, train_err=0.0694
Eval: 128_h1=0.0060, 128_l2=0.0028
[306] time=168.03, avg_loss=0.0042, train_err=0.1011
Eval: 128_h1=0.0073, 128_l2=0.0038
[558] time=220.71, avg_loss=0.0029, train_err=0.0694
[307] time=168.74, avg_loss=0.0042, train_err=0.1004
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0073, 128_l2=0.0038
[308] time=173.66, avg_loss=0.0042, train_err=0.0997
Eval: 128_h1=0.0073, 128_l2=0.0038
[559] time=224.60, avg_loss=0.0029, train_err=0.0693
Eval: 128_h1=0.0060, 128_l2=0.0028
[309] time=173.54, avg_loss=0.0041, train_err=0.0990
Eval: 128_h1=0.0073, 128_l2=0.0038
[560] time=225.39, avg_loss=0.0029, train_err=0.0693
Eval: 128_h1=0.0060, 128_l2=0.0028
[310] time=173.47, avg_loss=0.0041, train_err=0.0984
Eval: 128_h1=0.0073, 128_l2=0.0038
[561] time=225.82, avg_loss=0.0029, train_err=0.0693
Eval: 128_h1=0.0060, 128_l2=0.0028
[311] time=175.35, avg_loss=0.0041, train_err=0.0979
Eval: 128_h1=0.0073, 128_l2=0.0038
[312] time=179.60, avg_loss=0.0041, train_err=0.0974
Eval: 128_h1=0.0073, 128_l2=0.0038
[562] time=225.87, avg_loss=0.0029, train_err=0.0692
Eval: 128_h1=0.0060, 128_l2=0.0028
[313] time=179.56, avg_loss=0.0040, train_err=0.0969
Eval: 128_h1=0.0073, 128_l2=0.0038
[563] time=225.58, avg_loss=0.0029, train_err=0.0692
Eval: 128_h1=0.0060, 128_l2=0.0028
[314] time=179.59, avg_loss=0.0040, train_err=0.0964
Eval: 128_h1=0.0073, 128_l2=0.0038
[564] time=225.95, avg_loss=0.0029, train_err=0.0692
Eval: 128_h1=0.0060, 128_l2=0.0028
[315] time=176.07, avg_loss=0.0040, train_err=0.0960
Eval: 128_h1=0.0073, 128_l2=0.0038
[565] time=226.17, avg_loss=0.0029, train_err=0.0691
[316] time=167.42, avg_loss=0.0040, train_err=0.0955
Eval: 128_h1=0.0073, 128_l2=0.0038
Eval: 128_h1=0.0060, 128_l2=0.0028
[317] time=167.51, avg_loss=0.0040, train_err=0.0951
Eval: 128_h1=0.0072, 128_l2=0.0038
[566] time=225.77, avg_loss=0.0029, train_err=0.0691
Eval: 128_h1=0.0060, 128_l2=0.0028
[318] time=167.42, avg_loss=0.0040, train_err=0.0947
Eval: 128_h1=0.0072, 128_l2=0.0038
[567] time=224.86, avg_loss=0.0029, train_err=0.0690
Eval: 128_h1=0.0060, 128_l2=0.0028
[319] time=167.57, avg_loss=0.0039, train_err=0.0944
Eval: 128_h1=0.0072, 128_l2=0.0038
[320] time=168.24, avg_loss=0.0039, train_err=0.0940
[568] time=221.79, avg_loss=0.0029, train_err=0.0690
Eval: 128_h1=0.0072, 128_l2=0.0038
Eval: 128_h1=0.0060, 128_l2=0.0028
[321] time=173.36, avg_loss=0.0039, train_err=0.0937
Eval: 128_h1=0.0072, 128_l2=0.0038
[569] time=226.44, avg_loss=0.0029, train_err=0.0690
Eval: 128_h1=0.0060, 128_l2=0.0028
[322] time=173.46, avg_loss=0.0039, train_err=0.0933
Eval: 128_h1=0.0072, 128_l2=0.0038
[570] time=227.45, avg_loss=0.0029, train_err=0.0689
Eval: 128_h1=0.0060, 128_l2=0.0028
[323] time=173.45, avg_loss=0.0039, train_err=0.0930
Eval: 128_h1=0.0072, 128_l2=0.0038
[571] time=223.21, avg_loss=0.0029, train_err=0.0689
Eval: 128_h1=0.0060, 128_l2=0.0028
[324] time=174.66, avg_loss=0.0039, train_err=0.0927
Eval: 128_h1=0.0072, 128_l2=0.0038
[325] time=179.47, avg_loss=0.0039, train_err=0.0924
Eval: 128_h1=0.0072, 128_l2=0.0038
[572] time=222.24, avg_loss=0.0029, train_err=0.0689
Eval: 128_h1=0.0060, 128_l2=0.0028
[326] time=179.67, avg_loss=0.0038, train_err=0.0921
Eval: 128_h1=0.0072, 128_l2=0.0038
[573] time=221.76, avg_loss=0.0029, train_err=0.0688
Eval: 128_h1=0.0060, 128_l2=0.0028
[327] time=179.98, avg_loss=0.0038, train_err=0.0918
Eval: 128_h1=0.0072, 128_l2=0.0038
[574] time=221.84, avg_loss=0.0029, train_err=0.0688
Eval: 128_h1=0.0060, 128_l2=0.0028
[328] time=177.81, avg_loss=0.0038, train_err=0.0915
Eval: 128_h1=0.0072, 128_l2=0.0037
[575] time=222.07, avg_loss=0.0029, train_err=0.0687
[329] time=167.44, avg_loss=0.0038, train_err=0.0912
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0071, 128_l2=0.0037
[330] time=167.47, avg_loss=0.0038, train_err=0.0909
Eval: 128_h1=0.0071, 128_l2=0.0037
[576] time=222.33, avg_loss=0.0029, train_err=0.0687
Eval: 128_h1=0.0060, 128_l2=0.0028
[331] time=167.53, avg_loss=0.0038, train_err=0.0906
Eval: 128_h1=0.0071, 128_l2=0.0037
[577] time=222.98, avg_loss=0.0029, train_err=0.0687
Eval: 128_h1=0.0060, 128_l2=0.0028
[332] time=167.67, avg_loss=0.0038, train_err=0.0904
Eval: 128_h1=0.0071, 128_l2=0.0037
[578] time=223.55, avg_loss=0.0029, train_err=0.0686
[333] time=167.65, avg_loss=0.0038, train_err=0.0901
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0071, 128_l2=0.0037
[334] time=167.49, avg_loss=0.0037, train_err=0.0898
Eval: 128_h1=0.0071, 128_l2=0.0037
[579] time=223.82, avg_loss=0.0029, train_err=0.0686
Eval: 128_h1=0.0060, 128_l2=0.0028
[335] time=167.32, avg_loss=0.0037, train_err=0.0896
Eval: 128_h1=0.0071, 128_l2=0.0037
[580] time=223.70, avg_loss=0.0029, train_err=0.0686
Eval: 128_h1=0.0060, 128_l2=0.0028
[336] time=167.34, avg_loss=0.0037, train_err=0.0893
Eval: 128_h1=0.0071, 128_l2=0.0037
[581] time=224.14, avg_loss=0.0029, train_err=0.0685
[337] time=167.63, avg_loss=0.0037, train_err=0.0890
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0071, 128_l2=0.0037
[338] time=167.56, avg_loss=0.0037, train_err=0.0888
Eval: 128_h1=0.0071, 128_l2=0.0037
[582] time=223.75, avg_loss=0.0029, train_err=0.0685
Eval: 128_h1=0.0060, 128_l2=0.0028
[339] time=167.32, avg_loss=0.0037, train_err=0.0885
Eval: 128_h1=0.0070, 128_l2=0.0037
[583] time=223.86, avg_loss=0.0029, train_err=0.0685
Eval: 128_h1=0.0060, 128_l2=0.0028
[340] time=167.44, avg_loss=0.0037, train_err=0.0882
Eval: 128_h1=0.0070, 128_l2=0.0036
[584] time=220.62, avg_loss=0.0029, train_err=0.0684
[341] time=167.64, avg_loss=0.0037, train_err=0.0879
Eval: 128_h1=0.0060, 128_l2=0.0028
Eval: 128_h1=0.0070, 128_l2=0.0036
[342] time=167.63, avg_loss=0.0037, train_err=0.0876
Eval: 128_h1=0.0069, 128_l2=0.0035
[585] time=208.76, avg_loss=0.0029, train_err=0.0684
Eval: 128_h1=0.0060, 128_l2=0.0028
[343] time=167.46, avg_loss=0.0036, train_err=0.0872
Eval: 128_h1=0.0069, 128_l2=0.0034
[586] time=223.01, avg_loss=0.0029, train_err=0.0684
Eval: 128_h1=0.0060, 128_l2=0.0028
[344] time=172.27, avg_loss=0.0036, train_err=0.0869
Eval: 128_h1=0.0068, 128_l2=0.0034
[587] time=231.70, avg_loss=0.0028, train_err=0.0683
Eval: 128_h1=0.0060, 128_l2=0.0028
[345] time=167.27, avg_loss=0.0036, train_err=0.0865
Eval: 128_h1=0.0068, 128_l2=0.0033
[346] time=166.40, avg_loss=0.0036, train_err=0.0863
Eval: 128_h1=0.0068, 128_l2=0.0033
[588] time=201.98, avg_loss=0.0028, train_err=0.0683
Eval: 128_h1=0.0060, 128_l2=0.0028
[347] time=166.37, avg_loss=0.0036, train_err=0.0860
Eval: 128_h1=0.0067, 128_l2=0.0032
[589] time=196.36, avg_loss=0.0028, train_err=0.0683
Eval: 128_h1=0.0060, 128_l2=0.0028
[348] time=166.36, avg_loss=0.0036, train_err=0.0858
Eval: 128_h1=0.0067, 128_l2=0.0032
[590] time=197.07, avg_loss=0.0028, train_err=0.0682
Eval: 128_h1=0.0059, 128_l2=0.0028
[349] time=166.36, avg_loss=0.0036, train_err=0.0856
Eval: 128_h1=0.0067, 128_l2=0.0032
[591] time=207.44, avg_loss=0.0028, train_err=0.0682
Eval: 128_h1=0.0059, 128_l2=0.0028
[350] time=166.37, avg_loss=0.0036, train_err=0.0854
Eval: 128_h1=0.0067, 128_l2=0.0032
[351] time=166.38, avg_loss=0.0036, train_err=0.0854
[592] time=215.82, avg_loss=0.0028, train_err=0.0682
Eval: 128_h1=0.0067, 128_l2=0.0032
Eval: 128_h1=0.0059, 128_l2=0.0028
[352] time=166.36, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0068, 128_l2=0.0033
[593] time=195.71, avg_loss=0.0028, train_err=0.0681
Eval: 128_h1=0.0059, 128_l2=0.0028
[353] time=166.39, avg_loss=0.0036, train_err=0.0869
Eval: 128_h1=0.0073, 128_l2=0.0041
[594] time=195.13, avg_loss=0.0028, train_err=0.0681
Eval: 128_h1=0.0059, 128_l2=0.0028
[354] time=166.33, avg_loss=0.0037, train_err=0.0882
Eval: 128_h1=0.0071, 128_l2=0.0038
[595] time=196.11, avg_loss=0.0028, train_err=0.0681
Eval: 128_h1=0.0059, 128_l2=0.0028
[355] time=166.37, avg_loss=0.0036, train_err=0.0874
Eval: 128_h1=0.0071, 128_l2=0.0037
[596] time=209.17, avg_loss=0.0028, train_err=0.0680
Eval: 128_h1=0.0059, 128_l2=0.0028
[356] time=166.38, avg_loss=0.0036, train_err=0.0869
Eval: 128_h1=0.0071, 128_l2=0.0037
[357] time=166.37, avg_loss=0.0036, train_err=0.0866
Eval: 128_h1=0.0070, 128_l2=0.0037
[597] time=216.04, avg_loss=0.0028, train_err=0.0680
Eval: 128_h1=0.0059, 128_l2=0.0028
[358] time=166.43, avg_loss=0.0036, train_err=0.0864
Eval: 128_h1=0.0070, 128_l2=0.0037
[598] time=196.80, avg_loss=0.0028, train_err=0.0680
Eval: 128_h1=0.0059, 128_l2=0.0028
[359] time=166.43, avg_loss=0.0036, train_err=0.0861
Eval: 128_h1=0.0070, 128_l2=0.0036
[599] time=197.75, avg_loss=0.0028, train_err=0.0679
Eval: 128_h1=0.0059, 128_l2=0.0028
NS.sh: 57: exit: Illegal number: 0CFILE 2>/dev/null || echo 1)
[360] time=166.38, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0070, 128_l2=0.0036
[361] time=166.41, avg_loss=0.0036, train_err=0.0853
Eval: 128_h1=0.0069, 128_l2=0.0036
[362] time=166.44, avg_loss=0.0035, train_err=0.0846
Eval: 128_h1=0.0068, 128_l2=0.0034
[363] time=166.39, avg_loss=0.0035, train_err=0.0840
Eval: 128_h1=0.0067, 128_l2=0.0033
[364] time=166.42, avg_loss=0.0035, train_err=0.0834
Eval: 128_h1=0.0067, 128_l2=0.0032
[365] time=166.35, avg_loss=0.0035, train_err=0.0830
Eval: 128_h1=0.0066, 128_l2=0.0032
[366] time=166.42, avg_loss=0.0034, train_err=0.0827
Eval: 128_h1=0.0066, 128_l2=0.0031
[367] time=166.37, avg_loss=0.0034, train_err=0.0824
Eval: 128_h1=0.0066, 128_l2=0.0031
[368] time=166.40, avg_loss=0.0034, train_err=0.0820
Eval: 128_h1=0.0066, 128_l2=0.0031
[369] time=166.36, avg_loss=0.0034, train_err=0.0817
Eval: 128_h1=0.0066, 128_l2=0.0031
[370] time=166.36, avg_loss=0.0034, train_err=0.0815
Eval: 128_h1=0.0066, 128_l2=0.0031
[371] time=166.35, avg_loss=0.0034, train_err=0.0812
Eval: 128_h1=0.0066, 128_l2=0.0031
[372] time=166.38, avg_loss=0.0034, train_err=0.0810
Eval: 128_h1=0.0066, 128_l2=0.0031
[373] time=166.36, avg_loss=0.0034, train_err=0.0808
Eval: 128_h1=0.0066, 128_l2=0.0031
[374] time=166.36, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0067, 128_l2=0.0032
[375] time=166.34, avg_loss=0.0034, train_err=0.0803
Eval: 128_h1=0.0067, 128_l2=0.0032
[376] time=166.35, avg_loss=0.0033, train_err=0.0802
Eval: 128_h1=0.0067, 128_l2=0.0032
[377] time=166.35, avg_loss=0.0033, train_err=0.0800
Eval: 128_h1=0.0066, 128_l2=0.0032
[378] time=166.37, avg_loss=0.0033, train_err=0.0798
Eval: 128_h1=0.0066, 128_l2=0.0031
[379] time=166.38, avg_loss=0.0033, train_err=0.0796
Eval: 128_h1=0.0066, 128_l2=0.0031
[380] time=166.36, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0066, 128_l2=0.0031
[381] time=166.34, avg_loss=0.0033, train_err=0.0794
Eval: 128_h1=0.0066, 128_l2=0.0031
[382] time=166.39, avg_loss=0.0033, train_err=0.0793
Eval: 128_h1=0.0066, 128_l2=0.0032
[383] time=166.36, avg_loss=0.0033, train_err=0.0794
Eval: 128_h1=0.0068, 128_l2=0.0034
[384] time=166.37, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0066, 128_l2=0.0031
[385] time=166.35, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0065, 128_l2=0.0030
[386] time=166.40, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0065, 128_l2=0.0030
[387] time=166.35, avg_loss=0.0034, train_err=0.0808
Eval: 128_h1=0.0065, 128_l2=0.0031
[388] time=166.35, avg_loss=0.0034, train_err=0.0815
Eval: 128_h1=0.0066, 128_l2=0.0031
[389] time=166.35, avg_loss=0.0034, train_err=0.0821
Eval: 128_h1=0.0065, 128_l2=0.0031
[390] time=166.38, avg_loss=0.0034, train_err=0.0824
Eval: 128_h1=0.0065, 128_l2=0.0031
[391] time=166.35, avg_loss=0.0034, train_err=0.0822
Eval: 128_h1=0.0066, 128_l2=0.0031
[392] time=166.35, avg_loss=0.0034, train_err=0.0820
Eval: 128_h1=0.0065, 128_l2=0.0031
[393] time=166.35, avg_loss=0.0034, train_err=0.0821
Eval: 128_h1=0.0066, 128_l2=0.0031
[394] time=166.37, avg_loss=0.0034, train_err=0.0826
Eval: 128_h1=0.0067, 128_l2=0.0032
[395] time=166.43, avg_loss=0.0035, train_err=0.0836
Eval: 128_h1=0.0069, 128_l2=0.0036
[396] time=166.45, avg_loss=0.0035, train_err=0.0843
Eval: 128_h1=0.0068, 128_l2=0.0035
[397] time=166.42, avg_loss=0.0035, train_err=0.0839
Eval: 128_h1=0.0068, 128_l2=0.0035
[398] time=166.37, avg_loss=0.0035, train_err=0.0835
Eval: 128_h1=0.0068, 128_l2=0.0035
[399] time=166.32, avg_loss=0.0035, train_err=0.0833
Eval: 128_h1=0.0068, 128_l2=0.0035
[400] time=166.37, avg_loss=0.0037, train_err=0.0888
Eval: 128_h1=0.0065, 128_l2=0.0030
[401] time=166.45, avg_loss=0.0037, train_err=0.0882
Eval: 128_h1=0.0065, 128_l2=0.0030
[402] time=166.47, avg_loss=0.0036, train_err=0.0874
Eval: 128_h1=0.0065, 128_l2=0.0030
[403] time=166.43, avg_loss=0.0036, train_err=0.0868
Eval: 128_h1=0.0065, 128_l2=0.0030
[404] time=166.44, avg_loss=0.0036, train_err=0.0862
Eval: 128_h1=0.0065, 128_l2=0.0030
[405] time=166.41, avg_loss=0.0036, train_err=0.0857
Eval: 128_h1=0.0064, 128_l2=0.0030
[406] time=173.97, avg_loss=0.0036, train_err=0.0852
Eval: 128_h1=0.0064, 128_l2=0.0030
[407] time=176.29, avg_loss=0.0035, train_err=0.0848
Eval: 128_h1=0.0064, 128_l2=0.0030
[408] time=177.97, avg_loss=0.0035, train_err=0.0844
Eval: 128_h1=0.0064, 128_l2=0.0030
[409] time=174.19, avg_loss=0.0035, train_err=0.0841
Eval: 128_h1=0.0064, 128_l2=0.0030
[410] time=168.91, avg_loss=0.0035, train_err=0.0838
Eval: 128_h1=0.0064, 128_l2=0.0030
[411] time=181.68, avg_loss=0.0035, train_err=0.0835
Eval: 128_h1=0.0064, 128_l2=0.0030
[412] time=171.12, avg_loss=0.0035, train_err=0.0832
Eval: 128_h1=0.0064, 128_l2=0.0030
[413] time=166.45, avg_loss=0.0035, train_err=0.0829
Eval: 128_h1=0.0064, 128_l2=0.0030
[414] time=166.40, avg_loss=0.0034, train_err=0.0827
Eval: 128_h1=0.0064, 128_l2=0.0030
[415] time=166.44, avg_loss=0.0034, train_err=0.0825
Eval: 128_h1=0.0064, 128_l2=0.0030
[416] time=166.37, avg_loss=0.0034, train_err=0.0823
Eval: 128_h1=0.0064, 128_l2=0.0030
[417] time=166.36, avg_loss=0.0034, train_err=0.0820
Eval: 128_h1=0.0064, 128_l2=0.0030
[418] time=166.39, avg_loss=0.0034, train_err=0.0818
Eval: 128_h1=0.0064, 128_l2=0.0030
[419] time=166.38, avg_loss=0.0034, train_err=0.0816
Eval: 128_h1=0.0064, 128_l2=0.0030
[420] time=166.39, avg_loss=0.0034, train_err=0.0815
Eval: 128_h1=0.0064, 128_l2=0.0030
[421] time=166.40, avg_loss=0.0034, train_err=0.0813
Eval: 128_h1=0.0064, 128_l2=0.0030
[422] time=166.39, avg_loss=0.0034, train_err=0.0811
Eval: 128_h1=0.0064, 128_l2=0.0030
[423] time=166.43, avg_loss=0.0034, train_err=0.0809
Eval: 128_h1=0.0064, 128_l2=0.0030
[424] time=166.40, avg_loss=0.0034, train_err=0.0808
Eval: 128_h1=0.0064, 128_l2=0.0030
[425] time=166.40, avg_loss=0.0034, train_err=0.0806
Eval: 128_h1=0.0064, 128_l2=0.0030
[426] time=168.60, avg_loss=0.0034, train_err=0.0805
Eval: 128_h1=0.0064, 128_l2=0.0030
[427] time=180.93, avg_loss=0.0033, train_err=0.0803
Eval: 128_h1=0.0063, 128_l2=0.0030
[428] time=171.92, avg_loss=0.0033, train_err=0.0802
Eval: 128_h1=0.0063, 128_l2=0.0030
[429] time=173.90, avg_loss=0.0033, train_err=0.0800
Eval: 128_h1=0.0063, 128_l2=0.0030
[430] time=183.93, avg_loss=0.0033, train_err=0.0799
Eval: 128_h1=0.0063, 128_l2=0.0030
[431] time=166.38, avg_loss=0.0033, train_err=0.0797
Eval: 128_h1=0.0063, 128_l2=0.0030
[432] time=166.36, avg_loss=0.0033, train_err=0.0796
Eval: 128_h1=0.0063, 128_l2=0.0030
[433] time=175.47, avg_loss=0.0033, train_err=0.0795
Eval: 128_h1=0.0063, 128_l2=0.0030
[434] time=177.26, avg_loss=0.0033, train_err=0.0793
Eval: 128_h1=0.0063, 128_l2=0.0030
[435] time=176.81, avg_loss=0.0033, train_err=0.0792
Eval: 128_h1=0.0063, 128_l2=0.0030
[436] time=178.16, avg_loss=0.0033, train_err=0.0791
Eval: 128_h1=0.0063, 128_l2=0.0030
[437] time=177.19, avg_loss=0.0033, train_err=0.0789
Eval: 128_h1=0.0063, 128_l2=0.0030
[438] time=177.96, avg_loss=0.0033, train_err=0.0788
Eval: 128_h1=0.0063, 128_l2=0.0030
[439] time=177.84, avg_loss=0.0033, train_err=0.0787
Eval: 128_h1=0.0063, 128_l2=0.0030
[440] time=183.43, avg_loss=0.0033, train_err=0.0786
Eval: 128_h1=0.0063, 128_l2=0.0030
[441] time=185.44, avg_loss=0.0033, train_err=0.0785
Eval: 128_h1=0.0063, 128_l2=0.0030
[442] time=185.72, avg_loss=0.0033, train_err=0.0784
Eval: 128_h1=0.0063, 128_l2=0.0030
[443] time=186.14, avg_loss=0.0033, train_err=0.0782
Eval: 128_h1=0.0063, 128_l2=0.0030
[444] time=185.68, avg_loss=0.0033, train_err=0.0781
Eval: 128_h1=0.0063, 128_l2=0.0030
[445] time=183.47, avg_loss=0.0033, train_err=0.0780
Eval: 128_h1=0.0063, 128_l2=0.0030
[446] time=183.09, avg_loss=0.0032, train_err=0.0779
Eval: 128_h1=0.0063, 128_l2=0.0030
[447] time=185.56, avg_loss=0.0032, train_err=0.0778
Eval: 128_h1=0.0063, 128_l2=0.0030
[448] time=186.45, avg_loss=0.0032, train_err=0.0777
Eval: 128_h1=0.0063, 128_l2=0.0030
[449] time=186.37, avg_loss=0.0032, train_err=0.0776
Eval: 128_h1=0.0063, 128_l2=0.0030
[450] time=185.52, avg_loss=0.0032, train_err=0.0775
Eval: 128_h1=0.0063, 128_l2=0.0030
[451] time=184.65, avg_loss=0.0032, train_err=0.0774
Eval: 128_h1=0.0063, 128_l2=0.0030
[452] time=186.08, avg_loss=0.0032, train_err=0.0773
Eval: 128_h1=0.0063, 128_l2=0.0030
[453] time=186.06, avg_loss=0.0032, train_err=0.0772
Eval: 128_h1=0.0063, 128_l2=0.0030
[454] time=185.95, avg_loss=0.0032, train_err=0.0771
Eval: 128_h1=0.0063, 128_l2=0.0030
[455] time=183.76, avg_loss=0.0032, train_err=0.0770
Eval: 128_h1=0.0063, 128_l2=0.0030
[456] time=185.16, avg_loss=0.0032, train_err=0.0769
Eval: 128_h1=0.0063, 128_l2=0.0030
[457] time=186.47, avg_loss=0.0032, train_err=0.0768
Eval: 128_h1=0.0063, 128_l2=0.0030
[458] time=186.35, avg_loss=0.0032, train_err=0.0767
Eval: 128_h1=0.0063, 128_l2=0.0030
[459] time=185.11, avg_loss=0.0032, train_err=0.0766
Eval: 128_h1=0.0063, 128_l2=0.0030
[460] time=183.13, avg_loss=0.0032, train_err=0.0765
Eval: 128_h1=0.0063, 128_l2=0.0030
[461] time=181.01, avg_loss=0.0032, train_err=0.0764
Eval: 128_h1=0.0063, 128_l2=0.0030
[462] time=181.02, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0063, 128_l2=0.0030
[463] time=180.77, avg_loss=0.0032, train_err=0.0762
Eval: 128_h1=0.0063, 128_l2=0.0030
[464] time=180.51, avg_loss=0.0032, train_err=0.0761
Eval: 128_h1=0.0063, 128_l2=0.0030
[465] time=180.54, avg_loss=0.0032, train_err=0.0760
Eval: 128_h1=0.0063, 128_l2=0.0030
[466] time=168.53, avg_loss=0.0032, train_err=0.0759
Eval: 128_h1=0.0063, 128_l2=0.0030
[467] time=167.55, avg_loss=0.0032, train_err=0.0758
Eval: 128_h1=0.0063, 128_l2=0.0030
[468] time=167.62, avg_loss=0.0032, train_err=0.0757
Eval: 128_h1=0.0063, 128_l2=0.0030
[469] time=167.63, avg_loss=0.0032, train_err=0.0756
Eval: 128_h1=0.0063, 128_l2=0.0030
[470] time=167.33, avg_loss=0.0031, train_err=0.0755
Eval: 128_h1=0.0063, 128_l2=0.0030
[471] time=167.17, avg_loss=0.0031, train_err=0.0754
Eval: 128_h1=0.0063, 128_l2=0.0030
[472] time=167.57, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0063, 128_l2=0.0030
[473] time=167.64, avg_loss=0.0031, train_err=0.0752
Eval: 128_h1=0.0063, 128_l2=0.0030
[474] time=167.51, avg_loss=0.0031, train_err=0.0751
Eval: 128_h1=0.0063, 128_l2=0.0030
[475] time=167.53, avg_loss=0.0031, train_err=0.0750
Eval: 128_h1=0.0063, 128_l2=0.0030
[476] time=167.03, avg_loss=0.0031, train_err=0.0749
Eval: 128_h1=0.0063, 128_l2=0.0030
[477] time=167.44, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0063, 128_l2=0.0030
[478] time=167.67, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0063, 128_l2=0.0030
[479] time=167.79, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0063, 128_l2=0.0030
[480] time=167.84, avg_loss=0.0031, train_err=0.0746
Eval: 128_h1=0.0063, 128_l2=0.0030
[481] time=167.73, avg_loss=0.0031, train_err=0.0745
Eval: 128_h1=0.0063, 128_l2=0.0030
[482] time=167.75, avg_loss=0.0031, train_err=0.0744
Eval: 128_h1=0.0063, 128_l2=0.0030
[483] time=167.64, avg_loss=0.0031, train_err=0.0744
Eval: 128_h1=0.0063, 128_l2=0.0030
[484] time=167.72, avg_loss=0.0031, train_err=0.0743
Eval: 128_h1=0.0063, 128_l2=0.0030
[485] time=167.71, avg_loss=0.0031, train_err=0.0742
Eval: 128_h1=0.0063, 128_l2=0.0030
[486] time=167.51, avg_loss=0.0031, train_err=0.0741
Eval: 128_h1=0.0063, 128_l2=0.0030
[487] time=167.51, avg_loss=0.0031, train_err=0.0741
Eval: 128_h1=0.0063, 128_l2=0.0030
[488] time=167.52, avg_loss=0.0031, train_err=0.0740
Eval: 128_h1=0.0063, 128_l2=0.0030
[489] time=167.31, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0063, 128_l2=0.0030
[490] time=167.58, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0063, 128_l2=0.0030
[491] time=177.68, avg_loss=0.0031, train_err=0.0738
Eval: 128_h1=0.0063, 128_l2=0.0030
[492] time=181.00, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0063, 128_l2=0.0030
[493] time=181.24, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0063, 128_l2=0.0030
[494] time=181.07, avg_loss=0.0031, train_err=0.0736
Eval: 128_h1=0.0063, 128_l2=0.0030
[495] time=180.78, avg_loss=0.0031, train_err=0.0735
Eval: 128_h1=0.0063, 128_l2=0.0030
[496] time=180.80, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0063, 128_l2=0.0030
[497] time=181.00, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0063, 128_l2=0.0030
[498] time=180.89, avg_loss=0.0031, train_err=0.0733
Eval: 128_h1=0.0063, 128_l2=0.0030
[499] time=181.31, avg_loss=0.0031, train_err=0.0732
Eval: 128_h1=0.0063, 128_l2=0.0030
[500] time=181.18, avg_loss=0.0032, train_err=0.0770
Eval: 128_h1=0.0062, 128_l2=0.0029
[501] time=181.09, avg_loss=0.0032, train_err=0.0767
Eval: 128_h1=0.0062, 128_l2=0.0029
[502] time=181.01, avg_loss=0.0032, train_err=0.0763
Eval: 128_h1=0.0062, 128_l2=0.0029
[503] time=181.15, avg_loss=0.0032, train_err=0.0760
Eval: 128_h1=0.0062, 128_l2=0.0029
[504] time=181.17, avg_loss=0.0032, train_err=0.0757
Eval: 128_h1=0.0062, 128_l2=0.0028
[505] time=181.15, avg_loss=0.0031, train_err=0.0755
Eval: 128_h1=0.0062, 128_l2=0.0028
[506] time=181.24, avg_loss=0.0031, train_err=0.0753
Eval: 128_h1=0.0061, 128_l2=0.0028
[507] time=181.09, avg_loss=0.0031, train_err=0.0751
Eval: 128_h1=0.0061, 128_l2=0.0028
[508] time=181.17, avg_loss=0.0031, train_err=0.0750
Eval: 128_h1=0.0061, 128_l2=0.0028
[509] time=181.21, avg_loss=0.0031, train_err=0.0748
Eval: 128_h1=0.0061, 128_l2=0.0028
[510] time=181.07, avg_loss=0.0031, train_err=0.0747
Eval: 128_h1=0.0061, 128_l2=0.0028
[511] time=180.96, avg_loss=0.0031, train_err=0.0745
Eval: 128_h1=0.0061, 128_l2=0.0028
[512] time=181.36, avg_loss=0.0031, train_err=0.0744
Eval: 128_h1=0.0061, 128_l2=0.0028
[513] time=181.08, avg_loss=0.0031, train_err=0.0743
Eval: 128_h1=0.0061, 128_l2=0.0028
[514] time=181.08, avg_loss=0.0031, train_err=0.0742
Eval: 128_h1=0.0061, 128_l2=0.0028
[515] time=181.06, avg_loss=0.0031, train_err=0.0741
Eval: 128_h1=0.0061, 128_l2=0.0028
[516] time=181.06, avg_loss=0.0031, train_err=0.0740
Eval: 128_h1=0.0061, 128_l2=0.0028
[517] time=181.27, avg_loss=0.0031, train_err=0.0739
Eval: 128_h1=0.0061, 128_l2=0.0028
[518] time=181.12, avg_loss=0.0031, train_err=0.0738
Eval: 128_h1=0.0061, 128_l2=0.0028
[519] time=181.31, avg_loss=0.0031, train_err=0.0737
Eval: 128_h1=0.0061, 128_l2=0.0028
[520] time=181.59, avg_loss=0.0031, train_err=0.0736
Eval: 128_h1=0.0061, 128_l2=0.0028
[521] time=181.00, avg_loss=0.0031, train_err=0.0735
Eval: 128_h1=0.0061, 128_l2=0.0028
[522] time=181.40, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0061, 128_l2=0.0028
[523] time=181.39, avg_loss=0.0031, train_err=0.0734
Eval: 128_h1=0.0061, 128_l2=0.0028
[524] time=181.44, avg_loss=0.0031, train_err=0.0733
Eval: 128_h1=0.0061, 128_l2=0.0028
[525] time=181.31, avg_loss=0.0031, train_err=0.0732
Eval: 128_h1=0.0061, 128_l2=0.0028
[526] time=181.29, avg_loss=0.0030, train_err=0.0731
Eval: 128_h1=0.0061, 128_l2=0.0028
[527] time=168.94, avg_loss=0.0030, train_err=0.0731
Eval: 128_h1=0.0061, 128_l2=0.0028
[528] time=167.50, avg_loss=0.0030, train_err=0.0730
Eval: 128_h1=0.0061, 128_l2=0.0028
[529] time=168.91, avg_loss=0.0030, train_err=0.0729
Eval: 128_h1=0.0061, 128_l2=0.0028
[530] time=173.79, avg_loss=0.0030, train_err=0.0729
Eval: 128_h1=0.0061, 128_l2=0.0028
[531] time=173.91, avg_loss=0.0030, train_err=0.0728
Eval: 128_h1=0.0061, 128_l2=0.0028
[532] time=173.50, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0061, 128_l2=0.0028
[533] time=173.99, avg_loss=0.0030, train_err=0.0727
Eval: 128_h1=0.0061, 128_l2=0.0028
[534] time=173.87, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0061, 128_l2=0.0028
[535] time=173.72, avg_loss=0.0030, train_err=0.0726
Eval: 128_h1=0.0061, 128_l2=0.0028
[536] time=173.59, avg_loss=0.0030, train_err=0.0725
Eval: 128_h1=0.0061, 128_l2=0.0028
[537] time=173.65, avg_loss=0.0030, train_err=0.0724
Eval: 128_h1=0.0061, 128_l2=0.0028
[538] time=173.87, avg_loss=0.0030, train_err=0.0724
Eval: 128_h1=0.0061, 128_l2=0.0028
[539] time=173.74, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0061, 128_l2=0.0028
[540] time=174.05, avg_loss=0.0030, train_err=0.0723
Eval: 128_h1=0.0061, 128_l2=0.0028
[541] time=173.73, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0061, 128_l2=0.0028
[542] time=176.46, avg_loss=0.0030, train_err=0.0722
Eval: 128_h1=0.0061, 128_l2=0.0028
[543] time=180.80, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0061, 128_l2=0.0028
[544] time=180.68, avg_loss=0.0030, train_err=0.0721
Eval: 128_h1=0.0061, 128_l2=0.0028
[545] time=180.87, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0061, 128_l2=0.0028
[546] time=180.82, avg_loss=0.0030, train_err=0.0720
Eval: 128_h1=0.0061, 128_l2=0.0028
[547] time=180.71, avg_loss=0.0030, train_err=0.0719
Eval: 128_h1=0.0061, 128_l2=0.0028
[548] time=180.54, avg_loss=0.0030, train_err=0.0719
Eval: 128_h1=0.0061, 128_l2=0.0028
[549] time=180.72, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0061, 128_l2=0.0028
[550] time=180.74, avg_loss=0.0030, train_err=0.0718
Eval: 128_h1=0.0061, 128_l2=0.0028
[551] time=181.01, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0061, 128_l2=0.0028
[552] time=180.49, avg_loss=0.0030, train_err=0.0717
Eval: 128_h1=0.0061, 128_l2=0.0028
[553] time=180.64, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0061, 128_l2=0.0028
[554] time=180.61, avg_loss=0.0030, train_err=0.0716
Eval: 128_h1=0.0061, 128_l2=0.0028
[555] time=175.08, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0061, 128_l2=0.0028
[556] time=167.38, avg_loss=0.0030, train_err=0.0715
Eval: 128_h1=0.0061, 128_l2=0.0028
[557] time=167.57, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0061, 128_l2=0.0028
[558] time=167.37, avg_loss=0.0030, train_err=0.0714
Eval: 128_h1=0.0061, 128_l2=0.0028
[559] time=167.63, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0061, 128_l2=0.0028
[560] time=167.47, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0061, 128_l2=0.0028
[561] time=167.38, avg_loss=0.0030, train_err=0.0713
Eval: 128_h1=0.0061, 128_l2=0.0028
[562] time=167.51, avg_loss=0.0030, train_err=0.0712
Eval: 128_h1=0.0061, 128_l2=0.0028
[563] time=167.41, avg_loss=0.0030, train_err=0.0712
Eval: 128_h1=0.0061, 128_l2=0.0028
[564] time=167.45, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0061, 128_l2=0.0028
[565] time=167.62, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0061, 128_l2=0.0028
[566] time=167.57, avg_loss=0.0030, train_err=0.0711
Eval: 128_h1=0.0061, 128_l2=0.0028
[567] time=167.43, avg_loss=0.0030, train_err=0.0710
Eval: 128_h1=0.0061, 128_l2=0.0028
[568] time=167.36, avg_loss=0.0030, train_err=0.0710
Eval: 128_h1=0.0061, 128_l2=0.0028
[569] time=167.55, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0061, 128_l2=0.0028
[570] time=167.55, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0061, 128_l2=0.0028
[571] time=167.63, avg_loss=0.0030, train_err=0.0709
Eval: 128_h1=0.0061, 128_l2=0.0028
[572] time=167.64, avg_loss=0.0030, train_err=0.0708
Eval: 128_h1=0.0061, 128_l2=0.0028
[573] time=167.64, avg_loss=0.0030, train_err=0.0708
Eval: 128_h1=0.0061, 128_l2=0.0028
[574] time=167.36, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0061, 128_l2=0.0028
[575] time=167.64, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0061, 128_l2=0.0028
[576] time=167.52, avg_loss=0.0029, train_err=0.0707
Eval: 128_h1=0.0061, 128_l2=0.0028
[577] time=167.52, avg_loss=0.0029, train_err=0.0706
Eval: 128_h1=0.0061, 128_l2=0.0028
[578] time=167.48, avg_loss=0.0029, train_err=0.0706
Eval: 128_h1=0.0061, 128_l2=0.0028
[579] time=167.46, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0061, 128_l2=0.0028
[580] time=167.46, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0061, 128_l2=0.0028
[581] time=167.76, avg_loss=0.0029, train_err=0.0705
Eval: 128_h1=0.0061, 128_l2=0.0028
[582] time=167.53, avg_loss=0.0029, train_err=0.0704
Eval: 128_h1=0.0061, 128_l2=0.0028
[583] time=167.39, avg_loss=0.0029, train_err=0.0704
Eval: 128_h1=0.0061, 128_l2=0.0028
[584] time=167.61, avg_loss=0.0029, train_err=0.0704
Eval: 128_h1=0.0061, 128_l2=0.0028
[585] time=167.49, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0061, 128_l2=0.0028
[586] time=167.46, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0061, 128_l2=0.0028
[587] time=167.49, avg_loss=0.0029, train_err=0.0703
Eval: 128_h1=0.0061, 128_l2=0.0028
[588] time=167.75, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0061, 128_l2=0.0028
[589] time=167.53, avg_loss=0.0029, train_err=0.0702
Eval: 128_h1=0.0061, 128_l2=0.0028
[590] time=167.43, avg_loss=0.0029, train_err=0.0701
Eval: 128_h1=0.0061, 128_l2=0.0028
[591] time=167.49, avg_loss=0.0029, train_err=0.0701
Eval: 128_h1=0.0061, 128_l2=0.0028
[592] time=167.31, avg_loss=0.0029, train_err=0.0701
Eval: 128_h1=0.0061, 128_l2=0.0028
[593] time=167.44, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0061, 128_l2=0.0028
[594] time=167.66, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0061, 128_l2=0.0028
[595] time=167.41, avg_loss=0.0029, train_err=0.0700
Eval: 128_h1=0.0061, 128_l2=0.0028
[596] time=167.44, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0061, 128_l2=0.0028
[597] time=167.71, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0061, 128_l2=0.0028
[598] time=167.36, avg_loss=0.0029, train_err=0.0699
Eval: 128_h1=0.0061, 128_l2=0.0028
[599] time=167.48, avg_loss=0.0029, train_err=0.0698
Eval: 128_h1=0.0061, 128_l2=0.0028
